[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "This site hosts documentation to preprocess and analyze structural (DTI), and functional (rs-fMRI) data with the latest tools available. For any inquiry, please contact me at: guichetc@univ-grenoble-alpes.fr"
  },
  {
    "objectID": "content/guide/rs-fMRI/conn.html",
    "href": "content/guide/rs-fMRI/conn.html",
    "title": "CONN",
    "section": "",
    "text": "Following the standard preprocessing pipeline, the CONN toolbox (Whitfield-Gabrieli and Nieto-Castanon 2012) takes care of the FC generation after denoising (Behzadi et al. 2007). This is an add-on to SPM that can be downloaded here.\n\nSTEP 1. Importing the data into a new CONN project\nThis script will create a new conn project named conn_example and automatically import the functional and structural volumes for the set number of subjects.\n% Created by Andrew Jahn, University of Michigan, 02.27.2020\n% Adapted by Clément Guichet, UGA, LPNC, 07.01.2023\n\n% FIND functional/structural files\nNSUBJECTS= ??;\ncwd=pwd;\n\n# the smoothed out spatially preprocessed volumes, conn will automatically bind them to the unsmoothed ones\nFUNCTIONAL_FILE=cellstr(conn_dir('swar*.nii'));\nSTRUCTURAL_FILE=cellstr(conn_dir('wm*.nii'));\nif rem(length(FUNCTIONAL_FILE),NSUBJECTS),error('mismatch number of functional files %n', length(FUNCTIONAL_FILE));end\nif rem(length(STRUCTURAL_FILE),NSUBJECTS),error('mismatch number of anatomical files %n', length(FUNCTIONAL_FILE));end\nnsessions=length(FUNCTIONAL_FILE)/NSUBJECTS;\nFUNCTIONAL_FILE=reshape(FUNCTIONAL_FILE,[nsessions, NSUBJECTS]);\nSTRUCTURAL_FILE={STRUCTURAL_FILE{1:NSUBJECTS}};\ndisp([num2str(size(FUNCTIONAL_FILE,1)),' sessions']);\ndisp([num2str(size(FUNCTIONAL_FILE,2)),' subjects']);\nTR= ??; % Repetition time\n\n\n% CONN-SPECIFIC SECTION: RUNS SETUP STEPS\n% Prepares batch structure\nclear batch;\nbatch.filename=fullfile(cwd,'conn_example.mat'); % New conn_*.mat experiment name\n\n% SETUP step\nbatch.Setup.isnew=1;\nbatch.Setup.nsubjects=NSUBJECTS;\nbatch.Setup.RT=TR; % TR (seconds)\n\nbatch.Setup.functionals=repmat({{}},[NSUBJECTS,1]); % Pre-allocation\n% Point to functional volumes for each subject/session\nfor nsub=1:NSUBJECTS\n    for nses=1:nsessions\n        batch.Setup.functionals{nsub}{nses}{1}=FUNCTIONAL_FILE{nses,nsub};\n    end\nend \nbatch.Setup.structurals=STRUCTURAL_FILE; % Point to anatomical volumes for each subject\n\n\n% Define the names and files for the covariates\ncovariate_names = {'Art_outliers_&_movement'};\nART_FILE = cellstr(conn_dir('art_regression_outliers_and_movement_warRS.mat'));\nncovariate=length(ART_FILE)/NSUBJECTS;\nART_FILE = reshape(ART_FILE, [ncovariate, NSUBJECTS]);\ndisp([num2str(size(ART_FILE,1)),'covariate']);\ndisp([num2str(size(ART_FILE,2)),'subjects']);\n\n% Add covariates\nbatch.Setup.covariates.add=1;\nbatch.Setup.covariates.names=covariate_names; \nfor ncov=1:ncovariate\n    for nsub=1:NSUBJECTS\n        for nses=1:nsessions\n            batch.Setup.covariates.files{ncov}{nsub}{nses}{1}=ART_FILE{nses,nsub,ncov}; \n        end \n    end\nend\n\n\n% Run all analyses\nconn_batch(batch);\n\n\nSTEP 2. Running CONN in the GUI\nAfter creating the project, you can open the gui by typing:\nconn\nconn('load', fullfile(cwd, 'conn_example.mat'))\nIf the project does not load up, you can open the mat file in the GUI.\n\nAtlas selection & Denoising\n\nCheck that the structural and functional volumes have all been imported correctly.\nIn the ROIs field, remove the default atlas if there is one and import yours in NIFTI format.\nCheck the ‘Atlas file’ box.\n\nIn the Options field, enable ROI-to-ROI analyses only.\n\nClick done. This may take up a few hours depending on the cohort size.\nBy default, CONN includes regressors derived from the tissue types you generated in the ROIs section (WM, CSF) of the Setup tab, and the 1st-level covariates of the Setup tab (Art_mvt). You can leave the default settings and proceed to the 1st-level analyses by clicking done.\n\n\n\n\nGenerate the Functional Connectome (FC)\n\nCreate a new analysis and select RRC (ROI-to-ROI connectivity).\nSelect the brain regions to be included in the connectome.\n\nClick done to generate the .mat file. Under the path /conn_example/results/firstlevel/RRC, you should now visualize the .mat files for each subject.\n\n\nLearn how to analyze these functional connectomes with graph theory here.\n\n\n\n\n\n\nReferences\n\nBehzadi, Yashar, Khaled Restom, Joy Liau, and Thomas T. Liu. 2007. “A Component Based Noise Correction Method (CompCor) for BOLD and Perfusion Based fMRI.” NeuroImage 37 (1): 90–101. https://doi.org/10.1016/j.neuroimage.2007.04.042.\n\n\nWhitfield-Gabrieli, Susan, and Alfonso Nieto-Castanon. 2012. “Conn : A Functional Connectivity Toolbox for Correlated and Anticorrelated Brain Networks.” Brain Connectivity 2 (3): 125–41. https://doi.org/10.1089/brain.2012.0073."
  },
  {
    "objectID": "content/guide/DTI/setup_win.html",
    "href": "content/guide/DTI/setup_win.html",
    "title": "Setup (Windows)",
    "section": "",
    "text": "Check that WSL2 is running by typing this command in PowerShell:\n  wsl -l -v \n# You should see something like this\n  NAME                   STATE           VERSION\n  Ubuntu-22.04           Running         2\n  \n# If you have WSL1, you can update to WSL2 by typing \n  wsl --set-default-version 2 wsl --set-version Ubuntu-22.04 2\nOtherwise, you can install Ubuntu by pasting the following commands:\n1. Enable WSL by opening PowerShell as administrator\n    wsl --install -d Ubuntu-22.04\n2. Restart your computer\n3. Start the Ubuntu app to open a Ubuntu shell\n4. Set up a username and password\nYou’ll also need to GUI for WSL. I recommend you install VcXsrv on your system, which is a free X-sever on Windows. After downloading and installing VcXsrv with default options, run Xlaunch (which gets installed automatically) and perform the following configuration:\n\nDisplay setting: select multiple windows option\nClient startup: check the Start no client option\nExtra setting: make sure “Disable access control” is enabled and “native opengl” is disabled\nAdd this to your .bashrc file:\n echo \"export DISPLAY=$(grep nameserver /etc/resolv.conf  | awk '{print $2; exit}'):0\" &gt;&gt; ~/.bashrc\n echo \"export LIBGL_ALWAYS_INDIRECT=0\" &gt;&gt; ~/.bashrc\n # For Windows 11 users, add this as well\n  echo \"export LIBGL_ALWAYS_SOFTWARE=1\" &gt;&gt; ~/.bashrc\nTry running glxgears. A window with three spinning gears should open.\nTroubleshooting:\n\nMake sure you are not using a VPN.\nGo to Control panel &gt; System and security &gt; Windows defender firewall &gt; Advanced settings &gt; Inbound rules and make sure that the VcXsrv rules are not set to block - if they are you will need to edit the VcXsrv rule and change it from block to allow."
  },
  {
    "objectID": "content/guide/DTI/setup_win.html#os",
    "href": "content/guide/DTI/setup_win.html#os",
    "title": "Setup (Windows)",
    "section": "",
    "text": "Check that WSL2 is running by typing this command in PowerShell:\n  wsl -l -v \n# You should see something like this\n  NAME                   STATE           VERSION\n  Ubuntu-22.04           Running         2\n  \n# If you have WSL1, you can update to WSL2 by typing \n  wsl --set-default-version 2 wsl --set-version Ubuntu-22.04 2\nOtherwise, you can install Ubuntu by pasting the following commands:\n1. Enable WSL by opening PowerShell as administrator\n    wsl --install -d Ubuntu-22.04\n2. Restart your computer\n3. Start the Ubuntu app to open a Ubuntu shell\n4. Set up a username and password\nYou’ll also need to GUI for WSL. I recommend you install VcXsrv on your system, which is a free X-sever on Windows. After downloading and installing VcXsrv with default options, run Xlaunch (which gets installed automatically) and perform the following configuration:\n\nDisplay setting: select multiple windows option\nClient startup: check the Start no client option\nExtra setting: make sure “Disable access control” is enabled and “native opengl” is disabled\nAdd this to your .bashrc file:\n echo \"export DISPLAY=$(grep nameserver /etc/resolv.conf  | awk '{print $2; exit}'):0\" &gt;&gt; ~/.bashrc\n echo \"export LIBGL_ALWAYS_INDIRECT=0\" &gt;&gt; ~/.bashrc\n # For Windows 11 users, add this as well\n  echo \"export LIBGL_ALWAYS_SOFTWARE=1\" &gt;&gt; ~/.bashrc\nTry running glxgears. A window with three spinning gears should open.\nTroubleshooting:\n\nMake sure you are not using a VPN.\nGo to Control panel &gt; System and security &gt; Windows defender firewall &gt; Advanced settings &gt; Inbound rules and make sure that the VcXsrv rules are not set to block - if they are you will need to edit the VcXsrv rule and change it from block to allow."
  },
  {
    "objectID": "content/guide/DTI/setup_win.html#software-installation",
    "href": "content/guide/DTI/setup_win.html#software-installation",
    "title": "Setup (Windows)",
    "section": "Software installation",
    "text": "Software installation\nThe pipeline revolves around MRtrix3 which works hand in hand with Freesurfer, FSL, and ANTs\n\nMRtrix3\nDownload MRtrix3 by copy pasting this command in a bash terminal:\n# Clone the MRtrix3 repo\ngit clone https://github.com/MRtrix3/mrtrix3.git\n# Configure the install\ncd mrtrix3\n./configure\n# Build the binaries\n./build\n# Add it to your path\n./set_path\nIf you get an error, you can try with conda:\n# If conda has been installed in /root, you may need to enter:\nsudo chown -R $USER:$USER miniconda3\n\nconda install -c mrtrix3 mrtrix3\nType an MRtrix3 command like mrconvert to check everything’s working correctly.\nAdd MRtrix3 to your PATH:\necho \"export MRtrix3=$HOME/miniconda3/pkgs/mrtrix3-3.0.4-h2bc3f7f_0\" &gt;&gt; .bashrc\necho \"export PATH=${MRtrix3}:$PATH\" &gt;&gt; .bashrc\n\n\nFreesurfer\n\nIn your “HOME” directory (cd $HOME), download the Freesurfer installer package:\nwget https://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/7.4.1/freesurfer_ubuntu22-7.4.1_amd64.deb\nMake sure to install the Freesurfer distribution under the path /usr/local/freesurfer/7.4.1\ncd /usr/local\nsudo apt-get -y install ./freesurfer_ubuntu22-7.4.1_amd64.deb\nAdd it to your PATH\necho \"export FREESURFER_HOME=/usr/local/freesurfer/7.4.1\" &gt;&gt; $HOME/.bashrc\nGet the free license online, download it in your home directory and add this command in your .bashrc:\nexport FS_LICENSE=$HOME/license.txt\nSet the Freesurfer env to be setup when you open the shell:\necho \"source $FREESURFER_HOME/SetUpFreeSurfer.sh\" &gt;&gt; $HOME/.bashrc\n\nOpen a new Ubuntu linux terminal window and verify you see the following output showing the Freesurfer environment has been set. If everything went fine, you should see this output:\n - - - - - - - -freesurfer-linux-ubuntu22_x86_64-7.4.1-20230614-7eb8460- - - - - - - -\nSetting up environment for FreeSurfer/FS-FAST (and FSL)\nFREESURFER_HOME   /usr/local/freesurfer/7.4.1\nFSFAST_HOME       /usr/local/freesurfer/7.4.1/fsfast\nFSF_OUTPUT_FORMAT nii.gz\nSUBJECTS_DIR      /usr/local/freesurfer/7.4.1/subjects\nMNI_DIR           /usr/local/freesurfer/7.4.1/mni\n\n\nFSL\n\nDownload the FSL installer script online. When selecting the OS to install on the download page, make sure to select Ubuntu and not Windows.\nRun the installer script by replacing &lt;UserName&gt; with your windows user name. Make sure to install it under the path /usr/local/fsl/.\npython3 \"fslinstaller.py\"\n\n\n\nANTs\n\nDownload the ANTs installer script\nIn the terminal, enter:\nbash installANTs.sh\nAdd it to your PATH\necho \"ANTSPATH=$HOME/install/bin/\" &gt;&gt; $HOME/.bashrc\necho \"export PATH=${ANTSPATH}:$PATH\" &gt;&gt; $HOME/.bashrc"
  },
  {
    "objectID": "content/guide/DTI/parallel.html",
    "href": "content/guide/DTI/parallel.html",
    "title": "Parallel processing",
    "section": "",
    "text": "Install Homebrew with the following command and add it to your PATH:\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\ntest -d ~/.linuxbrew && eval \"$(~/.linuxbrew/bin/brew shellenv)\"\ntest -d /home/linuxbrew/.linuxbrew && eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\"\ntest -r ~/.bash_profile && echo \"eval \\\"\\$($(brew --prefix)/bin/brew shellenv)\\\"\" &gt;&gt; ~/.bash_profile\necho \"eval \\\"\\$($(brew --prefix)/bin/brew shellenv)\\\"\" &gt;&gt; ~/.profile\nThen install gcc and parallel:\nbrew install gcc\nbrew install parallel"
  },
  {
    "objectID": "content/guide/DTI/parallel.html#software-installation",
    "href": "content/guide/DTI/parallel.html#software-installation",
    "title": "Parallel processing",
    "section": "",
    "text": "Install Homebrew with the following command and add it to your PATH:\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\ntest -d ~/.linuxbrew && eval \"$(~/.linuxbrew/bin/brew shellenv)\"\ntest -d /home/linuxbrew/.linuxbrew && eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\"\ntest -r ~/.bash_profile && echo \"eval \\\"\\$($(brew --prefix)/bin/brew shellenv)\\\"\" &gt;&gt; ~/.bash_profile\necho \"eval \\\"\\$($(brew --prefix)/bin/brew shellenv)\\\"\" &gt;&gt; ~/.profile\nThen install gcc and parallel:\nbrew install gcc\nbrew install parallel"
  },
  {
    "objectID": "content/guide/DTI/parallel.html#using-the-parallel-command",
    "href": "content/guide/DTI/parallel.html#using-the-parallel-command",
    "title": "Parallel processing",
    "section": "Using the parallel command",
    "text": "Using the parallel command\nParallel is run by piping the ls command into the parallel command:\nls *.nii | parallel --jobs &lt;nproc --all&gt; recon-all -s {.}_recon -i {} -all\n--jobs N indicates that N cores will be used to analyze the data and that each instance of recon-all will be assigned to a different core.\nThe full bash script consists in copying the T1.nii.gz images in the new directory (FS), unzip them, run and store the output of recon-all in this directory\n#!/bin/bash\n\n# Assuming you are in the raw_data directory which lists all the subjects folders\nmkdir FS\ncd FS\n\n# grab the list of subject name\nls ../raw_data | grep ^sub- &gt; subjList.txt\n\n# Path to the anatomical T1 image\nfor sub in `cat subjList.txt`; do\n    cp ../raw_data/${sub}/anat/${sub}_T1w.nii.gz .\ndone\n\n# Unzip\ngunzip *.gz\n\n# Story output in the current directory\n# This avoids permission error\nSUBJECTS_DIR=`pwd`\n\nls *.nii | parallel --jobs 12 recon-all -s {.}_recon -i {} -all\n\n# Remove the copied T1.nii.gz files\nrm *.nii\n\n# Copy into freesurfer's subjects directory\n**On Windows**\necho &lt;password&gt; | sudo -S cp -r *recon $SUBJECTS_DIR\n# Grant permission to write the file\necho &lt;password&gt; | sudo -S chmod -R a+w /usr/local/freesurfer\n\n**On linux**\ncp -r *recon $SUBJECTS_DIR\nYou can then carry on with mapping the glasser annotation file:\n# Map the annotation files of the HCP MMP 1.0 atlas from fsaverage to you subject for both hemispheres:\ncd ../raw_data\n\nls . | grep ^sub- &gt; subjList.txt\n\nfor sub in `cat subjList.txt`; do\n  # Left hemisphere\n  mri_surf2surf --srcsubject fsaverage --trgsubject ${sub}_recon --hemi lh --sval-annot $SUBJECTS_DIR/fsaverage/label/lh.hcpmmp1.annot --tval $SUBJECTS_DIR/${sub}_T1w_recon/label/lh.hcpmmp1.annot\n\n  # Right hemisphere\n  mri_surf2surf --srcsubject fsaverage --trgsubject ${sub}_recon --hemi rh --sval-annot $SUBJECTS_DIR/fsaverage/label/rh.hcpmmp1.annot --tval $SUBJECTS_DIR/${sub}_T1w_recon/label/rh.hcpmmp1.annot\n  \n  cd ./{sub}/dwi\n  mri_aparc2aseg --old-ribbon --s ${sub}_recon --annot hcpmmp1 --o ${sub}/dwi/hcpmmp1.mgz\n  cd ../..\n  \ndone"
  },
  {
    "objectID": "content/about.html",
    "href": "content/about.html",
    "title": "About",
    "section": "",
    "text": "I’m a 2nd-year PhD Student in Cognitive and Computational Neuroscience at LPNC, CNRS UMR 5105, UGA, Grenoble, France. My research project is about modeling how our brain reorganizes across the lifespan to preserve optimal cognitive (language) performances. Find out more about our team LPNC-LANG here."
  },
  {
    "objectID": "content/about.html#education",
    "href": "content/about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\nPhD candidate (2022-2025) | LPNC, UGA | Supervised by Prof. Monica Baciu and Prof. Martial Mermillod\nMSc degree in Research in Psychology (2020-2022) | LPNC, UGA | Master theses in psycholinguistics supervised by Prof. Elsa Spinelli and Prof. Boris New\nBachelor’s degree in Psychology (2017-2020) | UGA"
  },
  {
    "objectID": "content/about.html#experience",
    "href": "content/about.html#experience",
    "title": "About",
    "section": "Experience",
    "text": "Experience\nCo-analyst & Peer-reviewer (April 2022 - ongoing) | Center of Open Science (COS) | Multi100 project\nCNRS Individual contractor (Sept 2021 - March 2022 incl.) | GIPSA-lab, UGA | Supervised by Takayuki Ito\nCNRS Research intern (June - Aug 2021 incl.) | GIPSA-lab, UGA | Supervised by Takayuki Ito and Jean-Luc Schwartz"
  },
  {
    "objectID": "content/guide/DTI/DTI.html",
    "href": "content/guide/DTI/DTI.html",
    "title": "Diffusion Tensor Imaging (DTI)",
    "section": "",
    "text": "I recommend you check Andrew Jahn’s book for a thorough walk-through DTI analysis with MRtrix3.\n\n\nTo determine the number of available logical processors or CPUs on your system, enter nproc --all in the terminal. The output number is the argument we’ll pass to the -nthreads flag below. I recommend you spare some of it if you wish to perform other tasks while the pipeline is running.\nFor example, I only use 8 out of the 48 available CPUs on my system. You may have to tweak it to your systems specs and size of your cohort for a smooth run.\n\n\n\n#!/bin/bash\n\n############################### STEP 1 ###############################\n#             Convert data to .mif format and denoise                #\n######################################################################\n\n# Also consider doing Gibbs denoising (using mrdegibbs). Check your diffusion data for ringing artifacts before deciding whether to use it\nmrconvert *dwi.nii.gz dwi.mif \nmrconvert dwi.mif -fslgrad *.bvec *.bval dwi_header.mif \n\ndwidenoise dwi_header.mif dwi_den.mif -noise noise.mif \nmrdegibbs dwi_den.mif dwi_den_unr.mif \n\n# Extract the b0 images from the diffusion data acquired in the AP direction\ndwiextract dwi_den.mif - -bzero | mrmath - mean mean_b0_AP.mif -axis 3 \n\n######################################################################\n# Runs the dwipreproc command, which is a wrapper for eddy and topup.\n#### !!! Here the CAMCAN dataset does not provide reverse encoding, hence -rpe_none !!!\n######################################################################\ndwifslpreproc dwi_den.mif dwi_den_preproc.mif -pe_dir AP -rpe_none -readout_time 0.0342002 -eddy_options \" --slm=linear --data_is_shelled\"  -nthreads 8\n\n# Performs bias field correction. Needs ANTs to be installed in order to use the \"ants\" option (use \"fsl\" otherwise)\ndwibiascorrect ants dwi_den_preproc.mif dwi_den_preproc_unbiased.mif -bias bias.mif \n\n# Create a mask for future processing steps\ndwi2mask dwi_den_preproc_unbiased.mif mask.mif \n\n########################### STEP 2 ###################################\n#             Basis function for each tissue type                    #\n######################################################################\n\n# Create a basis function from the subject's DWI data. The \"dhollander\" function is best used for multi-shell acquisitions; it will estimate different basis functions for each tissue type. For single-shell acquisition, use the \"tournier\" function instead\ndwi2response dhollander dwi_den_preproc_unbiased.mif wm.txt gm.txt csf.txt -voxels voxels.mif \n\n# Performs multishell-multitissue constrained spherical deconvolution, using the basis functions estimated above\ndwi2fod msmt_csd dwi_den_preproc_unbiased.mif -mask mask.mif wm.txt wmfod.mif gm.txt gmfod.mif csf.txt csffod.mif \n\n# Creates an image of the fiber orientation densities overlaid onto the estimated tissues (Blue=WM; Green=GM; Red=CSF)\n# You should see FOD's mostly within the white matter. These can be viewed later with the command \"mrview vf.mif -odf.load_sh wmfod.mif\"\nmrconvert -coord 3 0 wmfod.mif - | mrcat csffod.mif gmfod.mif - vf.mif \n\n# Now normalize the FODs to enable comparison between subjects\nmtnormalise wmfod.mif wmfod_norm.mif gmfod.mif gmfod_norm.mif csffod.mif csffod_norm.mif -mask mask.mif \n\n########################### STEP 3 ###################################\n#            Create a GM/WM boundary for seed analysis               #\n######################################################################\n\n# Convert the anatomical image to .mif format, and then extract all five tissue catagories (1=GM; 2=Subcortical GM; 3=WM; 4=CSF; 5=Pathological tissue)\nmrconvert ../anat/*T1w.nii.gz T1.mif \n5ttgen fsl T1.mif 5tt_nocoreg.mif -nthreads 8 \n\n# The following series of commands will take the average of the b0 images (which have the best contrast), convert them and the 5tt image to NIFTI format, and use it for coregistration.\ndwiextract dwi_den_preproc_unbiased.mif - -bzero | mrmath - mean mean_b0_processed.mif -axis 3 \nmrconvert mean_b0_processed.mif mean_b0_processed.nii.gz \nmrconvert 5tt_nocoreg.mif 5tt_nocoreg.nii.gz \n\n# Uses FSL commands fslroi and flirt to create a transformation matrix for regisitration between the tissue map and the b0 images\nfslroi 5tt_nocoreg.nii.gz 5tt_vol0.nii.gz 0 1 #Extract the first volume of the 5tt dataset (since flirt can only use 3D images, not 4D images)\nflirt -in mean_b0_processed.nii.gz -ref 5tt_vol0.nii.gz -interp nearestneighbour -dof 6 -omat diff2struct_fsl.mat\ntransformconvert diff2struct_fsl.mat mean_b0_processed.nii.gz 5tt_nocoreg.nii.gz flirt_import diff2struct_mrtrix.txt \nmrtransform 5tt_nocoreg.mif -linear diff2struct_mrtrix.txt -inverse 5tt_coreg.mif \n\n#Create a seed region along the GM/WM boundary\n5tt2gmwmi 5tt_coreg.mif gmwmSeed_coreg.mif \n\n\n\nMake sure to allocate at least 5Go of space for each subject on your local disk as streamline generation can get quite heavy. Here we generate 10 millions streamlines and then reduce that number using the tckgen and tcksift2 command.\n#!/bin/bash\n\n########################## STEP 4 ###################################\n#                 Run the streamline analysis                        #\n######################################################################\n\n# Create streamlines\n# Note that the \"right\" number of streamlines is still up for debate. Last I read from the MRtrix documentation,\n# They recommend about 100 million tracks. Here I use 10 million, if only to save time. Read their papers and then make a decision\ntckgen -act 5tt_coreg.mif -backtrack -seed_gmwmi gmwmSeed_coreg.mif -nthreads 8 -maxlength 250 -cutoff 0.06 -select 10000k wmfod_norm.mif tracks_10M.tck \n\n# Extract a subset of tracks (here, 200 thousand) for ease of visualization\n# tckedit tracks_10M.tck -number 200k smallerTracks_200k.tck\n\n# Reduce the number of streamlines with tcksift\ntcksift2 -act 5tt_coreg.mif -out_mu sift_mu.txt -out_coeffs sift_coeffs.txt -nthreads 8 tracks_10M.tck wmfod_norm.mif sift_1M.txt \n\n\n\nDownload the lh and rh.hcpmmp1 annot files in the supplementary files here and put them into $SUBJECTS_DIR/fsaverage/label. This will prepare the T1 image for the HCP MMP 1.0 atlas (Glasser et al. 2016).\n\nReplace &lt;sub&gt; with the name of your subject.\nIf recon-all does not work, make sure you have the tcsh shell installed by typing tcsh on the command line. In the event tcsh is not installed, enter sudo apt install tcsh.\nIf the flag -s is not recognized, use -subjid instead\n\n#!/bin/bash\n\n# 1. Since the HCPMMP1-atlas is a FreeSurfer-based atlas, you have to preprocess the T1 image in FreeSurfer. This will take several hours to complete.\nSUBJECTS_DIR=`pwd`;\nrecon-all –s &lt;sub&gt;_recon –i T1_raw.nii.gz –all\n\n# Copy into freesurfer's subjects directory\n**On Windows**\necho &lt;password&gt; | sudo -S cp -r *recon $SUBJECTS_DIR\n# Grant permission to write the file\necho &lt;password&gt; | sudo -S chmod -R a+w /usr/local/freesurfer\n\n**On linux**\ncp -r *recon $SUBJECTS_DIR\nYou can then carry on with mapping the glasser annotation file:\n# Map the annotation files of the HCP MMP 1.0 atlas from fsaverage to you subject for both hemispheres:\nmri_surf2surf --srcsubject fsaverage --trgsubject &lt;sub&gt;_recon --hemi lh --sval-annot $SUBJECTS_DIR/fsaverage/label/lh.hcpmmp1.annot --tval\n$SUBJECTS_DIR/&lt;sub&gt;_recon/label/lh.hcpmmp1.annot\n\nmri_surf2surf --srcsubject fsaverage --trgsubject &lt;sub&gt;_recon --hemi rh --sval-annot $SUBJECTS_DIR/fsaverage/label/rh.hcpmmp1.annot --tval $SUBJECTS_DIR/&lt;sub&gt;_recon/label/rh.hcpmmp1.annot\n\nmri_aparc2aseg --old-ribbon --s &lt;sub&gt;_recon --annot hcpmmp1 --o hcpmmp1.mgz --nthreads 12\n\n\n\n#!/bin/bash\n\nmrconvert –datatype uint32 hcpmmp1.mgz  hcpmmp1.mif\n\n# Replace the random integers of the hcpmmp1.mif file with integers\n# that start at 1 and increase by 1.\nlabelconvert hcpmmp1.mif $MRtrix3/share/mrtrix3/labelconvert/hcpmmp1_original.txt $MRtrix3/share/mrtrix3/labelconvert/hcpmmp1_ordered.txt hcpmmp1_parcels_nocoreg.mif\n\n# Register the ordered atlas-based volumetric parcellation to diffusion space.\nmrtransform hcpmmp1_parcels_nocoreg.mif –linear diff2struct_mrtrix.txt –inverse –datatype uint32 hcpmmp1_parcels_coreg.mif\n\n# Create a whole-brain connectome, representing the streamlines between each parcellation pair in the atlas (in this case, 379x379). The \"symmetric\" option will make the lower diagonal the same as the upper diagonal, and the \"scale_invnodevol\" option will scale the connectome by the inverse of the size of the node\n\ntck2connectome -symmetric -zero_diagonal -scale_invnodevol -tck_weights_in sift_1M.txt tracks_10M.tck hcpmmp1_parcels_coreg.mif IN_hcpmmp1_parcels_coreg.csv -out_assignment assignments_IN_hcpmmp1_parcels_coreg.csv\nThis is what you should end up with. The upper left and lower right quadrant represent the left and right intra-hemispheric connections respectively.\n\n\n\n\nIn Matlab: W = importdata(‘sub-XXXXX_hcpmmp1_parcels_coreg.csv’); figure, imagesc(W, [0 1]), xlabel([’ 379 Glasser regions ‘]), ylabel(’379 Glasser regions’), title([’ Structural connectome (streamline density) ‘]); colormap(jet), colorbar, set(gcf,’color’,‘w’), set(gca,‘fontsize’,14)"
  },
  {
    "objectID": "content/guide/DTI/DTI.html#single-subject-processing",
    "href": "content/guide/DTI/DTI.html#single-subject-processing",
    "title": "Diffusion Tensor Imaging (DTI)",
    "section": "",
    "text": "I recommend you check Andrew Jahn’s book for a thorough walk-through DTI analysis with MRtrix3.\n\n\nTo determine the number of available logical processors or CPUs on your system, enter nproc --all in the terminal. The output number is the argument we’ll pass to the -nthreads flag below. I recommend you spare some of it if you wish to perform other tasks while the pipeline is running.\nFor example, I only use 8 out of the 48 available CPUs on my system. You may have to tweak it to your systems specs and size of your cohort for a smooth run.\n\n\n\n#!/bin/bash\n\n############################### STEP 1 ###############################\n#             Convert data to .mif format and denoise                #\n######################################################################\n\n# Also consider doing Gibbs denoising (using mrdegibbs). Check your diffusion data for ringing artifacts before deciding whether to use it\nmrconvert *dwi.nii.gz dwi.mif \nmrconvert dwi.mif -fslgrad *.bvec *.bval dwi_header.mif \n\ndwidenoise dwi_header.mif dwi_den.mif -noise noise.mif \nmrdegibbs dwi_den.mif dwi_den_unr.mif \n\n# Extract the b0 images from the diffusion data acquired in the AP direction\ndwiextract dwi_den.mif - -bzero | mrmath - mean mean_b0_AP.mif -axis 3 \n\n######################################################################\n# Runs the dwipreproc command, which is a wrapper for eddy and topup.\n#### !!! Here the CAMCAN dataset does not provide reverse encoding, hence -rpe_none !!!\n######################################################################\ndwifslpreproc dwi_den.mif dwi_den_preproc.mif -pe_dir AP -rpe_none -readout_time 0.0342002 -eddy_options \" --slm=linear --data_is_shelled\"  -nthreads 8\n\n# Performs bias field correction. Needs ANTs to be installed in order to use the \"ants\" option (use \"fsl\" otherwise)\ndwibiascorrect ants dwi_den_preproc.mif dwi_den_preproc_unbiased.mif -bias bias.mif \n\n# Create a mask for future processing steps\ndwi2mask dwi_den_preproc_unbiased.mif mask.mif \n\n########################### STEP 2 ###################################\n#             Basis function for each tissue type                    #\n######################################################################\n\n# Create a basis function from the subject's DWI data. The \"dhollander\" function is best used for multi-shell acquisitions; it will estimate different basis functions for each tissue type. For single-shell acquisition, use the \"tournier\" function instead\ndwi2response dhollander dwi_den_preproc_unbiased.mif wm.txt gm.txt csf.txt -voxels voxels.mif \n\n# Performs multishell-multitissue constrained spherical deconvolution, using the basis functions estimated above\ndwi2fod msmt_csd dwi_den_preproc_unbiased.mif -mask mask.mif wm.txt wmfod.mif gm.txt gmfod.mif csf.txt csffod.mif \n\n# Creates an image of the fiber orientation densities overlaid onto the estimated tissues (Blue=WM; Green=GM; Red=CSF)\n# You should see FOD's mostly within the white matter. These can be viewed later with the command \"mrview vf.mif -odf.load_sh wmfod.mif\"\nmrconvert -coord 3 0 wmfod.mif - | mrcat csffod.mif gmfod.mif - vf.mif \n\n# Now normalize the FODs to enable comparison between subjects\nmtnormalise wmfod.mif wmfod_norm.mif gmfod.mif gmfod_norm.mif csffod.mif csffod_norm.mif -mask mask.mif \n\n########################### STEP 3 ###################################\n#            Create a GM/WM boundary for seed analysis               #\n######################################################################\n\n# Convert the anatomical image to .mif format, and then extract all five tissue catagories (1=GM; 2=Subcortical GM; 3=WM; 4=CSF; 5=Pathological tissue)\nmrconvert ../anat/*T1w.nii.gz T1.mif \n5ttgen fsl T1.mif 5tt_nocoreg.mif -nthreads 8 \n\n# The following series of commands will take the average of the b0 images (which have the best contrast), convert them and the 5tt image to NIFTI format, and use it for coregistration.\ndwiextract dwi_den_preproc_unbiased.mif - -bzero | mrmath - mean mean_b0_processed.mif -axis 3 \nmrconvert mean_b0_processed.mif mean_b0_processed.nii.gz \nmrconvert 5tt_nocoreg.mif 5tt_nocoreg.nii.gz \n\n# Uses FSL commands fslroi and flirt to create a transformation matrix for regisitration between the tissue map and the b0 images\nfslroi 5tt_nocoreg.nii.gz 5tt_vol0.nii.gz 0 1 #Extract the first volume of the 5tt dataset (since flirt can only use 3D images, not 4D images)\nflirt -in mean_b0_processed.nii.gz -ref 5tt_vol0.nii.gz -interp nearestneighbour -dof 6 -omat diff2struct_fsl.mat\ntransformconvert diff2struct_fsl.mat mean_b0_processed.nii.gz 5tt_nocoreg.nii.gz flirt_import diff2struct_mrtrix.txt \nmrtransform 5tt_nocoreg.mif -linear diff2struct_mrtrix.txt -inverse 5tt_coreg.mif \n\n#Create a seed region along the GM/WM boundary\n5tt2gmwmi 5tt_coreg.mif gmwmSeed_coreg.mif \n\n\n\nMake sure to allocate at least 5Go of space for each subject on your local disk as streamline generation can get quite heavy. Here we generate 10 millions streamlines and then reduce that number using the tckgen and tcksift2 command.\n#!/bin/bash\n\n########################## STEP 4 ###################################\n#                 Run the streamline analysis                        #\n######################################################################\n\n# Create streamlines\n# Note that the \"right\" number of streamlines is still up for debate. Last I read from the MRtrix documentation,\n# They recommend about 100 million tracks. Here I use 10 million, if only to save time. Read their papers and then make a decision\ntckgen -act 5tt_coreg.mif -backtrack -seed_gmwmi gmwmSeed_coreg.mif -nthreads 8 -maxlength 250 -cutoff 0.06 -select 10000k wmfod_norm.mif tracks_10M.tck \n\n# Extract a subset of tracks (here, 200 thousand) for ease of visualization\n# tckedit tracks_10M.tck -number 200k smallerTracks_200k.tck\n\n# Reduce the number of streamlines with tcksift\ntcksift2 -act 5tt_coreg.mif -out_mu sift_mu.txt -out_coeffs sift_coeffs.txt -nthreads 8 tracks_10M.tck wmfod_norm.mif sift_1M.txt \n\n\n\nDownload the lh and rh.hcpmmp1 annot files in the supplementary files here and put them into $SUBJECTS_DIR/fsaverage/label. This will prepare the T1 image for the HCP MMP 1.0 atlas (Glasser et al. 2016).\n\nReplace &lt;sub&gt; with the name of your subject.\nIf recon-all does not work, make sure you have the tcsh shell installed by typing tcsh on the command line. In the event tcsh is not installed, enter sudo apt install tcsh.\nIf the flag -s is not recognized, use -subjid instead\n\n#!/bin/bash\n\n# 1. Since the HCPMMP1-atlas is a FreeSurfer-based atlas, you have to preprocess the T1 image in FreeSurfer. This will take several hours to complete.\nSUBJECTS_DIR=`pwd`;\nrecon-all –s &lt;sub&gt;_recon –i T1_raw.nii.gz –all\n\n# Copy into freesurfer's subjects directory\n**On Windows**\necho &lt;password&gt; | sudo -S cp -r *recon $SUBJECTS_DIR\n# Grant permission to write the file\necho &lt;password&gt; | sudo -S chmod -R a+w /usr/local/freesurfer\n\n**On linux**\ncp -r *recon $SUBJECTS_DIR\nYou can then carry on with mapping the glasser annotation file:\n# Map the annotation files of the HCP MMP 1.0 atlas from fsaverage to you subject for both hemispheres:\nmri_surf2surf --srcsubject fsaverage --trgsubject &lt;sub&gt;_recon --hemi lh --sval-annot $SUBJECTS_DIR/fsaverage/label/lh.hcpmmp1.annot --tval\n$SUBJECTS_DIR/&lt;sub&gt;_recon/label/lh.hcpmmp1.annot\n\nmri_surf2surf --srcsubject fsaverage --trgsubject &lt;sub&gt;_recon --hemi rh --sval-annot $SUBJECTS_DIR/fsaverage/label/rh.hcpmmp1.annot --tval $SUBJECTS_DIR/&lt;sub&gt;_recon/label/rh.hcpmmp1.annot\n\nmri_aparc2aseg --old-ribbon --s &lt;sub&gt;_recon --annot hcpmmp1 --o hcpmmp1.mgz --nthreads 12\n\n\n\n#!/bin/bash\n\nmrconvert –datatype uint32 hcpmmp1.mgz  hcpmmp1.mif\n\n# Replace the random integers of the hcpmmp1.mif file with integers\n# that start at 1 and increase by 1.\nlabelconvert hcpmmp1.mif $MRtrix3/share/mrtrix3/labelconvert/hcpmmp1_original.txt $MRtrix3/share/mrtrix3/labelconvert/hcpmmp1_ordered.txt hcpmmp1_parcels_nocoreg.mif\n\n# Register the ordered atlas-based volumetric parcellation to diffusion space.\nmrtransform hcpmmp1_parcels_nocoreg.mif –linear diff2struct_mrtrix.txt –inverse –datatype uint32 hcpmmp1_parcels_coreg.mif\n\n# Create a whole-brain connectome, representing the streamlines between each parcellation pair in the atlas (in this case, 379x379). The \"symmetric\" option will make the lower diagonal the same as the upper diagonal, and the \"scale_invnodevol\" option will scale the connectome by the inverse of the size of the node\n\ntck2connectome -symmetric -zero_diagonal -scale_invnodevol -tck_weights_in sift_1M.txt tracks_10M.tck hcpmmp1_parcels_coreg.mif IN_hcpmmp1_parcels_coreg.csv -out_assignment assignments_IN_hcpmmp1_parcels_coreg.csv\nThis is what you should end up with. The upper left and lower right quadrant represent the left and right intra-hemispheric connections respectively.\n\n\n\n\nIn Matlab: W = importdata(‘sub-XXXXX_hcpmmp1_parcels_coreg.csv’); figure, imagesc(W, [0 1]), xlabel([’ 379 Glasser regions ‘]), ylabel(’379 Glasser regions’), title([’ Structural connectome (streamline density) ‘]); colormap(jet), colorbar, set(gcf,’color’,‘w’), set(gca,‘fontsize’,14)"
  },
  {
    "objectID": "content/guide/DTI/DTI.html#batch-processing",
    "href": "content/guide/DTI/DTI.html#batch-processing",
    "title": "Diffusion Tensor Imaging (DTI)",
    "section": "Batch processing",
    "text": "Batch processing\nBelow, I provide a synthesis of the preprocessing steps using the for_each command available on MRtrix3.\n\nFor_each command\nFor_each is useful when you want to run multiple subjects, with multi-threading if possible. You have to provide the path to your dwi directory where your raw data is stored (bvals, bvecs, etc…) as a template :\nassuming you are in the raw_data directory: */dwi\nfor_each will then iterate over the directories paths that match this template, substituting the * with each subject in your dataset.\nIN is used in the MRtrix command to echo the path to the dwi directory of each subject.\n\n\nSTEP 1. Preprocessing\n#!/bin/bash\n\n############################### STEP 1 ###############################\n#             Convert data to .mif format and denoise                #\n######################################################################\n\n# Also consider doing Gibbs denoising (using mrdegibbs). Check your diffusion data for ringing artifacts before deciding whether to use it\nfor_each -nthreads 8 -info */dwi : mrconvert *dwi.nii.gz dwi.mif \nfor_each -nthreads 8 -info */dwi : mrconvert dwi.mif -fslgrad *.bvec *.bval dwi_header.mif \n\nfor_each -nthreads 8 -info */dwi : dwidenoise dwi_header.mif dwi_den.mif -noise noise.mif \nfor_each -nthreads 8 -info */dwi : mrdegibbs dwi_den.mif dwi_den_unr.mif \n\n# Extract the b0 images from the diffusion data acquired in the AP direction\nfor_each -nthreads 8 -info */dwi : dwiextract dwi_den.mif - -bzero \\| mrmath - mean mean_b0_AP.mif -axis 3 \n\n######################################################################\n# Runs the dwipreproc command, which is a wrapper for eddy and topup.\n#### !!! Here the CAMCAN dataset does not provide reverse encoding, hence -rpe_none !!! ####\n#### !!! &lt;nproc --all&gt;/8 means you should divide by 8 as each subject's preprocessing will be performed by 8 threads already (see at the end of the line) #### !!!\n######################################################################\nfor_each &lt;nproc --all&gt;/8 -info */dwi : dwifslpreproc dwi_den.mif dwi_den_preproc.mif -pe_dir AP -rpe_none -readout_time 0.0342002 -eddy_options \" --slm=linear --data_is_shelled\"  -nthreads 8\n\n# Performs bias field correction. Needs ANTs to be installed in order to use the \"ants\" option (use \"fsl\" otherwise)\nfor_each -nthreads 8 -info */dwi : dwibiascorrect ants dwi_den_preproc.mif dwi_den_preproc_unbiased.mif -bias bias.mif \n\n# Create a mask for future processing steps\nfor_each -nthreads 8 -info */dwi : dwi2mask dwi_den_preproc_unbiased.mif mask.mif \n\n########################### STEP 2 ###################################\n#             Basis function for each tissue type                    #\n######################################################################\n\n# Create a basis function from the subject's DWI data. The \"dhollander\" function is best used for multi-shell acquisitions; it will estimate different basis functions for each tissue type. For single-shell acquisition, use the \"tournier\" function instead\nfor_each -nthreads 8 -info */dwi : dwi2response dhollander dwi_den_preproc_unbiased.mif wm.txt gm.txt csf.txt -voxels voxels.mif \n\n# Performs multishell-multitissue constrained spherical deconvolution, using the basis functions estimated above\nfor_each -nthreads 8 -info */dwi : dwi2fod msmt_csd dwi_den_preproc_unbiased.mif -mask mask.mif wm.txt wmfod.mif gm.txt gmfod.mif csf.txt csffod.mif \n\n# Creates an image of the fiber orientation densities overlaid onto the estimated tissues (Blue=WM; Green=GM; Red=CSF)\n# You should see FOD's mostly within the white matter. These can be viewed later with the command \"mrview vf.mif -odf.load_sh wmfod.mif\"\nfor_each -nthreads 8 -info */dwi : mrconvert -coord 3 0 wmfod.mif - \\| mrcat csffod.mif gmfod.mif - vf.mif \n\n# Now normalize the FODs to enable comparison between subjects\nfor_each -nthreads 8 -info */dwi : mtnormalise wmfod.mif wmfod_norm.mif gmfod.mif gmfod_norm.mif csffod.mif csffod_norm.mif -mask mask.mif \n\n########################### STEP 3 ###################################\n#            Create a GM/WM boundary for seed analysis               #\n######################################################################\n\n# Convert the anatomical image to .mif format, and then extract all five tissue catagories (1=GM; 2=Subcortical GM; 3=WM; 4=CSF; 5=Pathological tissue)\nfor_each -nthreads 8 -info */dwi : mrconvert ../anat/*T1w.nii.gz T1.mif \nfor_each &lt;nproc --all&gt;/8 -info */dwi : 5ttgen fsl T1.mif 5tt_nocoreg.mif -nthreads 8 \n\n# The following series of commands will take the average of the b0 images (which have the best contrast), convert them and the 5tt image to NIFTI format, and use it for coregistration.\nfor_each -nthreads 8 -info */dwi : dwiextract dwi_den_preproc_unbiased.mif - -bzero \\| mrmath - mean mean_b0_processed.mif -axis 3 \nfor_each -nthreads 8 -info */dwi : mrconvert mean_b0_processed.mif mean_b0_processed.nii.gz \nfor_each -nthreads 8 -info */dwi : mrconvert 5tt_nocoreg.mif 5tt_nocoreg.nii.gz \n\n# Uses FSL commands fslroi and flirt to create a transformation matrix for regisitration between the tissue map and the b0 images\nfor_each -nthreads 8 -info */dwi : fslroi 5tt_nocoreg.nii.gz 5tt_vol0.nii.gz 0 1 #Extract the first volume of the 5tt dataset (since flirt can only use 3D images, not 4D images)\nfor_each -nthreads 8 -info */dwi : flirt -in mean_b0_processed.nii.gz -ref 5tt_vol0.nii.gz -interp nearestneighbour -dof 6 -omat diff2struct_fsl.mat\nfor_each -nthreads 8 -info */dwi : transformconvert diff2struct_fsl.mat mean_b0_processed.nii.gz 5tt_nocoreg.nii.gz flirt_import diff2struct_mrtrix.txt \nfor_each -nthreads 8 -info */dwi : mrtransform 5tt_nocoreg.mif -linear diff2struct_mrtrix.txt -inverse 5tt_coreg.mif \n\n#Create a seed region along the GM/WM boundary\nfor_each -nthreads 8 -info */dwi : 5tt2gmwmi 5tt_coreg.mif gmwmSeed_coreg.mif\n\n\nSTEP 2. Streamline generation\nMake sure to allocate at least 5Go of space for each subject on your local disk as streamline generation can get quite heavy. Here we generate 10 millions streamlines and then reduce that number using the tckgen and tcksift2 command.\n#!/bin/bash\n\n########################## STEP 4 ###################################\n#                 Run the streamline analysis                        #\n######################################################################\n\n# Create streamlines\n# Note that the \"right\" number of streamlines is still up for debate. Last I read from the MRtrix documentation,\n# They recommend about 100 million tracks. Here I use 10 million, if only to save time. Read their papers and then make a decision\nfor_each -nthreads &lt;nproc --all&gt;/8 -info */dwi : tckgen -act 5tt_coreg.mif -backtrack -seed_gmwmi gmwmSeed_coreg.mif -nthreads 8 -maxlength 250 -cutoff 0.06 -select 10000k wmfod_norm.mif tracks_10M.tck \n\n# Extract a subset of tracks (here, 200 thousand) for ease of visualization\n# tckedit tracks_10M.tck -number 200k smallerTracks_200k.tck\n\n# Reduce the number of streamlines with tcksift\nfor_each -nthreads &lt;nproc --all&gt;/8 -info */dwi : tcksift2 -act 5tt_coreg.mif -out_mu sift_mu.txt -out_coeffs sift_coeffs.txt -nthreads 8 tracks_10M.tck wmfod_norm.mif sift_1M.txt \n\n\nSTEP 3. Recon-all\nCheck the parallel processing section to speed up this step using parallel computing.\n\n\nSTEP 4. Generate the Structural Connectome (SC)\n#!/bin/bash\n\nfor_each -nthreads &lt;nproc --all&gt; -info */dwi : mrconvert –datatype uint32 hcpmmp1.mgz  hcpmmp1.mif -force\n\n# Replace the random integers of the hcpmmp1.mif file with integers\n# that start at 1 and increase by 1.\nfor_each -nthreads &lt;nproc --all&gt; -info */dwi : labelconvert hcpmmp1.mif $MRtrix3/share/mrtrix3/labelconvert/hcpmmp1_original.txt $MRtrix3/share/mrtrix3/labelconvert/hcpmmp1_ordered.txt hcpmmp1_parcels_nocoreg.mif -force\n\n# Register the ordered atlas-based volumetric parcellation to diffusion space.\nfor_each -nthreads &lt;nproc --all&gt; -info */dwi : mrtransformhcpmmp1_parcels_nocoreg.mif –lineardiff2struct_mrtrix.txt –inverse –datatype uint32  hcpmmp1_parcels_coreg.mif -force\n\n# Create a whole-brain connectome, representing the streamlines between each parcellation pair in the atlas (in this case, 379x379). The \"symmetric\" option will make the lower diagonal the same as the upper diagonal, and the \"scale_invnodevol\" option will scale the connectome by the inverse of the size of the node\n\nfor_each -nthreads &lt;nproc --all&gt; -info * : tck2connectome -symmetric -zero_diagonal -scale_invnodevol -tck_weights_in dwi/sift_1M.txt dwi/tracks_10M.tck dwi/hcpmmp1_parcels_coreg.mif dwi/IN_hcpmmp1_parcels_coreg.csv -out_assignment dwi/assignments_IN_hcpmmp1_parcels_coreg.csv -force\nYou can then copy and save the structural connectomes wherever you like:\nfind . -name \\sub-*.csv -exec cp {} /path/to/where you want to save the SC \\;"
  },
  {
    "objectID": "content/guide/DTI/setup_lin.html",
    "href": "content/guide/DTI/setup_lin.html",
    "title": "Setup (Linux)",
    "section": "",
    "text": "The pipeline revolves around MRtrix3 which works hand in hand with Freesurfer, FSL, and ANTs\n\n\nDownload MRtrix3 by copy pasting this command in a bash terminal:\nconda install -c mrtrix3 mrtrix3\nIf everything went fine, you should now see a window pop up when typing mrview on the command line.\n\n\n\n\nIn your “HOME” directory (cd $HOME), download the Freesurfer installer package:\nwget https://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/7.4.1/freesurfer-linux-ubuntu22_amd64-7.4.1.tar.gz\nInstall it\ntar -zxpf freesurfer-linux-ubuntu22_amd64-7.4.1.tar.gz\nAdd this to your PATH\necho \"export FREESURFER_HOME=$HOME/freesurfer\" &gt;&gt; .bashrc\nsource \"$FREESURFER_HOME/SetUpFreeSurfer.sh\"\" &gt;&gt; .bashrc\nGet the free license online, download it in your home directory and add this command in your .bashrc:\nexport FS_LICENSE=$HOME/license.txt\n\n\n\n\n\nDownload the FSL installer script online. When selecting the OS to install on the download page, make sure to select Ubuntu and not Windows.\nRun the installer\npython3 \"fslinstaller.py\"\nAdd this to your PATH\nFSLDIR=$HOME/path/to/fsl\nPATH=${FSLDIR}/share/fsl/bin:${PATH}\nexport FSLDIR PATH\n. ${FSLDIR}/etc/fslconf/fsl.sh\n\n\n\n\n\nDownload the ANTs installer script\nIn the terminal, enter:\nbash installANTs.sh\nAdd it to your PATH\necho \"ANTSPATH=$HOME/install/bin/\" &gt;&gt; $HOME/.bashrc \necho \"export PATH=${ANTSPATH}:$PATH\" &gt;&gt; $HOME/.bashrc"
  },
  {
    "objectID": "content/guide/DTI/setup_lin.html#software-installation",
    "href": "content/guide/DTI/setup_lin.html#software-installation",
    "title": "Setup (Linux)",
    "section": "",
    "text": "The pipeline revolves around MRtrix3 which works hand in hand with Freesurfer, FSL, and ANTs\n\n\nDownload MRtrix3 by copy pasting this command in a bash terminal:\nconda install -c mrtrix3 mrtrix3\nIf everything went fine, you should now see a window pop up when typing mrview on the command line.\n\n\n\n\nIn your “HOME” directory (cd $HOME), download the Freesurfer installer package:\nwget https://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/7.4.1/freesurfer-linux-ubuntu22_amd64-7.4.1.tar.gz\nInstall it\ntar -zxpf freesurfer-linux-ubuntu22_amd64-7.4.1.tar.gz\nAdd this to your PATH\necho \"export FREESURFER_HOME=$HOME/freesurfer\" &gt;&gt; .bashrc\nsource \"$FREESURFER_HOME/SetUpFreeSurfer.sh\"\" &gt;&gt; .bashrc\nGet the free license online, download it in your home directory and add this command in your .bashrc:\nexport FS_LICENSE=$HOME/license.txt\n\n\n\n\n\nDownload the FSL installer script online. When selecting the OS to install on the download page, make sure to select Ubuntu and not Windows.\nRun the installer\npython3 \"fslinstaller.py\"\nAdd this to your PATH\nFSLDIR=$HOME/path/to/fsl\nPATH=${FSLDIR}/share/fsl/bin:${PATH}\nexport FSLDIR PATH\n. ${FSLDIR}/etc/fslconf/fsl.sh\n\n\n\n\n\nDownload the ANTs installer script\nIn the terminal, enter:\nbash installANTs.sh\nAdd it to your PATH\necho \"ANTSPATH=$HOME/install/bin/\" &gt;&gt; $HOME/.bashrc \necho \"export PATH=${ANTSPATH}:$PATH\" &gt;&gt; $HOME/.bashrc"
  },
  {
    "objectID": "content/guide/rs-fMRI/rs-fMRI.html",
    "href": "content/guide/rs-fMRI/rs-fMRI.html",
    "title": "Resting-state functional magnetic resonance (rs-fMRI)",
    "section": "",
    "text": "The pipeline is run primarily with Matlab\n\nDownload SPM by copy pasting this command in a bash terminal\nDownload CONN by copy pasting this command in a bash terminal\nDownload GraphVar"
  },
  {
    "objectID": "content/guide/rs-fMRI/rs-fMRI.html#software-installation",
    "href": "content/guide/rs-fMRI/rs-fMRI.html#software-installation",
    "title": "Resting-state functional magnetic resonance (rs-fMRI)",
    "section": "",
    "text": "The pipeline is run primarily with Matlab\n\nDownload SPM by copy pasting this command in a bash terminal\nDownload CONN by copy pasting this command in a bash terminal\nDownload GraphVar"
  },
  {
    "objectID": "content/guide/rs-fMRI/rs-fMRI.html#preprocessing-automation",
    "href": "content/guide/rs-fMRI/rs-fMRI.html#preprocessing-automation",
    "title": "Resting-state functional magnetic resonance (rs-fMRI)",
    "section": "Preprocessing automation",
    "text": "Preprocessing automation"
  },
  {
    "objectID": "content/guide/rs-fMRI/rs-fMRI.html#automating-conn-roi-to-roi-analysis",
    "href": "content/guide/rs-fMRI/rs-fMRI.html#automating-conn-roi-to-roi-analysis",
    "title": "Resting-state functional magnetic resonance (rs-fMRI)",
    "section": "Automating CONN ROI-to-ROI analysis",
    "text": "Automating CONN ROI-to-ROI analysis"
  },
  {
    "objectID": "content/research.html",
    "href": "content/research.html",
    "title": "Research",
    "section": "",
    "text": "PhD project:\nCognitive neuroscience is undergoing a paradigm shift. The abundance of multimodal empirical data, coupled with the unprecendented computational capabilities, is helping to redefine the links between the brain and human behavior. The brain is now understood as a vast network of interactions between cerebral regions from which cognitive operations and processes emerge.\nSpecifically, language functions (L) are not isolated but constantly interact with declarative memory (M) and executive functions (EF). However, the neural mechanisms underlying this L-M-EF dynamic remain unclear. The cognitomic perspective (structure-function-cognition) is closely linked to the identification of multimodal L-M-EF phenotypes, that is the neuropsychological implications that the language connectomic architecture places on cognition.\nThus, this project has:\n\na theoretical dimension, through the enrichment of a neurocognitive L-M-EF model\na methodological dimension, through the fusion of multimodal data required to evaluate this model (i.e. structural, functional, cognitive-behavioral)\n\nIn fine, we expect this project to enable significant advances in both fundamental and clinical research (e.g. pre-habilitation & cognitive rehabilitation).\n\nLatest:\n\nIn our latest preprint (Guichet et al. 2023), we modeled the neural mechanisms that uphold inter-cognitive functioning across the lifespan. The SENECA model has three dimensions:\n\n\n\n\n\n\n\nAt the cognitive level (CA), we show that language is not isolated but works in synergy with LTM and EF across the lifespan\nAt the cerebral level (SE), we show that DMN-FPN coupling is essential to mitigate cognitive decline, achieving an optimal balance between the cost of reorganization of neural connections and the cognitive efficiency.\nTaken together (SE-NE-CA), less DMN-FPN coupling may be responsible for a transition around 50yo towards less synergistic processing, accelerating cognitive decline in highly synergistic tasks such as lexical production.\n\n\n\nDMN-FPN coupling is associated with a Nonlinear and Emergent trajectory across the lifespan\n\n\n\n\nWhat’s next?\nWe are now investigating the structural underpinnings of the DMN-FPN coupling across the lifespan and whether SC-FC coupling can be a reliable biomarker of individuals with high vs. low cognitive reserve, thus predicting healthy cognitive aging.\n\n\nPublications:\n(Ashokumar et al. 2022)\n\n\n\n\n\nReferences\n\nAshokumar, Monica, Clément Guichet, Jean-Luc Schwartz, and Takayuki Ito. 2022. “Correlation Between the Effect of Orofacial Somatosensory Inputs in Speech Perception and Speech Production Performance.” Auditory Perception & Cognition, October, 1–11. https://doi.org/10.1080/25742442.2022.2134674.\n\n\nGuichet, Clément, Sonja Banjac, Martial Mermillod, Sophie Achard, and Monica Baciu. 2023. “Modeling the Neurocognitive Dynamics of Language Across the Lifespan.” Preprint. Neuroscience. https://doi.org/10.1101/2023.07.04.547510."
  }
]