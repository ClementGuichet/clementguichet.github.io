[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "This site hosts documentation to preprocess and analyze structural (DTI), and functional (rs-fMRI) data with the latest tools available. For any inquiry, please contact me at: guichetc@univ-grenoble-alpes.fr"
  },
  {
    "objectID": "content/guide/rs-fMRI/spm.html",
    "href": "content/guide/rs-fMRI/spm.html",
    "title": "SPM12",
    "section": "",
    "text": "SPM standard pipeline\nYou can download the batch matlab script here. The preprocessing pipeline entails:\n\nRealignement & Slice timing\nCo-registration of the T1w image to the mean image created by the realignement procedure\nSegmentation\nNormalization\nSmoothing (6mm FWHM Gaussian kernel)\n\n\n\nART\nMotion parameters from the realignment are evaluated with ART (Artifact Detection Tool; Massachusetts Institute of Technology) to detect outlying volumes:\n\nInterscan movement threshold of 3 mm in translation, 0.02 rad in rotation\nGlobal interscan signal intensity of 3 SD relative to the session mean.\nIndividuals with 10% of more outlying volumes can be considered outliers"
  },
  {
    "objectID": "content/guide/rs-fMRI/conn.html",
    "href": "content/guide/rs-fMRI/conn.html",
    "title": "CONN",
    "section": "",
    "text": "Following the standard preprocessing pipeline, the CONN toolbox (Whitfield-Gabrieli and Nieto-Castanon 2012) takes care of the FC generation after denoising (Behzadi et al. 2007). This is an add-on to SPM that can be downloaded here.\n\nSTEP 1. Importing the data into a new CONN project\nThis script will create a new conn project named conn_example and automatically import the functional and structural volumes for the set number of subjects.\n% Created by Andrew Jahn, University of Michigan, 02.27.2020\n% Adapted by Clément Guichet, UGA, LPNC, 07.01.2023\n\n% FIND functional/structural files\nNSUBJECTS= ??;\ncwd=pwd;\n\n# the smoothed out spatially preprocessed volumes, conn will automatically bind them to the unsmoothed ones\nFUNCTIONAL_FILE=cellstr(conn_dir('swar*.nii'));\nSTRUCTURAL_FILE=cellstr(conn_dir('wm*.nii'));\nif rem(length(FUNCTIONAL_FILE),NSUBJECTS),error('mismatch number of functional files %n', length(FUNCTIONAL_FILE));end\nif rem(length(STRUCTURAL_FILE),NSUBJECTS),error('mismatch number of anatomical files %n', length(FUNCTIONAL_FILE));end\nnsessions=length(FUNCTIONAL_FILE)/NSUBJECTS;\nFUNCTIONAL_FILE=reshape(FUNCTIONAL_FILE,[nsessions, NSUBJECTS]);\nSTRUCTURAL_FILE={STRUCTURAL_FILE{1:NSUBJECTS}};\ndisp([num2str(size(FUNCTIONAL_FILE,1)),' sessions']);\ndisp([num2str(size(FUNCTIONAL_FILE,2)),' subjects']);\nTR= ??; % Repetition time\n\n\n% CONN-SPECIFIC SECTION: RUNS SETUP STEPS\n% Prepares batch structure\nclear batch;\nbatch.filename=fullfile(cwd,'conn_example.mat'); % New conn_*.mat experiment name\n\n% SETUP step\nbatch.Setup.isnew=1;\nbatch.Setup.nsubjects=NSUBJECTS;\nbatch.Setup.RT=TR; % TR (seconds)\n\nbatch.Setup.functionals=repmat({{}},[NSUBJECTS,1]); % Pre-allocation\n% Point to functional volumes for each subject/session\nfor nsub=1:NSUBJECTS\n    for nses=1:nsessions\n        batch.Setup.functionals{nsub}{nses}{1}=FUNCTIONAL_FILE{nses,nsub};\n    end\nend \nbatch.Setup.structurals=STRUCTURAL_FILE; % Point to anatomical volumes for each subject\n\n\n% Define the names and files for the covariates\ncovariate_names = {'Art_outliers_&_movement'};\nART_FILE = cellstr(conn_dir('art_regression_outliers_and_movement_warRS.mat'));\nncovariate=length(ART_FILE)/NSUBJECTS;\nART_FILE = reshape(ART_FILE, [ncovariate, NSUBJECTS]);\ndisp([num2str(size(ART_FILE,1)),'covariate']);\ndisp([num2str(size(ART_FILE,2)),'subjects']);\n\n% Add covariates\nbatch.Setup.covariates.add=1;\nbatch.Setup.covariates.names=covariate_names; \nfor ncov=1:ncovariate\n    for nsub=1:NSUBJECTS\n        for nses=1:nsessions\n            batch.Setup.covariates.files{ncov}{nsub}{nses}{1}=ART_FILE{nses,nsub,ncov}; \n        end \n    end\nend\n\n\n% Run all analyses\nconn_batch(batch);\n\n\nSTEP 2. Running CONN in the GUI\nAfter creating the project, you can open the gui by typing:\nconn\nconn('load', fullfile(cwd, 'conn_example.mat'))\nIf the project does not load up, you can open the mat file in the GUI.\n\nAtlas selection & Denoising\n\nCheck that the structural and functional volumes have all been imported correctly.\nIn the ROIs field, remove the default atlas if there is one and import yours in NIFTI format.\nCheck the ‘Atlas file’ box.\n\nIn the Options field, enable ROI-to-ROI analyses only.\n\nClick done. This may take up a few hours depending on the cohort size.\nBy default, CONN includes regressors derived from the tissue types you generated in the ROIs section (WM, CSF) of the Setup tab, and the 1st-level covariates of the Setup tab (Art_mvt). You can leave the default settings and proceed to the 1st-level analyses by clicking done.\n\n\n\n\nGenerate the Functional Connectome (FC)\n\nCreate a new analysis and select RRC (ROI-to-ROI connectivity).\nSelect the brain regions to be included in the connectome.\n\nClick done to generate the .mat file. Under the path /conn_example/results/firstlevel/RRC, you should now visualize the .mat files for each subject.\n\n\n\n\n\n\n\n\nReferences\n\nBehzadi, Yashar, Khaled Restom, Joy Liau, and Thomas T. Liu. 2007. “A Component Based Noise Correction Method (CompCor) for BOLD and Perfusion Based fMRI.” NeuroImage 37 (1): 90–101. https://doi.org/10.1016/j.neuroimage.2007.04.042.\n\n\nWhitfield-Gabrieli, Susan, and Alfonso Nieto-Castanon. 2012. “Conn : A Functional Connectivity Toolbox for Correlated and Anticorrelated Brain Networks.” Brain Connectivity 2 (3): 125–41. https://doi.org/10.1089/brain.2012.0073."
  },
  {
    "objectID": "content/guide/DTI/setup_win.html",
    "href": "content/guide/DTI/setup_win.html",
    "title": "Setup (Windows)",
    "section": "",
    "text": "Check that WSL2 is running by typing this command in PowerShell:\n  wsl -l -v \n# You should see something like this\n  NAME                   STATE           VERSION\n  Ubuntu-22.04           Running         2\n  \n# If you have WSL1, you can update to WSL2 by typing \n  wsl --set-default-version 2 wsl --set-version Ubuntu-22.04 2\nOtherwise, you can install Ubuntu by pasting the following commands:\n1. Enable WSL by opening PowerShell as administrator\n    wsl --install -d Ubuntu-22.04\n2. Restart your computer\n3. Start the Ubuntu app to open a Ubuntu shell\n4. Set up a username and password\nYou’ll also need to GUI for WSL. I recommend you install VcXsrv on your system, which is a free X-sever on Windows. After downloading and installing VcXsrv with default options, run Xlaunch (which gets installed automatically) and perform the following configuration:\n\nDisplay setting: select multiple windows option\nClient startup: check the Start no client option\nExtra setting: make sure “Disable access control” is enabled and “native opengl” is disabled\nAdd this to your .bashrc file:\n echo \"export DISPLAY=$(grep nameserver /etc/resolv.conf  | awk '{print $2; exit}'):0\" &gt;&gt; ~/.bashrc\n echo \"export LIBGL_ALWAYS_INDIRECT=0\" &gt;&gt; ~/.bashrc\n # For Windows 11 users, add this as well\n  echo \"export LIBGL_ALWAYS_SOFTWARE=1\" &gt;&gt; ~/.bashrc\nTry running glxgears. A window with three spinning gears should open.\nTroubleshooting:\n\nMake sure you are not using a VPN.\nGo to Control panel &gt; System and security &gt; Windows defender firewall &gt; Advanced settings &gt; Inbound rules and make sure that the VcXsrv rules are not set to block - if they are you will need to edit the VcXsrv rule and change it from block to allow."
  },
  {
    "objectID": "content/guide/DTI/setup_win.html#os",
    "href": "content/guide/DTI/setup_win.html#os",
    "title": "Setup (Windows)",
    "section": "",
    "text": "Check that WSL2 is running by typing this command in PowerShell:\n  wsl -l -v \n# You should see something like this\n  NAME                   STATE           VERSION\n  Ubuntu-22.04           Running         2\n  \n# If you have WSL1, you can update to WSL2 by typing \n  wsl --set-default-version 2 wsl --set-version Ubuntu-22.04 2\nOtherwise, you can install Ubuntu by pasting the following commands:\n1. Enable WSL by opening PowerShell as administrator\n    wsl --install -d Ubuntu-22.04\n2. Restart your computer\n3. Start the Ubuntu app to open a Ubuntu shell\n4. Set up a username and password\nYou’ll also need to GUI for WSL. I recommend you install VcXsrv on your system, which is a free X-sever on Windows. After downloading and installing VcXsrv with default options, run Xlaunch (which gets installed automatically) and perform the following configuration:\n\nDisplay setting: select multiple windows option\nClient startup: check the Start no client option\nExtra setting: make sure “Disable access control” is enabled and “native opengl” is disabled\nAdd this to your .bashrc file:\n echo \"export DISPLAY=$(grep nameserver /etc/resolv.conf  | awk '{print $2; exit}'):0\" &gt;&gt; ~/.bashrc\n echo \"export LIBGL_ALWAYS_INDIRECT=0\" &gt;&gt; ~/.bashrc\n # For Windows 11 users, add this as well\n  echo \"export LIBGL_ALWAYS_SOFTWARE=1\" &gt;&gt; ~/.bashrc\nTry running glxgears. A window with three spinning gears should open.\nTroubleshooting:\n\nMake sure you are not using a VPN.\nGo to Control panel &gt; System and security &gt; Windows defender firewall &gt; Advanced settings &gt; Inbound rules and make sure that the VcXsrv rules are not set to block - if they are you will need to edit the VcXsrv rule and change it from block to allow."
  },
  {
    "objectID": "content/guide/DTI/setup_win.html#software-installation",
    "href": "content/guide/DTI/setup_win.html#software-installation",
    "title": "Setup (Windows)",
    "section": "Software installation",
    "text": "Software installation\nThe pipeline revolves around MRtrix3 which works hand in hand with Freesurfer, FSL, and ANTs\n\nMRtrix3\nDownload MRtrix3 by copy pasting this command in a bash terminal:\n# Clone the MRtrix3 repo\ngit clone https://github.com/MRtrix3/mrtrix3.git\n# Configure the install\ncd mrtrix3\n./configure\n# Build the binaries\n./build\n# Add it to your path\n./set_path\nIf you get an error, you can try with conda:\n# If conda has been installed in /root, you may need to enter:\nsudo chown -R $USER:$USER miniconda3\n\nconda install -c mrtrix3 mrtrix3\nType an MRtrix3 command like mrconvert to check everything’s working correctly.\nAdd MRtrix3 to your PATH:\necho \"export MRtrix3=/path/to/miniconda3/pkgs/mrtrix3-3.0.4-h2bc3f7f_0/share/mrtrix3\" &gt;&gt; .bashrc\necho \"export PATH=${MRtrix3}:$PATH\" &gt;&gt; .bashrc\n\n\nFreesurfer\n\nIn your “HOME” directory (cd $HOME), download the Freesurfer installer package:\nwget https://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/7.4.1/freesurfer_ubuntu22-7.4.1_amd64.deb\nMake sure to install the Freesurfer distribution under the path /usr/local/freesurfer/7.4.1\ncd /usr/local\nsudo apt-get -y install ./freesurfer_ubuntu22-7.4.1_amd64.deb\nAdd it to your PATH\necho \"export FREESURFER_HOME=/usr/local/freesurfer/7.4.1\" &gt;&gt; $HOME/.bashrc\nGet the free license online, download it in your home directory and add this command in your .bashrc:\nexport FS_LICENSE=$HOME/license.txt\nSet the Freesurfer env to be setup when you open the shell:\necho \"source $FREESURFER_HOME/SetUpFreeSurfer.sh\" &gt;&gt; $HOME/.bashrc\n\nOpen a new Ubuntu linux terminal window and verify you see the following output showing the Freesurfer environment has been set. If everything went fine, you should see this output:\n - - - - - - - -freesurfer-linux-ubuntu22_x86_64-7.4.1-20230614-7eb8460- - - - - - - -\nSetting up environment for FreeSurfer/FS-FAST (and FSL)\nFREESURFER_HOME   /usr/local/freesurfer/7.4.1\nFSFAST_HOME       /usr/local/freesurfer/7.4.1/fsfast\nFSF_OUTPUT_FORMAT nii.gz\nSUBJECTS_DIR      /usr/local/freesurfer/7.4.1/subjects\nMNI_DIR           /usr/local/freesurfer/7.4.1/mni\n\n\nFSL\n\nDownload the FSL installer script online. When selecting the OS to install on the download page, make sure to select Ubuntu and not Windows.\nRun the installer script by replacing &lt;UserName&gt; with your windows user name. Make sure to install it under the path /usr/local/fsl/.\npython3 \"fslinstaller.py\"\n\n\n\nANTs\n\nDownload the ANTs installer script\nIn the terminal, enter:\nbash installANTs.sh\nAdd it to your PATH\necho \"ANTSPATH=$HOME/install/bin/\" &gt;&gt; $HOME/.bashrc\necho \"export PATH=${ANTSPATH}:$PATH\" &gt;&gt; $HOME/.bashrc"
  },
  {
    "objectID": "content/guide/DTI/parallel.html",
    "href": "content/guide/DTI/parallel.html",
    "title": "Parallel computing",
    "section": "",
    "text": "Install Homebrew with the following command and add it to your PATH:\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\ntest -d ~/.linuxbrew && eval \"$(~/.linuxbrew/bin/brew shellenv)\"\ntest -d /home/linuxbrew/.linuxbrew && eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\"\ntest -r ~/.bash_profile && echo \"eval \\\"\\$($(brew --prefix)/bin/brew shellenv)\\\"\" &gt;&gt; ~/.bash_profile\necho \"eval \\\"\\$($(brew --prefix)/bin/brew shellenv)\\\"\" &gt;&gt; ~/.profile\nThen install gcc and parallel:\nbrew install gcc\nbrew install parallel"
  },
  {
    "objectID": "content/guide/DTI/parallel.html#software-installation",
    "href": "content/guide/DTI/parallel.html#software-installation",
    "title": "Parallel computing",
    "section": "",
    "text": "Install Homebrew with the following command and add it to your PATH:\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\ntest -d ~/.linuxbrew && eval \"$(~/.linuxbrew/bin/brew shellenv)\"\ntest -d /home/linuxbrew/.linuxbrew && eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\"\ntest -r ~/.bash_profile && echo \"eval \\\"\\$($(brew --prefix)/bin/brew shellenv)\\\"\" &gt;&gt; ~/.bash_profile\necho \"eval \\\"\\$($(brew --prefix)/bin/brew shellenv)\\\"\" &gt;&gt; ~/.profile\nThen install gcc and parallel:\nbrew install gcc\nbrew install parallel"
  },
  {
    "objectID": "content/guide/DTI/parallel.html#using-the-parallel-command",
    "href": "content/guide/DTI/parallel.html#using-the-parallel-command",
    "title": "Parallel computing",
    "section": "Using the parallel command",
    "text": "Using the parallel command\nParallel is run by piping the ls command into the parallel command:\nNPROC=$(nproc)\n\nls *.nii | parallel --jobs $NPROC recon-all -s {.}_recon -i {} -all\n--jobs NPROC indicates that NPROC cores will be used to analyze the data and that each instance of recon-all will be assigned to a different core.\nThe full bash script consists in copying the T1.nii.gz images in the new directory (/FS), unzip them, run and store the output of recon-all in this directory. Then, we move the newly created recon directory into freesurfer’s $SUBJECTS_DIR.\n#!/bin/bash\n\n# Assuming you are in the raw_data directory which lists all the subjects folders\nmkdir FS\n\n# grab the list of subject name\nls . | grep ^sub- &gt; subjList.txt\n\n# Path to the anatomical T1 image\nfor sub in `cat subjList.txt`; do\n    cp ./${sub}/anat/${sub}_T1w.nii.gz ./FS\ndone\n\ncd FS\n\n# Unzip\ngunzip *.gz\n\n# Story output in the current directory\n# This avoids permission error\nSUBJECTS_DIR=`pwd`\n\nls *.nii | parallel --jobs $NPROC recon-all -s {.}_recon -i {} -all\n# Remove the copied T1.nii.gz files\nrm *.nii\n\n# Move into freesurfer's subjects directory. Substitute &lt;password&gt; for your UNIX password\necho &lt;password&gt; | sudo -S mv *recon $SUBJECTS_DIR\n# Grant permission to write the file\necho &lt;password&gt; | sudo -S chmod -R a+w $FREESURFER_HOME\nYou can then carry on with mapping the glasser annotation file:\n################################################################\n# For the command \"mri_aparc2aseg\", there can be an error which is due to the way multithreading is handled. Just rerun the command manually for the subjects which did not have an output hcpmmp1.mgz\n# You can find these subjects by typing \"find . -name *.mgz\" in a terminal in the directory that contains all your subjects folders\n################################################################\n\n# Map the annotation files of the HCP MMP 1.0 atlas from fsaverage to you rsubject for both hemispheres:\n\nls . | grep ^sub- &gt; subjList.txt\n\nfor sub in `cat subjList.txt`; do\n  # Left hemisphere\n  mri_surf2surf --srcsubject fsaverage --trgsubject ${sub}_recon --hemi lh --sval-annot $SUBJECTS_DIR/fsaverage/label/lh.hcpmmp1.annot --tval $SUBJECTS_DIR/${sub}_T1w_recon/label/lh.hcpmmp1.annot\n\n  # Right hemisphere\n  mri_surf2surf --srcsubject fsaverage --trgsubject ${sub}_recon --hemi rh --sval-annot $SUBJECTS_DIR/fsaverage/label/rh.hcpmmp1.annot --tval $SUBJECTS_DIR/${sub}_T1w_recon/label/rh.hcpmmp1.annot\n  \n  cd ./{sub}/dwi\n  mri_aparc2aseg --old-ribbon --s ${sub}_recon --annot hcpmmp1 --o ${sub}/dwi/hcpmmp1.mgz --nthreads $NPROC/2\n  cd ../..\n  \ndone"
  },
  {
    "objectID": "content/guide/DTI/DTI_batch.html",
    "href": "content/guide/DTI/DTI_batch.html",
    "title": "Diffusion Tensor Imaging (DTI) - Batch processing",
    "section": "",
    "text": "Below, I provide a synthesis of the preprocessing steps using the for_each command available on MRtrix3. The full script is available for download at the bottom (see Download)."
  },
  {
    "objectID": "content/guide/DTI/DTI_batch.html#download",
    "href": "content/guide/DTI/DTI_batch.html#download",
    "title": "Diffusion Tensor Imaging (DTI) - Batch processing",
    "section": "Download",
    "text": "Download\nYou can download the full preprocessing script here and run it by typing this command in the folder that contains your subject’s data:\nbash batch_full_preproc.sh\nBefore running the script, open it and change the following parameters:\n\ndwifslpreproc: check your json file for the PhaseEncodingDirection (-pe_dir), the total readout time. More information on MRtrix3 documentation.\nIf you wish to generate a connectome with HCP regions, make sure you’ve downloaded the lh and rh.hcpmmp1 annot files in the supplementary files here and put them into $SUBJECTS_DIR/fsaverage/label (see also Recon-all with parallel computing)."
  },
  {
    "objectID": "content/about.html",
    "href": "content/about.html",
    "title": "About",
    "section": "",
    "text": "I’m a 2nd-year PhD Student in Cognitive and Computational Neuroscience at LPNC, CNRS UMR 5105, UGA, Grenoble, France. My research project is about modeling how our brain reorganizes across the lifespan to preserve optimal cognitive (language) performances. Find out more about our team LPNC-LANG here."
  },
  {
    "objectID": "content/about.html#education",
    "href": "content/about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\nPhD candidate (2022-2025) | LPNC, UGA | Supervised by Prof. Monica Baciu and Prof. Martial Mermillod\nMSc degree in Research in Psychology (2020-2022) | LPNC, UGA | Master theses in psycholinguistics supervised by Prof. Elsa Spinelli and Prof. Boris New\nBachelor’s degree in Psychology (2017-2020) | UGA"
  },
  {
    "objectID": "content/about.html#experience",
    "href": "content/about.html#experience",
    "title": "About",
    "section": "Experience",
    "text": "Experience\nCo-analyst & Peer-reviewer (April 2022 - ongoing) | Center of Open Science (COS) | Multi100 project\nCNRS Individual contractor (Sept 2021 - March 2022 incl.) | GIPSA-lab, UGA | Supervised by Takayuki Ito\nCNRS Research intern (June - Aug 2021 incl.) | GIPSA-lab, UGA | Supervised by Takayuki Ito and Jean-Luc Schwartz"
  },
  {
    "objectID": "content/guide/DTI/DTI_single.html",
    "href": "content/guide/DTI/DTI_single.html",
    "title": "Diffusion Tensor Imaging (DTI) - Single subject",
    "section": "",
    "text": "I recommend you check Andrew Jahn’s book for a thorough walk-through DTI analysis with MRtrix3. The full script is available for download at the bottom (see Download)."
  },
  {
    "objectID": "content/guide/DTI/DTI_single.html#download",
    "href": "content/guide/DTI/DTI_single.html#download",
    "title": "Diffusion Tensor Imaging (DTI) - Single subject",
    "section": "Download",
    "text": "Download\nYou can download the full preprocessing script here and run it by typing this command in the folder that contains your subject’s data:\nbash single_subj_full_preproc.sh\nBefore running the script, open it and change the following parameters:\n\ndwifslpreproc: check your json file for the PhaseEncodingDirection (-pe_dir), the total readout time. More information on MRtrix3 documentation.\nIf you wish to generate a connectome with HCP regions, make sure you’ve downloaded the lh and rh.hcpmmp1 annot files in the supplementary files here and put them into $SUBJECTS_DIR/fsaverage/label (see also STEP 3. Recon-all)."
  },
  {
    "objectID": "content/guide/DTI/setup_lin.html",
    "href": "content/guide/DTI/setup_lin.html",
    "title": "Setup (Linux)",
    "section": "",
    "text": "The pipeline revolves around MRtrix3 which works hand in hand with Freesurfer, FSL, and ANTs\n\n\nDownload MRtrix3 by copy pasting this command in a bash terminal:\nconda install -c mrtrix3 mrtrix3\nType an MRtrix3 command like mrconvert to check everything’s working correctly.\nAdd MRtrix3 to your PATH:\necho \"export MRtrix3=/path/to/miniconda3/share/mrtrix3\" &gt;&gt; .bashrc \necho \"export PATH=${MRtrix3}:$PATH\" &gt;&gt; .bashrc\n\n\n\n\nIn your “HOME” directory (cd $HOME), download the Freesurfer installer package:\nwget https://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/7.4.1/freesurfer-linux-ubuntu22_amd64-7.4.1.tar.gz\nInstall it\ntar -zxpf freesurfer-linux-ubuntu22_amd64-7.4.1.tar.gz\nAdd this to your PATH\necho \"export FREESURFER_HOME=$HOME/freesurfer\" &gt;&gt; .bashrc\nsource \"$FREESURFER_HOME/SetUpFreeSurfer.sh\"\" &gt;&gt; .bashrc\nGet the free license online, download it in your home directory and add this command in your .bashrc:\nexport FS_LICENSE=$HOME/license.txt\n\n\n\n\n\nDownload the FSL installer script online. When selecting the OS to install on the download page, make sure to select Ubuntu and not Windows.\nRun the installer\npython3 \"fslinstaller.py\"\nAdd this to your PATH\nFSLDIR=$HOME/path/to/fsl\nPATH=${FSLDIR}/share/fsl/bin:${PATH}\nexport FSLDIR PATH\n. ${FSLDIR}/etc/fslconf/fsl.sh\n\n\n\n\n\nDownload the ANTs installer script\nIn the terminal, enter:\nbash installANTs.sh\nAdd it to your PATH\necho \"ANTSPATH=$HOME/install/bin/\" &gt;&gt; $HOME/.bashrc \necho \"export PATH=${ANTSPATH}:$PATH\" &gt;&gt; $HOME/.bashrc"
  },
  {
    "objectID": "content/guide/DTI/setup_lin.html#software-installation",
    "href": "content/guide/DTI/setup_lin.html#software-installation",
    "title": "Setup (Linux)",
    "section": "",
    "text": "The pipeline revolves around MRtrix3 which works hand in hand with Freesurfer, FSL, and ANTs\n\n\nDownload MRtrix3 by copy pasting this command in a bash terminal:\nconda install -c mrtrix3 mrtrix3\nType an MRtrix3 command like mrconvert to check everything’s working correctly.\nAdd MRtrix3 to your PATH:\necho \"export MRtrix3=/path/to/miniconda3/share/mrtrix3\" &gt;&gt; .bashrc \necho \"export PATH=${MRtrix3}:$PATH\" &gt;&gt; .bashrc\n\n\n\n\nIn your “HOME” directory (cd $HOME), download the Freesurfer installer package:\nwget https://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/7.4.1/freesurfer-linux-ubuntu22_amd64-7.4.1.tar.gz\nInstall it\ntar -zxpf freesurfer-linux-ubuntu22_amd64-7.4.1.tar.gz\nAdd this to your PATH\necho \"export FREESURFER_HOME=$HOME/freesurfer\" &gt;&gt; .bashrc\nsource \"$FREESURFER_HOME/SetUpFreeSurfer.sh\"\" &gt;&gt; .bashrc\nGet the free license online, download it in your home directory and add this command in your .bashrc:\nexport FS_LICENSE=$HOME/license.txt\n\n\n\n\n\nDownload the FSL installer script online. When selecting the OS to install on the download page, make sure to select Ubuntu and not Windows.\nRun the installer\npython3 \"fslinstaller.py\"\nAdd this to your PATH\nFSLDIR=$HOME/path/to/fsl\nPATH=${FSLDIR}/share/fsl/bin:${PATH}\nexport FSLDIR PATH\n. ${FSLDIR}/etc/fslconf/fsl.sh\n\n\n\n\n\nDownload the ANTs installer script\nIn the terminal, enter:\nbash installANTs.sh\nAdd it to your PATH\necho \"ANTSPATH=$HOME/install/bin/\" &gt;&gt; $HOME/.bashrc \necho \"export PATH=${ANTSPATH}:$PATH\" &gt;&gt; $HOME/.bashrc"
  },
  {
    "objectID": "content/guide/rs-fMRI/bold_ts.html",
    "href": "content/guide/rs-fMRI/bold_ts.html",
    "title": "Extract denoised BOLD Timeseries",
    "section": "",
    "text": "Following the standard denoising pipeline, CONN outputs a mat file for each subject (ROI_Subjectxxx_Condition000.mat) in the conn*/data/results/preprocessing folder.\n\nExtract and store BOLD TS in a tensor\n%% Define analysis\n%==========================================================\nclearvars\n\n% Info is the main structure containing all analysis informations\nInfo            = []; \nmypath = uigetdir(\"Select the folder with your Condition000.mat files\");\nInfo.wdir       = [mypath, '\\'];\nInfo.session    = 1;       % 0 for all sessions, 1=session1, 2=session2, etc...\nInfo.nsub       = X;       % Total number of subjects\n\n% ROI is the main structure containing ROI names, data\nROI          = []; \nROI.ROI_data = [];\nROI_datafull = [];\n\n%% Loop on each subject\n%==========================================================\n\nfor i=1:Info.nsub\n    \n    % Loading .MAT file   \n    % if you have more than 99 subjects, input '%03i' instead\n    matfile = [ 'ROI_Subject', num2str(i, '%02i') ,'_Condition000.mat' ];\n    \n    %fprintf('\\nLoading:\\t %s', matfile);\n\n    load([Info.wdir matfile]);\n    ROI.names   = names;\n    \n    % Discard GM, WM, CSF\n    data_reshaped = data(1,4:length(ROI.names));\n    \n    % Loop through every region\n    for j=1:length(data_reshaped)\n        % Extract BOLD data\n        ROI.ROI_data(j,:)  = cell2mat(data_reshaped(j));\n    end\n    \n    % BOLD TimeSeries stored ROI*Volumes*Subject\n    ROI_datafull(:,:,i) = ROI.ROI_data;\n    \nend\n\n\nPlot BOLD TS and compute correlation coefficients between a pair of ROI\nclearvars\n\n%% Define analysis\n%==========================================================\n\n% Info is the main structure containing all analysis informations\nInfo            = [];       \nmypath = uigetdir(\"Select the folder with your Condition000.mat files\");\nInfo.wdir       = [mypath, '\\'];\nInfo.session    = 1;       % 0 for all sessions, 1=session1, 2=session2, etc...\nInfo.nsub       = X;       % Total number of subjects\n\n% ROI is the main structure containing ROI names, data\nROI             = [];       \nROI.ROI1_data   = [];\nROI.ROI2_data   = [];\n% Corr_mat is the main structure containing correlation values\nCorr_mat        = [];       \nCorr_mat.rho    = [];\nCorr_mat.pval   = [];\n\n% Select pair of ROIs\nROI.ROI1_name   = 'AAL3.Precentral_L'; % Input the name of the 1st ROI\nROI.ROI2_name   = 'AAL3.Precentral_R'; % Input the name of the 2nd ROI\n\n% Define outpath and outfilename\nInfo.outdir     = pwd;\nInfo.outfile    = [ Info.outdir '\\TS_' ROI.ROI1_name  '_' ROI.ROI2_name '_RUN' num2str(Info.session) '.png' ];\n\n% Print analysis info\nfprintf('---------------------------------------------');\nfprintf('\\nANALYSIS INFO');\nfprintf('\\nSession:\\t%d', Info.session);\nfprintf('\\nSubject:\\t%d', Info.nsub);\nfprintf('\\nROI1:\\t\\t%s', ROI.ROI1_name);\nfprintf('\\nROI2:\\t\\t%s', ROI.ROI2_name);\nfprintf('\\n---------------------------------------------\\n');\n\n%% Loop on each subject\n%==========================================================\n\nfor i=1:Info.nsub\n    \n    % Loading .MAT file   \n    % if you have more than 99 subjects, input '%03i' instead\n    matfile = [ 'ROI_Subject0', num2str(i, '%02i') ,'_Condition000.mat' ]; \n   \n    \n    %fprintf('\\nLoading:\\t %s', matfile);\n    \n    load([Info.wdir matfile]);\n    \n    ROI.names   = names;\n    ROI.dsess   = data_sessions;\n    \n    % Find index of selected ROIs\n    ROI.ROI1_idx    = find(strcmp(ROI.ROI1_name, names));\n    ROI.ROI2_idx    = find(strcmp(ROI.ROI2_name, names));\n    \n    % Extract BOLD data\n    ROI.ROI1_data   = [ ROI.ROI1_data , cell2mat(data(ROI.ROI1_idx)) ];\n    ROI.ROI2_data   = [ ROI.ROI2_data , cell2mat(data(ROI.ROI2_idx)) ];\n    \n    % Select sessions\n    if Info.session == 0 ;\n        ROI.cond = find(ROI.dsess);\n    else\n        ROI.cond = find(ROI.dsess == Info.session);\n    end\n    \n    % Compute correlations\n    if Info.nsub &gt; 1\n        [ rho, pval ]   = corr(ROI.ROI1_data(ROI.cond, i), ROI.ROI2_data(ROI.cond, i));\n        Corr_mat.rho    = [ Corr_mat.rho , rho ];\n        Corr_mat.pval   = [ Corr_mat.pval , pval ];\n    end\n    \nend\n\n% Compute mean, std and sem\nROI.ROI1_mean   = mean(ROI.ROI1_data, 2);\nROI.ROI1_std    = std(ROI.ROI1_data, 0, 2);\nROI.ROI1_sem    = ROI.ROI1_std / sqrt(Info.nsub);\n\nROI.ROI2_mean   = mean(ROI.ROI2_data, 2);\nROI.ROI2_std    = std(ROI.ROI2_data, 0, 2);\nROI.ROI2_sem    = ROI.ROI2_std / sqrt(Info.nsub);\n\n% Correlation between mean timeseries\n[Corr_mat.rho_mean, Corr_mat.pval_mean] = corr(ROI.ROI1_mean(ROI.cond), ROI.ROI2_mean(ROI.cond));\n\n%% PLOT\n%==========================================================\n% Create plot variables\nROI.x       = [ 1:length(ROI.cond) ]';\nROI.ROI1_Y  = ROI.ROI1_mean(ROI.cond,:);\nROI.ROI2_Y  = ROI.ROI2_mean(ROI.cond,:);\nROI.ROI1_dy = ROI.ROI1_sem(ROI.cond, :);\nROI.ROI2_dy = ROI.ROI2_sem(ROI.cond, :);\n\nset(0,'defaultfigurecolor',[ 1 1 1 ])\nset(0,'DefaultAxesFontSize', 10)\nfig = figure;\nset(gcf,'Units','inches', 'Position',[0 0 6 3])\nline_color = [ 0.1 0.3 0.2 ; 0.8 0.3 0.1 ];\nset(gca, 'ColorOrder', line_color, 'NextPlot', 'replacechildren');\n\n% Plot average ROI BOLD signal\nplot(ROI.x, ROI.ROI1_Y, ROI.x, ROI.ROI2_Y, 'LineWidth', 1.5)\nhold on\nlegend(ROI.ROI1_name, ROI.ROI2_name, 'Location', 'northeast')\nlegend('boxoff')\n\n% Plot error bar\nif Info.nsub &gt; 1\n    fill([ROI.x;flipud(ROI.x)],[ROI.ROI1_Y-ROI.ROI1_dy;flipud(ROI.ROI1_Y+ROI.ROI1_dy)],line_color(1,:),'linestyle','none', 'FaceAlpha', .2);\n    fill([ROI.x;flipud(ROI.x)],[ROI.ROI2_Y-ROI.ROI2_dy;flipud(ROI.ROI2_Y+ROI.ROI2_dy)],line_color(2,:),'linestyle','none', 'FaceAlpha', .2);\nend\n\n% Add correlation value\ndim = [.2 .2 .3 .1];\nstr = [ 'r = ', num2str(round(Corr_mat.rho_mean, 2), '%.2f'), ' ; p = ', num2str(Corr_mat.pval_mean), ' ; n = ', num2str(Info.nsub) ];\nannotation('textbox',dim,'String',str,'FitBoxToText','on', 'EdgeColor', 'none', 'FontWeight', 'bold', 'FontAngle', 'italic');\n\n% Set axis limits / titles\ny_lim = [ -0.2 0.2 ];\nylim(y_lim);\nxlim([0 length(ROI.cond)]);\n%set(gca, 'XColor', 'w');   % Mask x-axis\nylabel('BOLD signal');\nxlabel('Time (TR)');\nset(gca, 'XTick', [ 0:20:length(ROI.cond) ]);\n\ngrid off\nbox off\n\nclearvars -except ROI Corr_mat Info\n\n% Savefig 300 dpi\nfig.PaperPositionMode = 'auto';\nprint(Info.outfile,'-dpng','-r600')\n\n% EOF"
  },
  {
    "objectID": "content/guide/rs-fMRI/rs-fMRI.html",
    "href": "content/guide/rs-fMRI/rs-fMRI.html",
    "title": "Resting-state functional magnetic resonance (rs-fMRI)",
    "section": "",
    "text": "The pipeline is run primarily with Matlab\n\nDownload SPM by copy pasting this command in a bash terminal\nDownload CONN by copy pasting this command in a bash terminal\nDownload GraphVar"
  },
  {
    "objectID": "content/guide/rs-fMRI/rs-fMRI.html#software-installation",
    "href": "content/guide/rs-fMRI/rs-fMRI.html#software-installation",
    "title": "Resting-state functional magnetic resonance (rs-fMRI)",
    "section": "",
    "text": "The pipeline is run primarily with Matlab\n\nDownload SPM by copy pasting this command in a bash terminal\nDownload CONN by copy pasting this command in a bash terminal\nDownload GraphVar"
  },
  {
    "objectID": "content/guide/rs-fMRI/rs-fMRI.html#preprocessing-automation",
    "href": "content/guide/rs-fMRI/rs-fMRI.html#preprocessing-automation",
    "title": "Resting-state functional magnetic resonance (rs-fMRI)",
    "section": "Preprocessing automation",
    "text": "Preprocessing automation"
  },
  {
    "objectID": "content/guide/rs-fMRI/rs-fMRI.html#automating-conn-roi-to-roi-analysis",
    "href": "content/guide/rs-fMRI/rs-fMRI.html#automating-conn-roi-to-roi-analysis",
    "title": "Resting-state functional magnetic resonance (rs-fMRI)",
    "section": "Automating CONN ROI-to-ROI analysis",
    "text": "Automating CONN ROI-to-ROI analysis"
  },
  {
    "objectID": "content/research.html",
    "href": "content/research.html",
    "title": "Research",
    "section": "",
    "text": "PhD project:\nCognitive neuroscience is undergoing a paradigm shift. The abundance of multimodal empirical data, coupled with the unprecendented computational capabilities, is helping to redefine the links between the brain and human behavior. The brain is now understood as a vast network of interactions between cerebral regions from which cognitive operations and processes emerge.\nSpecifically, language functions (L) are not isolated but constantly interact with declarative memory (M) and executive functions (EF). However, the neural mechanisms underlying this L-M-EF dynamic remain unclear. The cognitomic perspective (structure-function-cognition) is closely linked to the identification of multimodal L-M-EF phenotypes, that is the neuropsychological implications that the language connectomic architecture places on cognition.\nThus, this project has:\n\na theoretical dimension, through the enrichment of a neurocognitive L-M-EF model\na methodological dimension, through the fusion of multimodal data required to evaluate this model (i.e. structural, functional, cognitive-behavioral)\n\nIn fine, we expect this project to enable significant advances in both fundamental and clinical research (e.g. pre-habilitation & cognitive rehabilitation).\n\nLatest:\n\nIn our latest preprint (Guichet et al. 2023), we modeled the neural mechanisms that uphold inter-cognitive functioning, lexical production being a prime example of the L-M-EF interaction, across the lifespan. The SENECA model has three dimensions:\n\n\n\n\n\n\n\nAt the cognitive level (CA), we show that language is not isolated but works in synergy with LTM and EF across the lifespan\nAt the cerebral level (SE), we show that DMN-FPN coupling is essential to mitigate cognitive decline, achieving an optimal balance between the cost of reorganization of neural connections and the cognitive efficiency.\nTaken together (SE-NE-CA), less DMN-FPN coupling may be responsible for a transition around 50yo towards less synergistic processing, accelerating cognitive decline in highly synergistic tasks such as lexical production.\n\n\n\nDMN-FPN coupling is associated with a Nonlinear and Emergent trajectory across the lifespan\n\n\n\n\nWhat’s next?\nWe are now investigating the structural underpinnings of the DMN-FPN coupling across the lifespan and whether SC-FC coupling can be a reliable biomarker of individuals with high vs. low cognitive reserve, thus predicting healthy cognitive aging.\n\n\nPublications:\n(Ashokumar et al. 2022)\n\n\n\n\n\nReferences\n\nAshokumar, Monica, Clément Guichet, Jean-Luc Schwartz, and Takayuki Ito. 2022. “Correlation Between the Effect of Orofacial Somatosensory Inputs in Speech Perception and Speech Production Performance.” Auditory Perception & Cognition, October, 1–11. https://doi.org/10.1080/25742442.2022.2134674.\n\n\nGuichet, Clément, Sonja Banjac, Martial Mermillod, Sophie Achard, and Monica Baciu. 2023. “Modeling the Neurocognitive Dynamics of Language Across the Lifespan.” Preprint. Neuroscience. https://doi.org/10.1101/2023.07.04.547510."
  }
]