[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "This site hosts tutorials to preprocess and analyze structural (DWI), and functional (rs-fMRI) data with the latest tools available. For any inquiry, please contact me at: Clement.Guichet@univ-grenoble-alpes.fr"
  },
  {
    "objectID": "content/guide/rs-fMRI/rs-fMRI.html",
    "href": "content/guide/rs-fMRI/rs-fMRI.html",
    "title": "Resting-state functional magnetic resonance (rs-fMRI)",
    "section": "",
    "text": "The pipeline is run primarily with Matlab\n\nDownload SPM by copy pasting this command in a bash terminal\nDownload CONN by copy pasting this command in a bash terminal\nDownload GraphVar"
  },
  {
    "objectID": "content/guide/rs-fMRI/rs-fMRI.html#software-installation",
    "href": "content/guide/rs-fMRI/rs-fMRI.html#software-installation",
    "title": "Resting-state functional magnetic resonance (rs-fMRI)",
    "section": "",
    "text": "The pipeline is run primarily with Matlab\n\nDownload SPM by copy pasting this command in a bash terminal\nDownload CONN by copy pasting this command in a bash terminal\nDownload GraphVar"
  },
  {
    "objectID": "content/guide/rs-fMRI/rs-fMRI.html#preprocessing-automation",
    "href": "content/guide/rs-fMRI/rs-fMRI.html#preprocessing-automation",
    "title": "Resting-state functional magnetic resonance (rs-fMRI)",
    "section": "Preprocessing automation",
    "text": "Preprocessing automation"
  },
  {
    "objectID": "content/guide/rs-fMRI/rs-fMRI.html#automating-conn-roi-to-roi-analysis",
    "href": "content/guide/rs-fMRI/rs-fMRI.html#automating-conn-roi-to-roi-analysis",
    "title": "Resting-state functional magnetic resonance (rs-fMRI)",
    "section": "Automating CONN ROI-to-ROI analysis",
    "text": "Automating CONN ROI-to-ROI analysis"
  },
  {
    "objectID": "content/guide/rs-fMRI/bold_ts.html",
    "href": "content/guide/rs-fMRI/bold_ts.html",
    "title": "Extract denoised BOLD Timeseries",
    "section": "",
    "text": "Following the standard denoising pipeline, CONN outputs a mat file for each subject (ROI_Subjectxxx_Condition000.mat) in the conn*/data/results/preprocessing folder.\n\nExtract and store BOLD TS in a tensor\n%% Define analysis\n%==========================================================\nclearvars\n\n% Info is the main structure containing all analysis informations\nInfo            = []; \nmypath = uigetdir(\"Select the folder with your Condition000.mat files\");\nInfo.wdir       = [mypath, '\\'];\nInfo.session    = 1;       % 0 for all sessions, 1=session1, 2=session2, etc...\nInfo.nsub       = X;       % Total number of subjects\n\n% ROI is the main structure containing ROI names, data\nROI          = []; \nROI.ROI_data = [];\nROI_datafull = [];\n\n%% Loop on each subject\n%==========================================================\n\nfor i=1:Info.nsub\n    \n    % Loading .MAT file   \n    % if you have more than 99 subjects, input '%03i' instead\n    matfile = [ 'ROI_Subject', num2str(i, '%02i') ,'_Condition000.mat' ];\n    \n    %fprintf('\\nLoading:\\t %s', matfile);\n\n    load([Info.wdir matfile]);\n    ROI.names   = names;\n    \n    % Discard GM, WM, CSF\n    data_reshaped = data(1,4:length(ROI.names));\n    \n    % Loop through every region\n    for j=1:length(data_reshaped)\n        % Extract BOLD data\n        ROI.ROI_data(j,:)  = cell2mat(data_reshaped(j));\n    end\n    \n    % BOLD TimeSeries stored ROI*Volumes*Subject\n    ROI_datafull(:,:,i) = ROI.ROI_data;\n    \nend\n\n\nPlot BOLD TS and compute correlation coefficients between a pair of ROI\nclearvars\n\n%% Define analysis\n%==========================================================\n\n% Info is the main structure containing all analysis informations\nInfo            = [];       \nmypath = uigetdir(\"Select the folder with your Condition000.mat files\");\nInfo.wdir       = [mypath, '\\'];\nInfo.session    = 1;       % 0 for all sessions, 1=session1, 2=session2, etc...\nInfo.nsub       = X;       % Total number of subjects\n\n% ROI is the main structure containing ROI names, data\nROI             = [];       \nROI.ROI1_data   = [];\nROI.ROI2_data   = [];\n% Corr_mat is the main structure containing correlation values\nCorr_mat        = [];       \nCorr_mat.rho    = [];\nCorr_mat.pval   = [];\n\n% Select pair of ROIs\nROI.ROI1_name   = 'AAL3.Precentral_L'; % Input the name of the 1st ROI\nROI.ROI2_name   = 'AAL3.Precentral_R'; % Input the name of the 2nd ROI\n\n% Define outpath and outfilename\nInfo.outdir     = pwd;\nInfo.outfile    = [ Info.outdir '\\TS_' ROI.ROI1_name  '_' ROI.ROI2_name '_RUN' num2str(Info.session) '.png' ];\n\n% Print analysis info\nfprintf('---------------------------------------------');\nfprintf('\\nANALYSIS INFO');\nfprintf('\\nSession:\\t%d', Info.session);\nfprintf('\\nSubject:\\t%d', Info.nsub);\nfprintf('\\nROI1:\\t\\t%s', ROI.ROI1_name);\nfprintf('\\nROI2:\\t\\t%s', ROI.ROI2_name);\nfprintf('\\n---------------------------------------------\\n');\n\n%% Loop on each subject\n%==========================================================\n\nfor i=1:Info.nsub\n    \n    % Loading .MAT file   \n    % if you have more than 99 subjects, input '%03i' instead\n    matfile = [ 'ROI_Subject0', num2str(i, '%02i') ,'_Condition000.mat' ]; \n   \n    \n    %fprintf('\\nLoading:\\t %s', matfile);\n    \n    load([Info.wdir matfile]);\n    \n    ROI.names   = names;\n    ROI.dsess   = data_sessions;\n    \n    % Find index of selected ROIs\n    ROI.ROI1_idx    = find(strcmp(ROI.ROI1_name, names));\n    ROI.ROI2_idx    = find(strcmp(ROI.ROI2_name, names));\n    \n    % Extract BOLD data\n    ROI.ROI1_data   = [ ROI.ROI1_data , cell2mat(data(ROI.ROI1_idx)) ];\n    ROI.ROI2_data   = [ ROI.ROI2_data , cell2mat(data(ROI.ROI2_idx)) ];\n    \n    % Select sessions\n    if Info.session == 0 ;\n        ROI.cond = find(ROI.dsess);\n    else\n        ROI.cond = find(ROI.dsess == Info.session);\n    end\n    \n    % Compute correlations\n    if Info.nsub &gt; 1\n        [ rho, pval ]   = corr(ROI.ROI1_data(ROI.cond, i), ROI.ROI2_data(ROI.cond, i));\n        Corr_mat.rho    = [ Corr_mat.rho , rho ];\n        Corr_mat.pval   = [ Corr_mat.pval , pval ];\n    end\n    \nend\n\n% Compute mean, std and sem\nROI.ROI1_mean   = mean(ROI.ROI1_data, 2);\nROI.ROI1_std    = std(ROI.ROI1_data, 0, 2);\nROI.ROI1_sem    = ROI.ROI1_std / sqrt(Info.nsub);\n\nROI.ROI2_mean   = mean(ROI.ROI2_data, 2);\nROI.ROI2_std    = std(ROI.ROI2_data, 0, 2);\nROI.ROI2_sem    = ROI.ROI2_std / sqrt(Info.nsub);\n\n% Correlation between mean timeseries\n[Corr_mat.rho_mean, Corr_mat.pval_mean] = corr(ROI.ROI1_mean(ROI.cond), ROI.ROI2_mean(ROI.cond));\n\n%% PLOT\n%==========================================================\n% Create plot variables\nROI.x       = [ 1:length(ROI.cond) ]';\nROI.ROI1_Y  = ROI.ROI1_mean(ROI.cond,:);\nROI.ROI2_Y  = ROI.ROI2_mean(ROI.cond,:);\nROI.ROI1_dy = ROI.ROI1_sem(ROI.cond, :);\nROI.ROI2_dy = ROI.ROI2_sem(ROI.cond, :);\n\nset(0,'defaultfigurecolor',[ 1 1 1 ])\nset(0,'DefaultAxesFontSize', 10)\nfig = figure;\nset(gcf,'Units','inches', 'Position',[0 0 6 3])\nline_color = [ 0.1 0.3 0.2 ; 0.8 0.3 0.1 ];\nset(gca, 'ColorOrder', line_color, 'NextPlot', 'replacechildren');\n\n% Plot average ROI BOLD signal\nplot(ROI.x, ROI.ROI1_Y, ROI.x, ROI.ROI2_Y, 'LineWidth', 1.5)\nhold on\nlegend(ROI.ROI1_name, ROI.ROI2_name, 'Location', 'northeast')\nlegend('boxoff')\n\n% Plot error bar\nif Info.nsub &gt; 1\n    fill([ROI.x;flipud(ROI.x)],[ROI.ROI1_Y-ROI.ROI1_dy;flipud(ROI.ROI1_Y+ROI.ROI1_dy)],line_color(1,:),'linestyle','none', 'FaceAlpha', .2);\n    fill([ROI.x;flipud(ROI.x)],[ROI.ROI2_Y-ROI.ROI2_dy;flipud(ROI.ROI2_Y+ROI.ROI2_dy)],line_color(2,:),'linestyle','none', 'FaceAlpha', .2);\nend\n\n% Add correlation value\ndim = [.2 .2 .3 .1];\nstr = [ 'r = ', num2str(round(Corr_mat.rho_mean, 2), '%.2f'), ' ; p = ', num2str(Corr_mat.pval_mean), ' ; n = ', num2str(Info.nsub) ];\nannotation('textbox',dim,'String',str,'FitBoxToText','on', 'EdgeColor', 'none', 'FontWeight', 'bold', 'FontAngle', 'italic');\n\n% Set axis limits / titles\ny_lim = [ -0.2 0.2 ];\nylim(y_lim);\nxlim([0 length(ROI.cond)]);\n%set(gca, 'XColor', 'w');   % Mask x-axis\nylabel('BOLD signal');\nxlabel('Time (TR)');\nset(gca, 'XTick', [ 0:20:length(ROI.cond) ]);\n\ngrid off\nbox off\n\nclearvars -except ROI Corr_mat Info\n\n% Savefig 300 dpi\nfig.PaperPositionMode = 'auto';\nprint(Info.outfile,'-dpng','-r600')\n\n% EOF"
  },
  {
    "objectID": "content/guide/DWI/setup_lin.html",
    "href": "content/guide/DWI/setup_lin.html",
    "title": "Setup (Linux)",
    "section": "",
    "text": "The pipeline revolves around MRtrix3 which works hand in hand with Freesurfer, FSL, and ANTs\n\n\nDownload MRtrix3 by copy pasting this command in a bash terminal:\nconda install -c mrtrix3 mrtrix3\nType an MRtrix3 command like mrconvert to check everything’s working correctly.\nAdd MRtrix3 to your PATH:\necho \"export MRtrix3=/path/to/miniconda3/share/mrtrix3\" &gt;&gt; .bashrc \necho \"export PATH=${MRtrix3}:$PATH\" &gt;&gt; .bashrc\n\n\n\n\nIn your “HOME” directory (cd $HOME), download the Freesurfer installer package:\nwget https://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/7.4.1/freesurfer-linux-ubuntu22_amd64-7.4.1.tar.gz\nInstall it\ntar -zxpf freesurfer-linux-ubuntu22_amd64-7.4.1.tar.gz\nAdd this to your PATH\necho \"export FREESURFER_HOME=$HOME/freesurfer\" &gt;&gt; .bashrc\nsource \"$FREESURFER_HOME/SetUpFreeSurfer.sh\"\" &gt;&gt; .bashrc\nGet the free license online, download it in your home directory and add this command in your .bashrc:\nexport FS_LICENSE=$HOME/license.txt\n\n\n\n\n\nDownload the FSL installer script online. When selecting the OS to install on the download page, make sure to select Ubuntu and not Windows.\nRun the installer\npython3 \"fslinstaller.py\"\nAdd this to your PATH\nFSLDIR=$HOME/path/to/fsl\nPATH=${FSLDIR}/share/fsl/bin:${PATH}\nexport FSLDIR PATH\n. ${FSLDIR}/etc/fslconf/fsl.sh\n\n\n\n\n\nDownload the ANTs installer script\nIn the terminal, enter:\nbash installANTs.sh\nAdd it to your PATH\necho \"ANTSPATH=$HOME/install/bin/\" &gt;&gt; $HOME/.bashrc \necho \"export PATH=${ANTSPATH}:$PATH\" &gt;&gt; $HOME/.bashrc"
  },
  {
    "objectID": "content/guide/DWI/setup_lin.html#software-installation",
    "href": "content/guide/DWI/setup_lin.html#software-installation",
    "title": "Setup (Linux)",
    "section": "",
    "text": "The pipeline revolves around MRtrix3 which works hand in hand with Freesurfer, FSL, and ANTs\n\n\nDownload MRtrix3 by copy pasting this command in a bash terminal:\nconda install -c mrtrix3 mrtrix3\nType an MRtrix3 command like mrconvert to check everything’s working correctly.\nAdd MRtrix3 to your PATH:\necho \"export MRtrix3=/path/to/miniconda3/share/mrtrix3\" &gt;&gt; .bashrc \necho \"export PATH=${MRtrix3}:$PATH\" &gt;&gt; .bashrc\n\n\n\n\nIn your “HOME” directory (cd $HOME), download the Freesurfer installer package:\nwget https://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/7.4.1/freesurfer-linux-ubuntu22_amd64-7.4.1.tar.gz\nInstall it\ntar -zxpf freesurfer-linux-ubuntu22_amd64-7.4.1.tar.gz\nAdd this to your PATH\necho \"export FREESURFER_HOME=$HOME/freesurfer\" &gt;&gt; .bashrc\nsource \"$FREESURFER_HOME/SetUpFreeSurfer.sh\"\" &gt;&gt; .bashrc\nGet the free license online, download it in your home directory and add this command in your .bashrc:\nexport FS_LICENSE=$HOME/license.txt\n\n\n\n\n\nDownload the FSL installer script online. When selecting the OS to install on the download page, make sure to select Ubuntu and not Windows.\nRun the installer\npython3 \"fslinstaller.py\"\nAdd this to your PATH\nFSLDIR=$HOME/path/to/fsl\nPATH=${FSLDIR}/share/fsl/bin:${PATH}\nexport FSLDIR PATH\n. ${FSLDIR}/etc/fslconf/fsl.sh\n\n\n\n\n\nDownload the ANTs installer script\nIn the terminal, enter:\nbash installANTs.sh\nAdd it to your PATH\necho \"ANTSPATH=$HOME/install/bin/\" &gt;&gt; $HOME/.bashrc \necho \"export PATH=${ANTSPATH}:$PATH\" &gt;&gt; $HOME/.bashrc"
  },
  {
    "objectID": "content/guide/DWI/DWI_single.html",
    "href": "content/guide/DWI/DWI_single.html",
    "title": "Diffusion Weighted Imaging (DWI) - Single subject",
    "section": "",
    "text": "This is largely adapted from Andrew Jahn’s book; consider checking the book for a thorough tutorial with MRtrix3.\n\nCPUs\nTo determine the number of available logical processors or CPUs on your system, enter nproc in the terminal. Then, pass the output to the -nthreads flag below. Spare some processors if you wish to perform other tasks while the pipeline is running as it usually runs for a couple hours.\n\n\nSTEP 1. Preprocessing\n#!/bin/bash\n\n################################################################\n# MUST FOLLOW BIDS ARCHITECTURE:\n# sub\n#   -anat\n#       -*T1w.nii.gz\n#   -dwi\n#       -*.bvec\n#       -*.bval\n#       -*.json\n#       -*dwi.nii.gz\n################################################################\n\n############################### STEP 1 ###############################\n#             Convert data to .mif format and denoise                #\n######################################################################\n\n# Also consider doing Gibbs denoising (using mrdegibbs). Check your diffusion data for ringing artifacts before deciding whether to use it\nmrconvert *dwi.nii.gz dwi.mif \nmrconvert dwi.mif -fslgrad *.bvec *.bval dwi_header.mif \n\ndwidenoise dwi_header.mif dwi_den.mif -noise noise.mif \nmrdegibbs dwi_den.mif dwi_den_unr.mif \n\n# Extract the b0 images from the diffusion data acquired in the AP direction\ndwiextract dwi_den.mif - -bzero | mrmath - mean mean_b0_AP.mif -axis 3 \n\n######################################################################\n# Runs the dwipreproc command, which is a wrapper for eddy and topup.\n#### !!! Here the CAMCAN dataset does not provide reverse encoding, hence -rpe_none !!!\n######################################################################\ndwifslpreproc dwi_den.mif dwi_den_preproc.mif -pe_dir AP -rpe_none -readout_time 0.0342002 -eddy_options \" --slm=linear --data_is_shelled\" -nthreads 8\n\n# Performs bias field correction. Needs ANTs to be installed in order to use the \"ants\" option (use \"fsl\" otherwise)\ndwibiascorrect ants dwi_den_preproc.mif dwi_den_preproc_unbiased.mif -bias bias.mif \n\n########################### STEP 2 ###################################\n#             Basis function for each tissue type                    #\n######################################################################\n\n# Create a basis function from the subject's DWI data. The \"dhollander\" function is best used for multi-shell acquisitions; it will estimate different basis functions for each tissue type. For single-shell acquisition, use the \"tournier\" function instead\ndwi2response dhollander dwi_den_preproc_unbiased.mif wm.txt gm.txt csf.txt -voxels voxels.mif \n\n#Upsample the difusion image for better resolution and tracto later\nmrgrid *unbiased.mif regrid -vox 1.5 dwi_unbiased_upsampled.mif\n\n# Create a mask for future processing steps\ndwi2mask dwi_unbiased_upsampled.mif mask_up.mif \n\n# Performs multishell-multitissue constrained spherical deconvolution, using the basis functions estimated above\ndwi2fod msmt_csd dwi_unbiased_upsampled.mif -mask mask_up.mif wm.txt wmfod_up.mif gm.txt gmfod_up.mif csf.txt csffod_up.mif \n\n# Creates an image of the fiber orientation densities overlaid onto the estimated tissues (Blue=WM; Green=GM; Red=CSF)\n# You should see FOD's mostly within the white matter. These can be viewed later with the command \"mrview vf.mif -odf.load_sh wmfod.mif\"\nmrconvert -coord 3 0 wmfod_up.mif - | mrcat csffod_up.mif gmfod_up.mif - vf_up.mif \n\n# Now normalize the FODs to enable comparison between subjects\nmtnormalise wmfod_up.mif wmfod_norm_up.mif gmfod_up.mif gmfod_norm_up.mif csffod_up.mif csffod_norm_up.mif -mask mask_up.mif \n\n########################### STEP 3 ###################################\n#            Create a GM/WM boundary for seed analysis               #\n######################################################################\n\n# Convert the anatomical image to .mif format, and then extract all five tissue catagories (1=GM; 2=Subcortical GM; 3=WM; 4=CSF; 5=Pathological tissue)\nmrconvert ../anat/*T1w.nii.gz T1.mif \n5ttgen fsl T1.mif 5tt_nocoreg.mif -nthreads 8 \n\n# The following series of commands will take the average of the b0 images (which have the best contrast), convert them and the 5tt image to NIFTI format, and use it for coregistration.\ndwiextract dwi_den_preproc_unbiased_upsampled.mif - -bzero | mrmath - mean mean_b0_processed_up.mif -axis 3 \nmrconvert mean_b0_processed_up.mif mean_b0_processed_up.nii.gz \nmrconvert 5tt_nocoreg.mif 5tt_nocoreg.nii.gz \n\n# Uses FSL commands fslroi and flirt to create a transformation matrix for regisitration between the tissue map and the b0 images\nfslroi 5tt_nocoreg.nii.gz 5tt_vol0.nii.gz 0 1 #Extract the first volume of the 5tt dataset (since flirt can only use 3D images, not 4D images)\nflirt -in mean_b0_processed_up.nii.gz -ref 5tt_vol0.nii.gz -interp nearestneighbour -dof 6 -omat diff2struct_fsl_up.mat\ntransformconvert diff2struct_fsl_up.mat mean_b0_processed_up.nii.gz 5tt_nocoreg.nii.gz flirt_import diff2struct_mrtrix_up.txt \nmrtransform 5tt_nocoreg.mif -linear diff2struct_mrtrix_up.txt -inverse 5tt_coreg_up.mif \n\n#Create a seed region along the GM/WM boundary\n5tt2gmwmi 5tt_coreg_up.mif gmwmSeed_coreg_up.mif \n\n\nSTEP 2. Streamline generation\nMake sure to allocate at least 5Go of space for each subject on your local disk as streamline generation can get quite heavy. Here we generate 10 millions streamlines and then reduce that number using the tckgen and tcksift2 command.\n#!/bin/bash\n\n########################## STEP 4 ###################################\n#                 Run the streamline analysis                        #\n######################################################################\n\n# Create streamlines\n# Note that the \"right\" number of streamlines is still up for debate. Last I read from the MRtrix documentation,\n# They recommend about 100 million tracks. Here I use 10 million, if only to save time. Read their papers and then make a decision\ntckgen -act 5tt_coreg_up.mif -backtrack -seed_gmwmi gmwmSeed_coreg_up.mif -nthreads 8 -maxlength 250 -cutoff 0.06 -select 10000k wmfod_norm_up.mif tracks_10M_up.tck \n\n# Extract a subset of tracks (here, 200 thousand) for ease of visualization\n# tckedit tracks_10M.tck -number 200k smallerTracks_200k.tck\n\n# Reduce the number of streamlines with tcksift\ntcksift2 -act 5tt_coreg_up.mif -out_mu sift_mu_up.txt -out_coeffs sift_coeffs_up.txt -nthreads 8 tracks_10M.tck wmfod_norm_up.mif sift_1M_up.txt \n\n\nSTEP 3. Recon-all\nDownload the lh and rh.hcpmmp1 annot files in the supplementary files here and put them into $SUBJECTS_DIR/fsaverage/label. This will prepare the T1 image for the HCP MMP 1.0 atlas (Glasser et al. 2016).\n\nReplace &lt;sub&gt; with the name of your subject.\nIf recon-all does not work, make sure you have the tcsh shell installed by typing tcsh on the command line. In the event tcsh is not installed, enter “sudo apt install tcsh”.\nIf the flag -s is not recognized, use -subjid instead\n\n#!/bin/bash\n\nNPROC=$(nproc)\n\n# Since the HCPMMP1-atlas is a FreeSurfer-based atlas, you have to preprocess the T1 image in FreeSurfer. This will take several hours to complete.\nSUBJECTS_DIR=`pwd`;\nrecon-all –s &lt;sub&gt;_recon –i T1_raw.nii.gz –all -nthreads $NPROC\n\n# Move into freesurfer's subjects directory. Substitute &lt;password&gt; for your UNIX password\necho &lt;password&gt; | sudo -S mv *recon $SUBJECTS_DIR\n# Grant permission to write the file\necho &lt;password&gt; | sudo -S chmod -R a+w $FREESURFER_HOME\nYou can then carry on with mapping the glasser annotation file:\n################################################################\n# For the command \"mri_aparc2aseg\", there can be an error which is due to the way multithreading is handled. Just rerun the command manually until it works or use a single thread\n################################################################\n\n# Map the annotation files of the HCP MMP 1.0 atlas from fsaverage to your subject for both hemispheres:\nmri_surf2surf --srcsubject fsaverage --trgsubject &lt;sub&gt;_recon --hemi lh --sval-annot $SUBJECTS_DIR/fsaverage/label/lh.hcpmmp1.annot --tval\n$SUBJECTS_DIR/&lt;sub&gt;_recon/label/lh.hcpmmp1.annot\n\nmri_surf2surf --srcsubject fsaverage --trgsubject &lt;sub&gt;_recon --hemi rh --sval-annot $SUBJECTS_DIR/fsaverage/label/rh.hcpmmp1.annot --tval $SUBJECTS_DIR/&lt;sub&gt;_recon/label/rh.hcpmmp1.annot\n\nmri_aparc2aseg --old-ribbon --s &lt;sub&gt;_recon --annot hcpmmp1 --o hcpmmp1.mgz --nthreads $NPROC/2\n\n\nSTEP 4. Generate the Structural Connectome (SC)\n#!/bin/bash\n\nmrconvert –datatype uint32 hcpmmp1.mgz  hcpmmp1.mif\n\n# Replace the random integers of the hcpmmp1.mif file with integers\n# that start at 1 and increase by 1.\nlabelconvert hcpmmp1.mif $MRtrix3/labelconvert/hcpmmp1_original.txt $MRtrix3/labelconvert/hcpmmp1_ordered.txt hcpmmp1_parcels_nocoreg.mif\n\n# Register the ordered atlas-based volumetric parcellation to diffusion space.\nmrtransform hcpmmp1_parcels_nocoreg.mif –linear diff2struct_mrtrix_up.txt –inverse –datatype uint32 hcpmmp1_parcels_coreg_up.mif\n\n# Create a whole-brain connectome, representing the streamlines between each parcellation pair in the atlas (in this case, 379x379). The \"symmetric\" option will make the lower diagonal the same as the upper diagonal, and the \"scale_invnodevol\" option will scale the connectome by the inverse of the size of the node\n\ntck2connectome -symmetric -zero_diagonal -scale_invnodevol -tck_weights_in sift_1M.txt tracks_10M.tck hcpmmp1_parcels_coreg_up.mif &lt;sub&gt;_hcpmmp1_parcels_coreg_up.csv -out_assignment assignments_IN_hcpmmp1_parcels_coreg_up.csv\n\n# Visualize the connectome in MRtrix3\nmrview hcpmmp1_parcels_coreg_up.mif -connectome.init hcpmmp1_parcels_coreg_up.mif -connectome.load sub*.csv\nYou can then visualize the connectivity matrix in matlab: the upper left and lower right quadrant represent the left and right intra-hemispheric connections respectively.\n\n\n\n\nIn Matlab: W = importdata(‘sub-XXXXX_hcpmmp1_parcels_coreg.csv’); figure, imagesc(W, [0 1]), xlabel([’ 379 Glasser regions ‘]), ylabel(’379 Glasser regions’), title([’ Structural connectome (streamline density) ‘]); colormap(jet), colorbar, set(gcf,’color’,‘w’), set(gca,‘fontsize’,14)\n\n\n\n\nOPTIONAL. FA-weighted connectome\n# Generate the RGB-colored FA map\ndwi2tensor dwi_den_preproc_unbiased.mif - | tensor2metric - -fa - | mrcalc - -abs FA.mif\n\n# Generate the connectome\ntcksample tracks_10M.tck FA.mif mean_FA_per_streamline.csv -stat_tck mean\n\ntck2connectome -symmetric tracks_10M.tck -tck_weights_in sift_1M.txt hcpmmp1_parcels_coreg.mif mean_FA_connectome.csv -scale_file mean_FA_per_streamline.csv -stat_edge mean\n\n\n\n\n\nReferences\n\nGlasser, Matthew F., Timothy S. Coalson, Emma C. Robinson, Carl D. Hacker, John Harwell, Essa Yacoub, Kamil Ugurbil, et al. 2016. “A Multi-Modal Parcellation of Human Cerebral Cortex.” Nature 536 (7615): 171–78. https://doi.org/10.1038/nature18933."
  },
  {
    "objectID": "content/about.html",
    "href": "content/about.html",
    "title": "About",
    "section": "",
    "text": "I’m a 2nd-year PhD Student in Cognitive Neuroscience at LPNC, CNRS UMR 5105, UGA, Grenoble, France. My research project is about modeling the neurocognitive mechanisms that uphold language production across the lifespan. Find out more about our team LPNC-LANG here."
  },
  {
    "objectID": "content/about.html#education",
    "href": "content/about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\nPhD candidate (2022-2025) | LPNC, UGA | Supervised by Prof. Monica Baciu and Prof. Martial Mermillod\nMSc degree in Research in Psychology (2020-2022) | LPNC, UGA | Master theses in psycholinguistics supervised by Prof. Elsa Spinelli and Prof. Boris New\nBachelor’s degree in Psychology (2017-2020) | UGA"
  },
  {
    "objectID": "content/about.html#supervision",
    "href": "content/about.html#supervision",
    "title": "About",
    "section": "Supervision",
    "text": "Supervision\nNicolas Grivel - UGA Master’s student (Oct 2023 - ongoing) | Language, Cognitive Reserve, Brain connectivity"
  },
  {
    "objectID": "content/about.html#experience",
    "href": "content/about.html#experience",
    "title": "About",
    "section": "Experience",
    "text": "Experience\nCo-analyst & Peer-reviewer (April 2022 - ongoing) | Center of Open Science (COS) | Multi100 project\nCNRS Individual contractor (Sept 2021 - March 2022 incl.) | GIPSA-lab, UGA | Supervised by Takayuki Ito\nCNRS Research intern (June - Aug 2021 incl.) | GIPSA-lab, UGA | Supervised by Takayuki Ito and Jean-Luc Schwartz"
  },
  {
    "objectID": "content/guide/DWI/DWI_batch.html",
    "href": "content/guide/DWI/DWI_batch.html",
    "title": "Diffusion Weighted Imaging (DWI) - Batch processing",
    "section": "",
    "text": "Below, I provide a synthesis of the preprocessing steps using the for_each command available on MRtrix3.\n\nFor_each command\nFor_each is useful when you want to run multiple subjects, with multithreading. You have to provide the path to the /dwi directory/ within each subject’s folder where the data is stored (bvals, bvecs, etc…) as a template :\nFor_each will then iterate over the directories paths that match this template (*/dwi), substituting the * with each subject’s folder in your dataset. IN is used in the MRtrix command to echo the *.\n\n\nSTEP 1. Preprocessing\n#!/bin/bash\n\n################################################################\n# MUST FOLLOW BIDS ARCHITECTURE:\n# sub\n#   -anat\n#       -*T1w.nii.gz\n#   -dwi\n#       -*.bvec\n#       -*.bval\n#       -*.json\n#       -*dwi.nii.gz\n################################################################\n\nNPROC=$(nproc)\n############################### STEP 1 ###############################\n#             Convert data to .mif format and denoise                #\n######################################################################\n\n# Also consider doing Gibbs denoising (using mrdegibbs). Check your diffusion data for ringing artifacts before deciding whether to use it\nfor_each -nthreads $NPROC -info */dwi : mrconvert IN/*dwi.nii.gz IN/dwi.mif \nfor_each -nthreads $NPROC -info */dwi : mrconvert IN/dwi.mif -fslgrad IN/*.bvec IN/*.bval IN/dwi_header.mif \n\nfor_each -nthreads $NPROC -info */dwi : dwidenoise IN/dwi_header.mif IN/dwi_den.mif -noise IN/noise.mif \nfor_each -nthreads $NPROC -info */dwi : mrdegibbs IN/dwi_den.mif IN/dwi_den_unr.mif \n\n# Extract the b0 images from the diffusion data acquired in the AP direction\nfor_each -nthreads $NPROC -info */dwi : dwiextract IN/dwi_den.mif - -bzero \\| mrmath - mean IN/mean_b0_AP.mif -axis 3 \n\n######################################################################\n# Runs the dwipreproc command, which is a wrapper for eddy and topup.\n#### !!! Here the CAMCAN dataset does not provide reverse encoding, hence -rpe_none !!! ####\n#### !!! $NPROC/8 means you should divide by 8 as each subject's preprocessing will be performed by 8 threads already (see at the end of the line) #### !!!\n######################################################################\nfor_each 8 -info */dwi : dwifslpreproc IN/dwi_den.mif IN/dwi_den_preproc.mif -pe_dir AP -rpe_none -readout_time 0.0342002 -eddy_options \" --slm=linear --data_is_shelled\"  -nthreads 8\n\n# Performs bias field correction. Needs ANTs to be installed in order to use the \"ants\" option (use \"fsl\" otherwise)\nfor_each -nthreads $NPROC -info */dwi : dwibiascorrect ants IN/dwi_den_preproc.mif IN/dwi_den_preproc_unbiased.mif -bias IN/bias.mif \n\n########################### STEP 2 ###################################\n#             Basis function for each tissue type                    #\n######################################################################\n\n#The \"dhollander\" function is best used for multi-shell acquisitions; it will estimate different basis functions for each tissue type. For single-shell acquisition, use the \"tournier\" function instead\nfor_each -nthreads $NPROC -info */dwi : dwi2response dhollander IN/dwi_den_preproc_unbiased.mif IN/wm.txt IN/gm.txt IN/csf.txt -voxels IN/voxels.mif \n\n# Create an average basis function from the subject's DWI data. \nresponsemean */dwi/wm.txt ./group_average_wm.txt\nresponsemean */dwi/gm.txt ./group_average_gm.txt\nresponsemean */dwi/csf.txt ./group_average_csf.txt\n\n#Upsample the difusion image for better resolution and tracto later\nfor_each -nthreads $NPROC -info */dwi : mrgrid IN/*unbiased.mif regrid -vox 1.5 IN/dwi_unbiased_upsampled.mif\n\n# Create a mask for future processing steps\nfor_each -nthreads $NPROC -info */dwi : dwi2mask IN/*unbiased_upsampled.mif IN/mask_up.mif\n\n# Performs multishell-multitissue constrained spherical deconvolution, using the basis functions estimated above\nfor_each -nthreads $NPROC -info */dwi : dwi2fod msmt_csd IN/*unbiased_upsampled.mif -mask IN/mask_up.mif group_average_wm.txt IN/wmfod_up.mif group_average_gm.txt IN/gmfod_up.mif group_average_csf.txt IN/csffod_up.mif \n\n# Creates an image of the fiber orientation densities overlaid onto the estimated tissues (Blue=WM; Green=GM; Red=CSF)\n# You should see FOD's mostly within the white matter. These can be viewed later with the command \"mrview vf.mif -odf.load_sh wmfod.mif\"\nfor_each -nthreads $NPROC -info */dwi : mrconvert -coord 3 0 IN/wmfod_up.mif - \\| mrcat IN/csffod_up.mif IN/gmfod_up.mif - IN/vf_up.mif \n\n# Now normalize the FODs to enable comparison between subjects\nfor_each -nthreads $NPROC -info */dwi : mtnormalise IN/wmfod_up.mif IN/wmfod_norm_up.mif IN/gmfod_up.mif IN/gmfod_norm_up.mif IN/csffod_up.mif IN/csffod_norm_up.mif -mask IN/mask_up.mif \n\n########################### STEP 3 ###################################\n#            Create a GM/WM boundary for seed analysis               #\n######################################################################\n\n# Convert the anatomical image to .mif format, and then extract all five tissue catagories (1=GM; 2=Subcortical GM; 3=WM; 4=CSF; 5=Pathological tissue)\nfor_each -nthreads 8 -info */dwi : mrconvert IN/../anat/*T1w.nii.gz IN/T1.mif \nfor_each -nthreads $NPROC/8 -info */dwi : 5ttgen fsl IN/T1.mif IN/5tt_nocoreg.mif -nthreads 8 \nfor_each -nthreads $NPROC -info */dwi : mrconvert IN/5tt_nocoreg.mif IN/5tt_nocoreg.nii.gz\n\n# The following series of commands will take the average of the b0 images (which have the best contrast), convert them to NIFTI format, and use it for coregistration.\nfor_each -nthreads $NPROC -info */dwi : dwiextract IN/*unbiased_upsampled.mif - -bzero \\| mrmath - mean IN/mean_b0_processed_up.mif -axis 3 \nfor_each -nthreads $NPROC -info */dwi : mrconvert IN/mean_b0_processed_up.mif IN/mean_b0_processed_up.nii.gz \n\n\n# Uses FSL commands fslroi and flirt to create a transformation matrix for regisitration between the tissue map and the b0 images\nfor_each -nthreads $NPROC -info */dwi : fslroi IN/5tt_nocoreg.nii.gz IN/5tt_vol0.nii.gz 0 1 #Extract the first volume of the 5tt dataset (since flirt can only use 3D images, not 4D images)\nfor_each -nthreads $NPROC -info */dwi : flirt -in IN/mean_b0_processed_up.nii.gz -ref IN/5tt_vol0.nii.gz -interp nearestneighbour -dof 6 -omat IN/diff2struct_fsl_up.mat\nfor_each -nthreads $NPROC -info */dwi : transformconvert IN/diff2struct_fsl_up.mat IN/mean_b0_processed_up.nii.gz IN/5tt_nocoreg.nii.gz flirt_import IN/diff2struct_mrtrix_up.txt \nfor_each -nthreads $NPROC -info */dwi : mrtransform IN/5tt_nocoreg.mif -linear IN/diff2struct_mrtrix_up.txt -inverse IN/5tt_coreg_up.mif \n\n#Create a seed region along the GM/WM boundary\nfor_each -nthreads $NPROC -info */dwi : 5tt2gmwmi IN/5tt_coreg_up.mif IN/gmwmSeed_coreg_up.mif\n\n\nSTEP 2. Streamline generation\nMake sure to allocate at least 4Go of space for each subject on your local disk as streamline generation can get quite heavy.\n#!/bin/bash\n\n########################## STEP 4 ###################################\n#                 Run the streamline analysis                        #\n######################################################################\n\n# MRtrix3 recommend about 100 million tracks. Here I use 10 million, if only to save time. Read their papers and then make a decision\nfor_each -nthreads 8 -info */dwi : tckgen -act IN/5tt_coreg_up.mif -backtrack -seed_gmwmi IN/gmwmSeed_coreg_up.mif -nthreads 8 -maxlength 250 -cutoff 0.06 -select 10000k IN/wmfod_norm_up.mif IN/tracks_10M_up.tck \n\n# Extract a subset of tracks (here, 200 thousand) for ease of visualization\n# tckedit tracks_10M.tck -number 200k smallerTracks_200k.tck\n\n# Reduce the number of streamlines with tcksift\nfor_each -nthreads 8 -info */dwi : tcksift2 -act IN/5tt_coreg_up.mif -out_mu IN/sift_mu_up.txt -out_coeffs IN/sift_coeffs_up.txt -nthreads 8 IN/tracks_10M_up.tck IN/wmfod_norm_up.mif IN/sift_1M_up.txt \n\n\nSTEP 3. Recon-all\nCheck the parallel processing section to speed up this step using parallel computing. Make sure you’ve downloaded the lh and rh.hcpmmp1 annot files in the supplementary files here and put them into $SUBJECTS_DIR/fsaverage/label.\n\n\nSTEP 4. Generate the Structural Connectome (SC)\n#!/bin/bash\n\nfor_each -nthreads $NPROC -info */dwi : mrconvert –datatype uint32 IN/hcpmmp1.mgz  IN/hcpmmp1.mif \n\n# Replace the random integers of the hcpmmp1.mif file with integers\n# that start at 1 and increase by 1.\nfor_each -nthreads $NPROC -info */dwi : labelconvert IN/hcpmmp1.mif $MRtrix3/labelconvert/hcpmmp1_original.txt $MRtrix3/labelconvert/hcpmmp1_ordered.txt IN/hcpmmp1_parcels_nocoreg.mif \n\n# Register the ordered atlas-based volumetric parcellation to diffusion space.\nfor_each -nthreads $NPROC -info */dwi : mrtransform IN/hcpmmp1_parcels_nocoreg.mif –linear IN/diff2struct_mrtrix_up.txt –inverse –datatype uint32 IN/hcpmmp1_parcels_coreg_up.mif \n\n# Create a whole-brain connectome, representing the streamlines between each parcellation pair in the atlas (in this case, 379x379). The \"symmetric\" option will make the lower diagonal the same as the upper diagonal, and the \"scale_invnodevol\" option will scale the connectome by the inverse of the size of the node\n\nfor_each -nthreads $NPROC -info * : tck2connectome -symmetric -zero_diagonal -scale_invnodevol -tck_weights_in IN/dwi/sift_1M_up.txt IN/dwi/tracks_10M_up.tck IN/dwi/hcpmmp1_parcels_coreg_up.mif IN/dwi/IN_hcpmmp1_parcels_coreg_up.csv -out_assignment IN/dwi/assignments_IN_hcpmmp1_parcels_coreg_up.csv \n\n# For a given subject, Visualize the connectome in MRtrix3\nmrview hcpmmp1_parcels_coreg_up.mif -connectome.init hcpmmp1_parcels_coreg_up.mif -connectome.load sub*_up.csv\n\n\nOPTIONAL. FA-weighted connectome\n# Generate the RGB-colored FA map\nfor_each -nthreads $NPROC -info */dwi : dwi2tensor IN/*unbiased_upsampled.mif - \\| tensor2metric - -fa - \\| mrcalc - -abs IN/FA_up.mif\n\n# Generate the connectome\nfor_each -nthreads $NPROC -info * : tcksample IN/dwi/tracks_10M_up.tck IN/dwi/FA_up.mif IN/dwi/IN_mean_FA_per_streamline_up.csv -stat_tck mean\n\nfor_each -nthreads $NPROC -info * : tck2connectome -symmetric dwi/tracks_10M_up.tck -tck_weights_in dwi/sift_1M_up.txt dwi/hcpmmp1_parcels_coreg_up.mif dwi/IN_mean_FA_connectome_up.csv -scale_file dwi/IN_mean_FA_per_streamline_up.csv -stat_edge mean\n\n\n\nUseful shell commands\n# Copy and paste specific files \nfind . -name \\filename.xxx -exec cp {} /path/to/where you want to save the SC \\;  \n\n#Find all directories that do contain a specific file \nfind . -name \\filename.xxx | wc -l #(get the total count)  \n\n# Find all directories that do not contain a specific file \nfind . -type d '!' -exec test -e \"{}/filename.xxx\" \\; -print"
  },
  {
    "objectID": "content/guide/DWI/parallel.html",
    "href": "content/guide/DWI/parallel.html",
    "title": "Parallel computing",
    "section": "",
    "text": "Install Homebrew with the following command and add it to your PATH:\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\ntest -d ~/.linuxbrew && eval \"$(~/.linuxbrew/bin/brew shellenv)\"\ntest -d /home/linuxbrew/.linuxbrew && eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\"\ntest -r ~/.bash_profile && echo \"eval \\\"\\$($(brew --prefix)/bin/brew shellenv)\\\"\" &gt;&gt; ~/.bash_profile\necho \"eval \\\"\\$($(brew --prefix)/bin/brew shellenv)\\\"\" &gt;&gt; ~/.profile\nThen install gcc and parallel:\nbrew install gcc\nbrew install parallel"
  },
  {
    "objectID": "content/guide/DWI/parallel.html#software-installation",
    "href": "content/guide/DWI/parallel.html#software-installation",
    "title": "Parallel computing",
    "section": "",
    "text": "Install Homebrew with the following command and add it to your PATH:\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\ntest -d ~/.linuxbrew && eval \"$(~/.linuxbrew/bin/brew shellenv)\"\ntest -d /home/linuxbrew/.linuxbrew && eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\"\ntest -r ~/.bash_profile && echo \"eval \\\"\\$($(brew --prefix)/bin/brew shellenv)\\\"\" &gt;&gt; ~/.bash_profile\necho \"eval \\\"\\$($(brew --prefix)/bin/brew shellenv)\\\"\" &gt;&gt; ~/.profile\nThen install gcc and parallel:\nbrew install gcc\nbrew install parallel"
  },
  {
    "objectID": "content/guide/DWI/parallel.html#using-the-parallel-command",
    "href": "content/guide/DWI/parallel.html#using-the-parallel-command",
    "title": "Parallel computing",
    "section": "Using the parallel command",
    "text": "Using the parallel command\nParallel is run by piping the ls command into the parallel command:\nNPROC=$(nproc)\n\nls *.nii | parallel --jobs $NPROC recon-all -s {.}_recon -i {} -all\n--jobs NPROC indicates that NPROC cores will be used to analyze the data and that each instance of recon-all will be assigned to a different core.\nThe full bash script consists in copying the T1.nii.gz images in the new directory (/FS), unzip them, run and store the output of recon-all in this directory. Then, we move the newly created recon directory into freesurfer’s $SUBJECTS_DIR.\n#!/bin/bash\n\n# Assuming you are in the raw_data directory which lists all the subjects folders\nmkdir FS\n\n# grab the list of subject name\nls . | grep ^sub- &gt; subjList.txt\n\n# Path to the anatomical T1 image\nfor sub in `cat subjList.txt`; do\n    cp ./${sub}/anat/${sub}_T1w.nii.gz ./FS\ndone\n\ncd FS\n\n# Unzip\ngunzip *.gz\n\n# Story output in the current directory\n# This avoids permission error\nSUBJECTS_DIR=`pwd`\n\nls *.nii | parallel --jobs $NPROC recon-all -s {.}_recon -i {} -all\n# Remove the copied T1.nii.gz files\nrm *.nii\n\n# Move into freesurfer's subjects directory. Substitute &lt;password&gt; for your UNIX password\necho &lt;password&gt; | sudo -S mv *recon $SUBJECTS_DIR\n# Grant permission to write the file\necho &lt;password&gt; | sudo -S chmod -R a+w $FREESURFER_HOME\nYou can then carry on with mapping the glasser annotation file:\n################################################################\n# For the command \"mri_aparc2aseg\", there can be an error which is due to the way multithreading is handled. Just rerun the command manually for the subjects which did not have an output hcpmmp1.mgz\n# You can find these subjects by typing \"find . -name *.mgz\" in a terminal in the directory that contains all your subjects folders\n################################################################\n\n# Map the annotation files of the HCP MMP 1.0 atlas from fsaverage to you rsubject for both hemispheres:\n\nls . | grep ^sub- &gt; subjList.txt\n\nfor sub in `cat subjList.txt`; do\n  # Left hemisphere\n  mri_surf2surf --srcsubject fsaverage --trgsubject ${sub}_recon --hemi lh --sval-annot $SUBJECTS_DIR/fsaverage/label/lh.hcpmmp1.annot --tval $SUBJECTS_DIR/${sub}_T1w_recon/label/lh.hcpmmp1.annot\n\n  # Right hemisphere\n  mri_surf2surf --srcsubject fsaverage --trgsubject ${sub}_recon --hemi rh --sval-annot $SUBJECTS_DIR/fsaverage/label/rh.hcpmmp1.annot --tval $SUBJECTS_DIR/${sub}_T1w_recon/label/rh.hcpmmp1.annot\n  \n  cd ./{sub}/dwi\n  mri_aparc2aseg --old-ribbon --s ${sub}_recon --annot hcpmmp1 --o ${sub}/dwi/hcpmmp1.mgz --nthreads $NPROC/2\n  cd ../..\n  \ndone"
  },
  {
    "objectID": "content/guide/DWI/setup_win.html",
    "href": "content/guide/DWI/setup_win.html",
    "title": "Setup (Windows)",
    "section": "",
    "text": "Check that WSL2 is running by typing this command in PowerShell:\n  wsl -l -v \n# You should see something like this\n  NAME                   STATE           VERSION\n  Ubuntu-22.04           Running         2\n  \n# If you have WSL1, you can update to WSL2 by typing \n  wsl --set-default-version 2 wsl --set-version Ubuntu-22.04 2\nOtherwise, you can install Ubuntu by pasting the following commands:\n1. Enable WSL by opening PowerShell as administrator\n    wsl --install -d Ubuntu-22.04\n2. Restart your computer\n3. Start the Ubuntu app to open a Ubuntu shell\n4. Set up a username and password\nYou’ll also need to GUI for WSL. I recommend you install VcXsrv on your system, which is a free X-sever on Windows. After downloading and installing VcXsrv with default options, run Xlaunch (which gets installed automatically) and perform the following configuration:\n\nDisplay setting: select multiple windows option\nClient startup: check the Start no client option\nExtra setting: make sure “Disable access control” is enabled and “native opengl” is disabled\nAdd this to your .bashrc file:\n echo \"export DISPLAY=$(grep nameserver /etc/resolv.conf  | awk '{print $2; exit}'):0\" &gt;&gt; ~/.bashrc\n echo \"export LIBGL_ALWAYS_INDIRECT=0\" &gt;&gt; ~/.bashrc\n # For Windows 11 users, add this as well\n  echo \"export LIBGL_ALWAYS_SOFTWARE=1\" &gt;&gt; ~/.bashrc\nTry running glxgears. A window with three spinning gears should open.\nTroubleshooting:\n\nMake sure you are not using a VPN.\nGo to Control panel &gt; System and security &gt; Windows defender firewall &gt; Advanced settings &gt; Inbound rules and make sure that the VcXsrv rules are not set to block - if they are you will need to edit the VcXsrv rule and change it from block to allow."
  },
  {
    "objectID": "content/guide/DWI/setup_win.html#os",
    "href": "content/guide/DWI/setup_win.html#os",
    "title": "Setup (Windows)",
    "section": "",
    "text": "Check that WSL2 is running by typing this command in PowerShell:\n  wsl -l -v \n# You should see something like this\n  NAME                   STATE           VERSION\n  Ubuntu-22.04           Running         2\n  \n# If you have WSL1, you can update to WSL2 by typing \n  wsl --set-default-version 2 wsl --set-version Ubuntu-22.04 2\nOtherwise, you can install Ubuntu by pasting the following commands:\n1. Enable WSL by opening PowerShell as administrator\n    wsl --install -d Ubuntu-22.04\n2. Restart your computer\n3. Start the Ubuntu app to open a Ubuntu shell\n4. Set up a username and password\nYou’ll also need to GUI for WSL. I recommend you install VcXsrv on your system, which is a free X-sever on Windows. After downloading and installing VcXsrv with default options, run Xlaunch (which gets installed automatically) and perform the following configuration:\n\nDisplay setting: select multiple windows option\nClient startup: check the Start no client option\nExtra setting: make sure “Disable access control” is enabled and “native opengl” is disabled\nAdd this to your .bashrc file:\n echo \"export DISPLAY=$(grep nameserver /etc/resolv.conf  | awk '{print $2; exit}'):0\" &gt;&gt; ~/.bashrc\n echo \"export LIBGL_ALWAYS_INDIRECT=0\" &gt;&gt; ~/.bashrc\n # For Windows 11 users, add this as well\n  echo \"export LIBGL_ALWAYS_SOFTWARE=1\" &gt;&gt; ~/.bashrc\nTry running glxgears. A window with three spinning gears should open.\nTroubleshooting:\n\nMake sure you are not using a VPN.\nGo to Control panel &gt; System and security &gt; Windows defender firewall &gt; Advanced settings &gt; Inbound rules and make sure that the VcXsrv rules are not set to block - if they are you will need to edit the VcXsrv rule and change it from block to allow."
  },
  {
    "objectID": "content/guide/DWI/setup_win.html#software-installation",
    "href": "content/guide/DWI/setup_win.html#software-installation",
    "title": "Setup (Windows)",
    "section": "Software installation",
    "text": "Software installation\nThe pipeline revolves around MRtrix3 which works hand in hand with Freesurfer, FSL, and ANTs\n\nMRtrix3\nDownload MRtrix3 by copy pasting this command in a bash terminal:\n# Clone the MRtrix3 repo\ngit clone https://github.com/MRtrix3/mrtrix3.git\n# Configure the install\ncd mrtrix3\n./configure\n# Build the binaries\n./build\n# Add it to your path\n./set_path\nIf you get an error, you can try with conda:\n# If conda has been installed in /root, you may need to enter:\nsudo chown -R $USER:$USER miniconda3\n\nconda install -c mrtrix3 mrtrix3\nType an MRtrix3 command like mrconvert to check everything’s working correctly.\nAdd MRtrix3 to your PATH:\necho \"export MRtrix3=/path/to/miniconda3/pkgs/mrtrix3-3.0.4-h2bc3f7f_0/share/mrtrix3\" &gt;&gt; .bashrc\necho \"export PATH=${MRtrix3}:$PATH\" &gt;&gt; .bashrc\n\n\nFreesurfer\n\nIn your “HOME” directory (cd $HOME), download the Freesurfer installer package:\nwget https://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/7.4.1/freesurfer_ubuntu22-7.4.1_amd64.deb\nMake sure to install the Freesurfer distribution under the path /usr/local/freesurfer/7.4.1\ncd /usr/local\nsudo apt-get -y install ./freesurfer_ubuntu22-7.4.1_amd64.deb\nAdd it to your PATH\necho \"export FREESURFER_HOME=/usr/local/freesurfer/7.4.1\" &gt;&gt; $HOME/.bashrc\nGet the free license online, download it in your home directory and add this command in your .bashrc:\nexport FS_LICENSE=$HOME/license.txt\nSet the Freesurfer env to be setup when you open the shell:\necho \"source $FREESURFER_HOME/SetUpFreeSurfer.sh\" &gt;&gt; $HOME/.bashrc\n\nOpen a new Ubuntu linux terminal window and verify you see the following output showing the Freesurfer environment has been set. If everything went fine, you should see this output:\n - - - - - - - -freesurfer-linux-ubuntu22_x86_64-7.4.1-20230614-7eb8460- - - - - - - -\nSetting up environment for FreeSurfer/FS-FAST (and FSL)\nFREESURFER_HOME   /usr/local/freesurfer/7.4.1\nFSFAST_HOME       /usr/local/freesurfer/7.4.1/fsfast\nFSF_OUTPUT_FORMAT nii.gz\nSUBJECTS_DIR      /usr/local/freesurfer/7.4.1/subjects\nMNI_DIR           /usr/local/freesurfer/7.4.1/mni\n\n\nFSL\n\nDownload the FSL installer script online. When selecting the OS to install on the download page, make sure to select Ubuntu and not Windows.\nRun the installer script by replacing &lt;UserName&gt; with your windows user name. Make sure to install it under the path /usr/local/fsl/.\npython3 \"fslinstaller.py\"\n\n\n\nANTs\n\nDownload the ANTs installer script\nIn the terminal, enter:\nbash installANTs.sh\nAdd it to your PATH\necho \"ANTSPATH=$HOME/install/bin/\" &gt;&gt; $HOME/.bashrc\necho \"export PATH=${ANTSPATH}:$PATH\" &gt;&gt; $HOME/.bashrc"
  },
  {
    "objectID": "content/guide/rs-fMRI/conn.html",
    "href": "content/guide/rs-fMRI/conn.html",
    "title": "CONN",
    "section": "",
    "text": "Following the standard preprocessing pipeline, the CONN toolbox (Nieto-Castanon 2020) takes care of the FC generation after denoising. This is an add-on to SPM that can be downloaded here.\n\nSTEP 1. Importing the data into a new CONN project\nThis script will create a new conn project named conn_example and automatically import the functional and structural volumes for the set number of subjects.\n% Created by Andrew Jahn, University of Michigan, 02.27.2020\n% Adapted by Clément Guichet, UGA, LPNC, 07.01.2023\n\n% FIND functional/structural files\nNSUBJECTS= X;\ncwd=pwd;\n\n# the smoothed out spatially preprocessed volumes, conn will automatically bind them to the unsmoothed ones\nFUNCTIONAL_FILE=cellstr(conn_dir('swar*.nii'));\nSTRUCTURAL_FILE=cellstr(conn_dir('wm*.nii'));\nif rem(length(FUNCTIONAL_FILE),NSUBJECTS),error('mismatch number of functional files %n', length(FUNCTIONAL_FILE));end\nif rem(length(STRUCTURAL_FILE),NSUBJECTS),error('mismatch number of anatomical files %n', length(FUNCTIONAL_FILE));end\nnsessions=length(FUNCTIONAL_FILE)/NSUBJECTS;\nFUNCTIONAL_FILE=reshape(FUNCTIONAL_FILE,[nsessions, NSUBJECTS]);\nSTRUCTURAL_FILE={STRUCTURAL_FILE{1:NSUBJECTS}};\ndisp([num2str(size(FUNCTIONAL_FILE,1)),' sessions']);\ndisp([num2str(size(FUNCTIONAL_FILE,2)),' subjects']);\nTR= X; % Repetition time\n\n\n% CONN-SPECIFIC SECTION: RUNS SETUP STEPS\n% Prepares batch structure\nclear batch;\nbatch.filename=fullfile(cwd,'conn_example.mat'); % New conn_*.mat experiment name\n\n% SETUP step\nbatch.Setup.isnew=1;\nbatch.Setup.nsubjects=NSUBJECTS;\nbatch.Setup.RT=TR; % TR (seconds)\n\nbatch.Setup.functionals=repmat({{}},[NSUBJECTS,1]); % Pre-allocation\n% Point to functional volumes for each subject/session\nfor nsub=1:NSUBJECTS\n    for nses=1:nsessions\n        batch.Setup.functionals{nsub}{nses}{1}=FUNCTIONAL_FILE{nses,nsub};\n    end\nend \nbatch.Setup.structurals=STRUCTURAL_FILE; % Point to anatomical volumes for each subject\n\n\n% Define the names and files for the covariates\ncovariate_names = {'Art_outliers_&_movement'};\nART_FILE = cellstr(conn_dir('art_regression_outliers_and_movement_warRS.mat'));\nncovariate=length(ART_FILE)/NSUBJECTS;\nART_FILE = reshape(ART_FILE, [ncovariate, NSUBJECTS]);\ndisp([num2str(size(ART_FILE,1)),'covariate']);\ndisp([num2str(size(ART_FILE,2)),'subjects']);\n\n% Add covariates\nbatch.Setup.covariates.add=1;\nbatch.Setup.covariates.names=covariate_names; \nfor ncov=1:ncovariate\n    for nsub=1:NSUBJECTS\n        for nses=1:nsessions\n            batch.Setup.covariates.files{ncov}{nsub}{nses}{1}=ART_FILE{nses,nsub,ncov}; \n        end \n    end\nend\n\n\n% Run all analyses\nconn_batch(batch);\n\n\nSTEP 2. Running CONN in the GUI\nAfter creating the project, you can open the gui by typing:\nconn\nconn('load', fullfile(cwd, 'conn_example.mat'))\nIf the project does not load up, you can open the mat file in the GUI.\n\nAtlas selection & Denoising\n\nCheck that the structural and functional volumes have all been imported correctly.\nIn the ROIs field, remove the default atlas if there is one and import yours in NIFTI format.\nCheck the ‘Atlas file’ box.\n\nIn the Options field, enable ROI-to-ROI analyses only.\n\nClick done. This may take up a few hours depending on the cohort size.\nBy default, CONN includes regressors derived from the tissue types you generated in the ROIs section (WM, CSF) of the Setup tab, and the 1st-level covariates of the Setup tab (Art_mvt). You can leave the default settings and proceed to the 1st-level analyses by clicking done.\n\n\n\n\nGenerate the Functional Connectome (FC)\n\nCreate a new analysis and select RRC (ROI-to-ROI connectivity).\nSelect the brain regions to be included in the connectome.\n\nClick done to generate the .mat file. Under the path /conn_example/results/firstlevel/RRC, you should now visualize the .mat files for each subject.\n\n\n\n\n\n\n\n\nReferences\n\nNieto-Castanon, Alfonso. 2020. Handbook of Functional Connectivity Magnetic Resonance Imaging Methods in CONN. Hilbert Press. https://doi.org/10.56441/hilbertpress.2207.6598."
  },
  {
    "objectID": "content/guide/rs-fMRI/spm.html",
    "href": "content/guide/rs-fMRI/spm.html",
    "title": "SPM12",
    "section": "",
    "text": "SPM standard pipeline\nYou can download the batch matlab script here. The preprocessing pipeline entails:\n\nRealignement & Slice timing\nCo-registration of the T1w image to the mean image created by the realignement procedure\nSegmentation\nNormalization\nSmoothing (6mm FWHM Gaussian kernel)\n\n\n\nART\nMotion parameters from the realignment are evaluated with ART (Artifact Detection Tool; Massachusetts Institute of Technology) to detect outlying volumes:\n\nInterscan movement threshold of 3 mm in translation, 0.02 rad in rotation\nGlobal interscan signal intensity of 3 SD relative to the session mean.\nIndividuals with 10% of more outlying volumes can be considered outliers"
  }
]