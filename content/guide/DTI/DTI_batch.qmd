---
title: "Diffusion Tensor Imaging (DTI) - **Batch processing**"
subtitle: A step-by-step guide to DTI preprocessing & SC generation based on MRtrix3
bibliography: references.yaml
---

Below, I provide a synthesis of the preprocessing steps using the for_each command available on MRtrix3. The full script is available for download at the bottom (see [Download]).

#### For_each command

For_each is useful when you want to run multiple subjects, with multithreading. You have to provide the path to the /*dwi directory*/ within each subject's folder where the data is stored (bvals, bvecs, etc...) as a template :

For_each will then iterate over the directories paths that match this template (*\*/dwi*), substituting the \* with each subject's folder in your dataset. *IN* is used in the MRtrix command to echo the \*.

### STEP 1. Preprocessing

``` bash
#!/bin/bash

################################################################
# MUST FOLLOW BIDS ARCHITECTURE:
# sub
#   -anat
#       -*T1w.nii.gz
#   -dwi
#       -*.bvec
#       -*.bval
#       -*.json
#       -*dwi.nii.gz
################################################################

NPROC=$(nproc)
############################### STEP 1 ###############################
#             Convert data to .mif format and denoise                #
######################################################################

# Also consider doing Gibbs denoising (using mrdegibbs). Check your diffusion data for ringing artifacts before deciding whether to use it
for_each -nthreads $NPROC -info */dwi : mrconvert *dwi.nii.gz dwi.mif 
for_each -nthreads $NPROC -info */dwi : mrconvert dwi.mif -fslgrad *.bvec *.bval dwi_header.mif 

for_each -nthreads $NPROC -info */dwi : dwidenoise dwi_header.mif dwi_den.mif -noise noise.mif 
for_each -nthreads $NPROC -info */dwi : mrdegibbs dwi_den.mif dwi_den_unr.mif 

# Extract the b0 images from the diffusion data acquired in the AP direction
for_each -nthreads $NPROC -info */dwi : dwiextract dwi_den.mif - -bzero \| mrmath - mean mean_b0_AP.mif -axis 3 

######################################################################
# Runs the dwipreproc command, which is a wrapper for eddy and topup.
#### !!! Here the CAMCAN dataset does not provide reverse encoding, hence -rpe_none !!! ####
#### !!! $NPROC/8 means you should divide by 8 as each subject's preprocessing will be performed by 8 threads already (see at the end of the line) #### !!!
######################################################################
for_each 8 -info */dwi : dwifslpreproc dwi_den.mif dwi_den_preproc.mif -pe_dir AP -rpe_none -readout_time 0.0342002 -eddy_options " --slm=linear --data_is_shelled"  -nthreads 8

# Performs bias field correction. Needs ANTs to be installed in order to use the "ants" option (use "fsl" otherwise)
for_each -nthreads $NPROC -info */dwi : dwibiascorrect ants dwi_den_preproc.mif dwi_den_preproc_unbiased.mif -bias bias.mif 

########################### STEP 2 ###################################
#             Basis function for each tissue type                    #
######################################################################

# Create a basis function from the subject's DWI data. The "dhollander" function is best used for multi-shell acquisitions; it will estimate different basis functions for each tissue type. For single-shell acquisition, use the "tournier" function instead
for_each -nthreads $NPROC -info */dwi : dwi2response dhollander dwi_den_preproc_unbiased.mif wm.txt gm.txt csf.txt -voxels voxels.mif 

#Upsample the difusion image for better resolution and tracto later
for_each -nthreads $NPROC -info */dwi : mrgrid *unbiased.mif regrid -vox 1.25 dwi_unbiased_upsampled.mif

# Create a mask for future processing steps
for_each -nthreads $NPROC -info */dwi : dwi2mask *unbiased_upsampled.mif mask_up.mif

# Performs multishell-multitissue constrained spherical deconvolution, using the basis functions estimated above
for_each -nthreads $NPROC -info */dwi : dwi2fod msmt_csd *unbiased_upsampled.mif -mask mask_up.mif wm.txt wmfod_up.mif gm.txt gmfod_up.mif csf.txt csffod_up.mif 

# Creates an image of the fiber orientation densities overlaid onto the estimated tissues (Blue=WM; Green=GM; Red=CSF)
# You should see FOD's mostly within the white matter. These can be viewed later with the command "mrview vf.mif -odf.load_sh wmfod.mif"
for_each -nthreads $NPROC -info */dwi : mrconvert -coord 3 0 wmfod_up.mif - \| mrcat csffod_up.mif gmfod_up.mif - vf_up.mif 

# Now normalize the FODs to enable comparison between subjects
for_each -nthreads $NPROC -info */dwi : mtnormalise wmfod_up.mif wmfod_norm_up.mif gmfod_up.mif gmfod_norm_up.mif csffod_up.mif csffod_norm_up.mif -mask mask_up.mif 

########################### STEP 3 ###################################
#            Create a GM/WM boundary for seed analysis               #
######################################################################

# Convert the anatomical image to .mif format, and then extract all five tissue catagories (1=GM; 2=Subcortical GM; 3=WM; 4=CSF; 5=Pathological tissue)
for_each -nthreads 8 -info */dwi : mrconvert ../anat/*T1w.nii.gz T1.mif 
for_each -nthreads $NPROC/8 -info */dwi : 5ttgen fsl T1.mif 5tt_nocoreg.mif -nthreads 8 
for_each -nthreads $NPROC -info */dwi : mrconvert 5tt_nocoreg.mif 5tt_nocoreg.nii.gz

# The following series of commands will take the average of the b0 images (which have the best contrast), convert them to NIFTI format, and use it for coregistration.
for_each -nthreads $NPROC -info */dwi : dwiextract *unbiased_upsampled.mif - -bzero \| mrmath - mean mean_b0_processed_up.mif -axis 3 
for_each -nthreads $NPROC -info */dwi : mrconvert mean_b0_processed_up.mif mean_b0_processed_up.nii.gz 


# Uses FSL commands fslroi and flirt to create a transformation matrix for regisitration between the tissue map and the b0 images
for_each -nthreads $NPROC -info */dwi : fslroi 5tt_nocoreg.nii.gz 5tt_vol0.nii.gz 0 1 #Extract the first volume of the 5tt dataset (since flirt can only use 3D images, not 4D images)
for_each -nthreads $NPROC -info */dwi : flirt -in mean_b0_processed_up.nii.gz -ref 5tt_vol0.nii.gz -interp nearestneighbour -dof 6 -omat diff2struct_fsl_up.mat
for_each -nthreads $NPROC -info */dwi : transformconvert diff2struct_fsl_up.mat mean_b0_processed_up.nii.gz 5tt_nocoreg.nii.gz flirt_import diff2struct_mrtrix_up.txt 
for_each -nthreads $NPROC -info */dwi : mrtransform 5tt_nocoreg.mif -linear diff2struct_mrtrix_up.txt -inverse 5tt_coreg_up.mif 

#Create a seed region along the GM/WM boundary
for_each -nthreads $NPROC -info */dwi : 5tt2gmwmi 5tt_coreg_up.mif gmwmSeed_coreg_up.mif
```

### STEP 2. Streamline generation

Make sure to allocate at least 4Go of space for each subject on your local disk as streamline generation can get quite heavy.

``` bash
#!/bin/bash

########################## STEP 4 ###################################
#                 Run the streamline analysis                        #
######################################################################

# MRtrix3 recommend about 100 million tracks. Here I use 10 million, if only to save time. Read their papers and then make a decision
for_each -nthreads 8 -info */dwi : tckgen -act 5tt_coreg_up.mif -backtrack -seed_gmwmi gmwmSeed_coreg_up.mif -nthreads 8 -maxlength 250 -cutoff 0.06 -select 10000k wmfod_norm_up.mif tracks_10M_up.tck 

# Extract a subset of tracks (here, 200 thousand) for ease of visualization
# tckedit tracks_10M.tck -number 200k smallerTracks_200k.tck

# Reduce the number of streamlines with tcksift
for_each -nthreads 8 -info */dwi : tcksift2 -act 5tt_coreg_up.mif -out_mu sift_mu_up.txt -out_coeffs sift_coeffs_up.txt -nthreads 8 tracks_10M_up.tck wmfod_norm_up.mif sift_1M_up.txt 
```

### STEP 3. Recon-all

Check the [parallel processing section](parallel.qmd) to speed up this step using parallel computing**.** Make sure you've downloaded the ***lh*** and ***rh.hcpmmp1 annot*** files in the supplementary files [here](https://osf.io/fkyht/#!) and put them into **\$SUBJECTS_DIR/fsaverage/label**.

### STEP 4. Generate the Structural Connectome (SC)

``` bash
#!/bin/bash

for_each -nthreads $NPROC -info */dwi : mrconvert –datatype uint32 hcpmmp1.mgz  hcpmmp1.mif 

# Replace the random integers of the hcpmmp1.mif file with integers
# that start at 1 and increase by 1.
for_each -nthreads $NPROC -info */dwi : labelconvert hcpmmp1.mif $MRtrix3/share/mrtrix3/labelconvert/hcpmmp1_original.txt $MRtrix3/share/mrtrix3/labelconvert/hcpmmp1_ordered.txt hcpmmp1_parcels_nocoreg.mif 

# Register the ordered atlas-based volumetric parcellation to diffusion space.
for_each -nthreads $NPROC -info */dwi : mrtransform hcpmmp1_parcels_nocoreg.mif –linear diff2struct_mrtrix_up.txt –inverse –datatype uint32 hcpmmp1_parcels_coreg_up.mif 

# Create a whole-brain connectome, representing the streamlines between each parcellation pair in the atlas (in this case, 379x379). The "symmetric" option will make the lower diagonal the same as the upper diagonal, and the "scale_invnodevol" option will scale the connectome by the inverse of the size of the node

for_each -nthreads $NPROC -info * : tck2connectome -symmetric -zero_diagonal -scale_invnodevol -tck_weights_in IN/dwi/sift_1M_up.txt IN/dwi/tracks_10M_up.tck IN/dwi/hcpmmp1_parcels_coreg_up.mif IN/dwi/IN_hcpmmp1_parcels_coreg_up.csv -out_assignment IN/dwi/assignments_IN_hcpmmp1_parcels_coreg_up.csv 

# For a given subject, Visualize the connectome in MRtrix3
mrview hcpmmp1_parcels_coreg_up.mif -connectome.init hcpmmp1_parcels_coreg_up.mif -connectome.load sub*_up.csv
```

You can then copy and save the structural connectomes wherever you like:

``` bash
find . -name \sub-*.csv -exec cp {} /path/to/where you want to save the SC \;
```

------------------------------------------------------------------------

### OPTIONAL. FA-weighted connectome

``` bash
# Generate the RGB-colored FA map
for_each -nthreads $NPROC -info */dwi : dwi2tensor IN/*unbiased_upsampled.mif - \| tensor2metric - -fa - \| mrcalc - -abs IN/FA_up.mif

# Generate the connectome
for_each -nthreads $NPROC -info * : tcksample IN/dwi/tracks_10M_up.tck IN/dwi/FA_up.mif IN/dwi/IN_mean_FA_per_streamline_up.csv -stat_tck mean

for_each -nthreads $NPROC -info * : tck2connectome -symmetric dwi/tracks_10M_up.tck -tck_weights_in dwi/sift_1M_up.txt dwi/hcpmmp1_parcels_coreg_up.mif dwi/IN_mean_FA_connectome_up.csv -scale_file dwi/IN_mean_FA_per_streamline_up.csv -stat_edge mean
```

------------------------------------------------------------------------

## Download

**You can download the full preprocessing script** [here](https://github.com/ClementGuichet/clementguichet.github.io/blob/main/content/downloads/batch_full_preproc.sh) **and run it by typing this command in the folder that contains your subject's data:**

``` bash
bash batch_full_preproc.sh
```

Before running the script, open it and change the following parameters:

-   ***dwifslpreproc***: check your json file for the *PhaseEncodingDirection* (-pe_dir), the total readout time. More information on [MRtrix3 documentation](https://www.mrtrix.org/documentation/).

-   If you wish to generate a connectome with HCP regions, make sure you've downloaded the ***lh*** and ***rh.hcpmmp1 annot*** files in the supplementary files [here](https://osf.io/fkyht/#!) and put them into **\$SUBJECTS_DIR/fsaverage/label** (see also [Recon-all with parallel computing](parallel.qmd)).
