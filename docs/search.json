[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "What you will found",
    "section": "",
    "text": "This site hosts documentation to preprocess and analyze structural (DTI), and functional (rs-fMRI) data with the latest tools available.\n\n\n\n\nFor any inquiry, please contact me at: guichetc@univ-grenoble-alpes.fr"
  },
  {
    "objectID": "content/guide/rs-fMRI/conn.html",
    "href": "content/guide/rs-fMRI/conn.html",
    "title": "CONN",
    "section": "",
    "text": "Following the standard preprocessing pipeline, the CONN toolbox (Whitfield-Gabrieli and Nieto-Castanon 2012) takes care of the FC generation after denoising (Behzadi et al. 2007). This is an add-on to SPM that can be downloaded here.\n\nSTEP 1. Importing the data into a new CONN project\nThis script will create a new conn project named conn_example and automatically import the functional and structural volumes for the set number of subjects.\n% Created by Andrew Jahn, University of Michigan, 02.27.2020\n% Adapted by Clément Guichet, UGA, LPNC, 07.01.2023\n\n% FIND functional/structural files\nNSUBJECTS= ??;\ncwd=pwd;\n\n# the smoothed out spatially preprocessed volumes, conn will automatically bind them to the unsmoothed ones\nFUNCTIONAL_FILE=cellstr(conn_dir('swar*.nii'));\nSTRUCTURAL_FILE=cellstr(conn_dir('wm*.nii'));\nif rem(length(FUNCTIONAL_FILE),NSUBJECTS),error('mismatch number of functional files %n', length(FUNCTIONAL_FILE));end\nif rem(length(STRUCTURAL_FILE),NSUBJECTS),error('mismatch number of anatomical files %n', length(FUNCTIONAL_FILE));end\nnsessions=length(FUNCTIONAL_FILE)/NSUBJECTS;\nFUNCTIONAL_FILE=reshape(FUNCTIONAL_FILE,[nsessions, NSUBJECTS]);\nSTRUCTURAL_FILE={STRUCTURAL_FILE{1:NSUBJECTS}};\ndisp([num2str(size(FUNCTIONAL_FILE,1)),' sessions']);\ndisp([num2str(size(FUNCTIONAL_FILE,2)),' subjects']);\nTR= ??; % Repetition time\n\n\n% CONN-SPECIFIC SECTION: RUNS SETUP STEPS\n% Prepares batch structure\nclear batch;\nbatch.filename=fullfile(cwd,'conn_example.mat'); % New conn_*.mat experiment name\n\n% SETUP step\nbatch.Setup.isnew=1;\nbatch.Setup.nsubjects=NSUBJECTS;\nbatch.Setup.RT=TR; % TR (seconds)\n\nbatch.Setup.functionals=repmat({{}},[NSUBJECTS,1]); % Pre-allocation\n% Point to functional volumes for each subject/session\nfor nsub=1:NSUBJECTS\n    for nses=1:nsessions\n        batch.Setup.functionals{nsub}{nses}{1}=FUNCTIONAL_FILE{nses,nsub};\n    end\nend \nbatch.Setup.structurals=STRUCTURAL_FILE; % Point to anatomical volumes for each subject\n\n\n% Define the names and files for the covariates\ncovariate_names = {'Art_outliers_&_movement'};\nART_FILE = cellstr(conn_dir('art_regression_outliers_and_movement_warRS.mat'));\nncovariate=length(ART_FILE)/NSUBJECTS;\nART_FILE = reshape(ART_FILE, [ncovariate, NSUBJECTS]);\ndisp([num2str(size(ART_FILE,1)),'covariate']);\ndisp([num2str(size(ART_FILE,2)),'subjects']);\n\n% Add covariates\nbatch.Setup.covariates.add=1;\nbatch.Setup.covariates.names=covariate_names; \nfor ncov=1:ncovariate\n    for nsub=1:NSUBJECTS\n        for nses=1:nsessions\n            batch.Setup.covariates.files{ncov}{nsub}{nses}{1}=ART_FILE{nses,nsub,ncov}; \n        end \n    end\nend\n\n\n% Run all analyses\nconn_batch(batch);\n\n\nSTEP 2. Running CONN in the GUI\nAfter creating the project, you can open the gui by typing:\nconn\nconn('load', fullfile(cwd, 'conn_example.mat'))\nIf the project does not load up, you can open the mat file in the GUI.\n\nAtlas selection & Denoising\n\nCheck that the structural and functional volumes have all been imported correctly.\nIn the ROIs field, remove the default atlas if there is one and import yours in NIFTI format.\nCheck the ‘Atlas file’ box.\n\nIn the Options field, enable ROI-to-ROI analyses only.\n\nClick done. This may take up a few hours depending on the cohort size.\nBy default, CONN includes regressors derived from the tissue types you generated in the ROIs section (WM, CSF) of the Setup tab, and the 1st-level covariates of the Setup tab (Art_mvt). You can leave the default settings and proceed to the 1st-level analyses by clicking done.\n\n\n\n\nGenerate the Functional Connectome (FC)\n\nCreate a new analysis and select RRC (ROI-to-ROI connectivity).\nSelect the brain regions to be included in the connectome.\n\nClick done to generate the .mat file. Under the path /conn_example/results/firstlevel/RRC, you should now visualize the .mat files for each subject.\n\n\n\n\n\n\nLearn how to analyze these functional connectomes with graph theory here.\n\n\n\n\n\n\nReferences\n\nBehzadi, Yashar, Khaled Restom, Joy Liau, and Thomas T. Liu. 2007. “A Component Based Noise Correction Method (CompCor) for BOLD and Perfusion Based fMRI.” NeuroImage 37 (1): 90–101. https://doi.org/10.1016/j.neuroimage.2007.04.042.\n\n\nWhitfield-Gabrieli, Susan, and Alfonso Nieto-Castanon. 2012. “Conn : A Functional Connectivity Toolbox for Correlated and Anticorrelated Brain Networks.” Brain Connectivity 2 (3): 125–41. https://doi.org/10.1089/brain.2012.0073."
  },
  {
    "objectID": "content/guide/DTI/parallel.html",
    "href": "content/guide/DTI/parallel.html",
    "title": "Parallel processing",
    "section": "",
    "text": "Install Homebrew with the following command:\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\nThen install parallel:\nbrew install parallel"
  },
  {
    "objectID": "content/guide/DTI/parallel.html#software-installation",
    "href": "content/guide/DTI/parallel.html#software-installation",
    "title": "Parallel processing",
    "section": "",
    "text": "Install Homebrew with the following command:\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\nThen install parallel:\nbrew install parallel"
  },
  {
    "objectID": "content/guide/DTI/parallel.html#using-the-parallel-command",
    "href": "content/guide/DTI/parallel.html#using-the-parallel-command",
    "title": "Parallel processing",
    "section": "Using the parallel command",
    "text": "Using the parallel command\nParallel is run by piping the ls command into the parallel command:\nls *.nii | parallel --jobs &lt;nproc --all&gt; recon-all -s {.}_recon -i {} -all\n--jobs N indicates that N cores will be used to analyze the data and that each instance of recon-all will be assigned to a different core.\nThe full bash script consists in copying the T1.nii.gz images in the new directory (FS), unzip them, run and store the output of recon-all in this directory\n#!/bin/bash\n\n# Assuming you are in the raw_data directory which lists all the subjects folders\nmkdir FS\ncd FS\n\n# grab the list of subject name\nls ../raw_data | grep ^sub- &gt; subjList.txt\n\n# Path to the anatomical T1 image\nfor sub in `cat subjList.txt`; do\n    cp ../raw_data/${sub}/anat/${sub}_T1w.nii.gz .\ndone\n\n# Unzip\ngunzip *.gz\n\n# Story output in the current directory\n# This avoids permission error\nSUBJECTS_DIR=`pwd`\n\nls *.nii | parallel --jobs &lt;nproc --all&gt; recon-all -s {.}_recon -i {} -all\n\n# Remove the copied T1.nii.gz files\nrm *.nii"
  },
  {
    "objectID": "content/guide/DTI/basic_setup.html",
    "href": "content/guide/DTI/basic_setup.html",
    "title": "Basic setup",
    "section": "",
    "text": "The pipelines work with Linux or WSL2 for Windows already installed on your system. I also assume you are familiar with the basic UNIX commands. Otherwise you can check this tutorial.\nCheck that WSL2 is running by typing this command in PowerShell:\n  wsl -l -v \n# You should see something like this\n  NAME                   STATE           VERSION\n  Ubuntu-22.04           Running         2\n  \n# If you have WSL1, you can update to WSL2 by typing \n  wsl --set-default-version 2 wsl --set-version Ubuntu-22.04 2\nOtherwise, you can install Ubuntu by pasting the following commands:\n1. Enable WSL by opening PowerShell as administrator\n    wsl --install -d Ubuntu-22.04\n2. Restart your computer\n3. Start the Ubuntu app to open a Ubuntu shell\n4. Set up a username and password\nYou’ll also need to GUI for WSL. I recommend you install VcXsrv on your system, which is a free X-sever on Windows. After downloading and installing VcXsrv with default options, run Xlaunch (which gets installed automatically) and perform the following configuration:\n\nDisplay setting: select multiple windows option\nClient startup: check the Start no client option\nExtra setting: make sure “Disable access control” is enabled and “native opengl” is disabled\nAdd this to your .bashrc file:\n echo \"export DISPLAY=\\$(grep nameserver /etc/resolv.conf  | awk '{print \\$2; exit}'):0\" &gt;&gt; ~/.bashrc\n echo \"export LIBGL_ALWAYS_INDIRECT=0\" &gt;&gt; ~/.bashrc\n # For Windows 11 users, add this as well\n  echo \"export LIBGL_ALWAYS_SOFTWARE=1\" &gt;&gt; ~/.bashrc\nTry running glxgears. A window with three spinning gears should open.\nTroubleshooting:\n\nMake sure you are not using a VPN.\nGo to Control panel &gt; System and security &gt; Windows defender firewall &gt; Advanced settings &gt; Inbound rules and make sure that the VcXsrv rules are not set to block - if they are you will need to edit the VcXsrv rule and change it from block to allow."
  },
  {
    "objectID": "content/about.html",
    "href": "content/about.html",
    "title": "About",
    "section": "",
    "text": "I’m a 2nd-year PhD Student in Cognitive and Computational Neuroscience at LPNC, CNRS UMR 5105, UGA, Grenoble, France. My research project is about modeling how our brain reorganizes across the lifespan to preserve optimal cognitive (language) performances. Find out more about our team LPNC-LANG here."
  },
  {
    "objectID": "content/about.html#education",
    "href": "content/about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\nPhD candidate (2022-2025) | LPNC, UGA | Supervised by Prof. Monica Baciu and Prof. Martial Mermillod\nMSc degree in Research in Psychology (2020-2022) | LPNC, UGA | Master theses in psycholinguistics supervised by Prof. Elsa Spinelli and Prof. Boris New\nBachelor’s degree in Psychology (2017-2020) | UGA"
  },
  {
    "objectID": "content/about.html#experience",
    "href": "content/about.html#experience",
    "title": "About",
    "section": "Experience",
    "text": "Experience\nCo-analyst & Peer-reviewer (April 2022 - ongoing) | Center of Open Science (COS) | Multi100 project\nCNRS Individual contractor (Sept 2021 - March 2022 incl.) | GIPSA-lab, UGA | Supervised by Takayuki Ito\nCNRS Research intern (June - Aug 2021 incl.) | GIPSA-lab, UGA | Supervised by Takayuki Ito and Jean-Luc Schwartz"
  },
  {
    "objectID": "content/guide/DTI/DTI.html",
    "href": "content/guide/DTI/DTI.html",
    "title": "Diffusion Tensor Imaging (DTI)",
    "section": "",
    "text": "The pipeline revolves around MRtrix3 which works hand in hand with Freesurfer, FSL, and ANTs\n\n\nDownload MRtrix3 by copy pasting this command in a bash terminal:\n# Clone the MRtrix3 repo\ngit clone https://github.com/MRtrix3/mrtrix3.git\n# Configure the install\ncd mrtrix3\n./configure\n# Build the binaries\n./build\n# Add it to your path\n./set_path\nIf everything went fine, you should now see a window pop up when typing mrview on the command line.\n\n\n\n\n\nFollow the instructions here.\n\n\n\n\nIn your “HOME” directory (cd $HOME), download the Freesurfer installer package:\nwget https://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/7.4.1/freesurfer_ubuntu22-7.4.1_amd64.deb\nMake sure to install the Freesurfer distribution under the path /usr/local/freesurfer/7.4.1\ncd /usr/local\nsudo apt-get -y install ./freesurfer_ubuntu22-7.4.1_amd64.deb\nAdd it to your PATH\necho \"export FREESURFER_HOME=/usr/local/freesurfer/7.4.1\" &gt;&gt; $HOME/.bashrc\nGet the free license online, download it in your home directory and add this command in your .bashrc:\nexport FS_LICENSE=$HOME/license.txt\nSet the Freesurfer env to be setup when you open the shell:\necho \"source $FREESURFER_HOME/SetUpFreeSurfer.sh\" &gt;&gt; $HOME/.bashrc\n\nOpen a new Ubuntu linux terminal window and verify you see the following output showing the Freesurfer environment has been set. If everything went fine, you should see this output:\n - - - - - - - -freesurfer-linux-ubuntu22_x86_64-7.4.1-20230614-7eb8460- - - - - - - -\nSetting up environment for FreeSurfer/FS-FAST (and FSL)\nFREESURFER_HOME   /usr/local/freesurfer/7.4.1\nFSFAST_HOME       /usr/local/freesurfer/7.4.1/fsfast\nFSF_OUTPUT_FORMAT nii.gz\nSUBJECTS_DIR      /usr/local/freesurfer/7.4.1/subjects\nMNI_DIR           /usr/local/freesurfer/7.4.1/mni\n\n\n\n\n\nDownload the FSL installer script online. When selecting the OS to install on the download page, make sure to select Ubuntu and not Windows.\nRun the installer script by replacing &lt;UserName&gt; with your windows user name. Make sure to install it under the path /usr/local/fsl/.\npython \"/mnt/c/Users/&lt;WindowsUserName&gt;/Downloads/fslinstaller.py\"\n\n\n\n\n\nDownload the ANTs installer script\nIn the terminal, enter:\nbash installANTs.sh\nAdd it to your PATH\necho \"ANTSPATH=$HOME/install/bin/\" &gt;&gt; $HOME/.bashrc\necho \"export PATH=${ANTSPATH}:$PATH\" &gt;&gt; $HOME/.bashrc"
  },
  {
    "objectID": "content/guide/DTI/DTI.html#software-installation",
    "href": "content/guide/DTI/DTI.html#software-installation",
    "title": "Diffusion Tensor Imaging (DTI)",
    "section": "",
    "text": "The pipeline revolves around MRtrix3 which works hand in hand with Freesurfer, FSL, and ANTs\n\n\nDownload MRtrix3 by copy pasting this command in a bash terminal:\n# Clone the MRtrix3 repo\ngit clone https://github.com/MRtrix3/mrtrix3.git\n# Configure the install\ncd mrtrix3\n./configure\n# Build the binaries\n./build\n# Add it to your path\n./set_path\nIf everything went fine, you should now see a window pop up when typing mrview on the command line.\n\n\n\n\n\nFollow the instructions here.\n\n\n\n\nIn your “HOME” directory (cd $HOME), download the Freesurfer installer package:\nwget https://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/7.4.1/freesurfer_ubuntu22-7.4.1_amd64.deb\nMake sure to install the Freesurfer distribution under the path /usr/local/freesurfer/7.4.1\ncd /usr/local\nsudo apt-get -y install ./freesurfer_ubuntu22-7.4.1_amd64.deb\nAdd it to your PATH\necho \"export FREESURFER_HOME=/usr/local/freesurfer/7.4.1\" &gt;&gt; $HOME/.bashrc\nGet the free license online, download it in your home directory and add this command in your .bashrc:\nexport FS_LICENSE=$HOME/license.txt\nSet the Freesurfer env to be setup when you open the shell:\necho \"source $FREESURFER_HOME/SetUpFreeSurfer.sh\" &gt;&gt; $HOME/.bashrc\n\nOpen a new Ubuntu linux terminal window and verify you see the following output showing the Freesurfer environment has been set. If everything went fine, you should see this output:\n - - - - - - - -freesurfer-linux-ubuntu22_x86_64-7.4.1-20230614-7eb8460- - - - - - - -\nSetting up environment for FreeSurfer/FS-FAST (and FSL)\nFREESURFER_HOME   /usr/local/freesurfer/7.4.1\nFSFAST_HOME       /usr/local/freesurfer/7.4.1/fsfast\nFSF_OUTPUT_FORMAT nii.gz\nSUBJECTS_DIR      /usr/local/freesurfer/7.4.1/subjects\nMNI_DIR           /usr/local/freesurfer/7.4.1/mni\n\n\n\n\n\nDownload the FSL installer script online. When selecting the OS to install on the download page, make sure to select Ubuntu and not Windows.\nRun the installer script by replacing &lt;UserName&gt; with your windows user name. Make sure to install it under the path /usr/local/fsl/.\npython \"/mnt/c/Users/&lt;WindowsUserName&gt;/Downloads/fslinstaller.py\"\n\n\n\n\n\nDownload the ANTs installer script\nIn the terminal, enter:\nbash installANTs.sh\nAdd it to your PATH\necho \"ANTSPATH=$HOME/install/bin/\" &gt;&gt; $HOME/.bashrc\necho \"export PATH=${ANTSPATH}:$PATH\" &gt;&gt; $HOME/.bashrc"
  },
  {
    "objectID": "content/guide/DTI/DTI.html#batch-processing",
    "href": "content/guide/DTI/DTI.html#batch-processing",
    "title": "Diffusion Tensor Imaging (DTI)",
    "section": "Batch processing",
    "text": "Batch processing\nI recommend you check Andrew Jahn’s book for a thorough walk-through DTI analysis with MRtrix3. Below, I provide a synthesis of the preprocessing steps using the for_each command available on MRtrix3. You may want to tweak it to your systems specs and size of your cohort for a smooth run.\n\nLogical processors\nTo determine the number of available logical processors on your system, enter nproc --all in the terminal. The output number is the argument we’ll pass to the -nthreads flag below. I recommend you spare some of it if you wish to perform other tasks while the pipeline is running. For example, I only use 32 out of the 48 available on my system.\n\n\nFor_each command\nFor_each is useful when you want to run multiple subjects, with multi-threading if possible. You have to provide the path to your dwi directory where your raw data is stored (bvals, bvecs, etc…) as a template :\nassuming you are in the raw_data directory: */dwi\nIn a BIDS-compliant dataset, for_each will then iterate over the directories paths that match this template, substituting the * with each subject in your dataset.\nIN is used in the MRtrix command to echo the path to the dwi directory of each subject.\n\n\nPreprocessing\n#!/bin/bash\n\n############################### STEP 1 ###############################\n#             Convert data to .mif format and denoise                #\n######################################################################\n\n# Also consider doing Gibbs denoising (using mrdegibbs). Check your diffusion data for ringing artifacts before deciding whether to use it\nfor_each -nthreads &lt;nproc -all&gt; -info */dwi : mrconvert IN/*dwi.nii.gz IN/dwi.mif \nfor_each -nthreads &lt;nproc -all&gt; -info */dwi : mrconvert IN/dwi.mif -fslgrad IN/*.bvec IN/*.bval IN/dwi_header.mif \n\nfor_each -nthreads &lt;nproc -all&gt; -info */dwi : dwidenoise IN/dwi_header.mif IN/dwi_den.mif -noise IN/noise.mif \nfor_each -nthreads &lt;nproc -all&gt; -info */dwi : mrdegibbs IN/dwi_den.mif IN/dwi_den_unr.mif \n\n# Extract the b0 images from the diffusion data acquired in the AP direction\nfor_each -nthreads &lt;nproc -all&gt; -info */dwi : dwiextract IN/dwi_den.mif - -bzero \\| mrmath - mean IN/mean_b0_AP.mif -axis 3 \n\n######################################################################\n# Runs the dwipreproc command, which is a wrapper for eddy and topup.\n#### !!! Here the CAMCAN dataset does not provide reverse encoding, hence -rpe_none !!! ####\n#### !!! &lt;nproc --all&gt;/8 means you should divide by 8 as each subject's preprocessing will be performed by 8 threads already (see at the end of the line) #### !!!\n######################################################################\nfor_each &lt;nproc --all&gt;/8 -info */dwi : dwifslpreproc IN/dwi_den.mif IN/dwi_den_preproc.mif -pe_dir AP -rpe_none -readout_time 0.0342002 -eddy_options \" --slm=linear --data_is_shelled\"  -nthreads 8\n\n# Performs bias field correction. Needs ANTs to be installed in order to use the \"ants\" option (use \"fsl\" otherwise)\nfor_each -nthreads &lt;nproc -all&gt; -info */dwi : dwibiascorrect ants IN/dwi_den_preproc.mif IN/dwi_den_preproc_unbiased.mif -bias IN/bias.mif \n\n# Create a mask for future processing steps\nfor_each -nthreads &lt;nproc -all&gt; -info */dwi : dwi2mask IN/dwi_den_preproc_unbiased.mif IN/mask.mif \n\n########################### STEP 2 ###################################\n#             Basis function for each tissue type                    #\n######################################################################\n\n# Create a basis function from the subject's DWI data. The \"dhollander\" function is best used for multi-shell acquisitions; it will estimate different basis functions for each tissue type. For single-shell acquisition, use the \"tournier\" function instead\nfor_each -nthreads &lt;nproc -all&gt; -info */dwi : dwi2response dhollander IN/dwi_den_preproc_unbiased.mif IN/wm.txt IN/gm.txt IN/csf.txt -voxels IN/voxels.mif \n\n# Performs multishell-multitissue constrained spherical deconvolution, using the basis functions estimated above\nfor_each -nthreads &lt;nproc -all&gt; -info */dwi : dwi2fod msmt_csd IN/dwi_den_preproc_unbiased.mif -mask IN/mask.mif IN/wm.txt IN/wmfod.mif IN/gm.txt IN/gmfod.mif IN/csf.txt IN/csffod.mif \n\n# Creates an image of the fiber orientation densities overlaid onto the estimated tissues (Blue=WM; Green=GM; Red=CSF)\n# You should see FOD's mostly within the white matter. These can be viewed later with the command \"mrview vf.mif -odf.load_sh wmfod.mif\"\nfor_each -nthreads &lt;nproc -all&gt; -info */dwi : mrconvert -coord 3 0 IN/wmfod.mif - \\| mrcat IN/csffod.mif IN/gmfod.mif - IN/vf.mif \n\n# Now normalize the FODs to enable comparison between subjects\nfor_each -nthreads &lt;nproc -all&gt; -info */dwi : mtnormalise IN/wmfod.mif IN/wmfod_norm.mif IN/gmfod.mif IN/gmfod_norm.mif IN/csffod.mif IN/csffod_norm.mif -mask IN/mask.mif \n\n########################### STEP 3 ###################################\n#            Create a GM/WM boundary for seed analysis               #\n######################################################################\n\n# Convert the anatomical image to .mif format, and then extract all five tissue catagories (1=GM; 2=Subcortical GM; 3=WM; 4=CSF; 5=Pathological tissue)\nfor_each -nthreads &lt;nproc -all&gt; -info */dwi : mrconvert IN/../anat/*T1w.nii.gz IN/T1.mif \nfor_each &lt;nproc --all&gt;/8 -info */dwi : 5ttgen fsl IN/T1.mif IN/5tt_nocoreg.mif -nthreads 8 \n\n# The following series of commands will take the average of the b0 images (which have the best contrast), convert them and the 5tt image to NIFTI format, and use it for coregistration.\nfor_each -nthreads &lt;nproc -all&gt; -info */dwi : dwiextract IN/dwi_den_preproc_unbiased.mif - -bzero \\| mrmath - mean IN/mean_b0_processed.mif -axis 3 \nfor_each -nthreads &lt;nproc -all&gt; -info */dwi : mrconvert IN/mean_b0_processed.mif IN/mean_b0_processed.nii.gz \nfor_each -nthreads &lt;nproc -all&gt; -info */dwi : mrconvert IN/5tt_nocoreg.mif IN/5tt_nocoreg.nii.gz \n\n# Uses FSL commands fslroi and flirt to create a transformation matrix for regisitration between the tissue map and the b0 images\nfor_each -nthreads &lt;nproc -all&gt; -info */dwi : fslroi IN/5tt_nocoreg.nii.gz IN/5tt_vol0.nii.gz 0 1 #Extract the first volume of the 5tt dataset (since flirt can only use 3D images, not 4D images)\nfor_each -nthreads &lt;nproc -all&gt; -info */dwi : flirt -in IN/mean_b0_processed.nii.gz -ref IN/5tt_vol0.nii.gz -interp nearestneighbour -dof 6 -omat IN/diff2struct_fsl.mat\nfor_each -nthreads &lt;nproc -all&gt; -info */dwi : transformconvert IN/diff2struct_fsl.mat IN/mean_b0_processed.nii.gz IN/5tt_nocoreg.nii.gz flirt_import IN/diff2struct_mrtrix.txt \nfor_each -nthreads &lt;nproc -all&gt; -info */dwi : mrtransform IN/5tt_nocoreg.mif -linear IN/diff2struct_mrtrix.txt -inverse IN/5tt_coreg.mif \n\n#Create a seed region along the GM/WM boundary\nfor_each -nthreads &lt;nproc -all&gt; -info */dwi : 5tt2gmwmi IN/5tt_coreg.mif IN/gmwmSeed_coreg.mif \n\n\nStreamline generation\nMake sure to allocate at least 5Go of space for each subject on your local disk as streamline generation can get quite heavy. Here we generate 10 millions streamlines and then reduce that number using the tckgen and tcksift2 command.\n#!/bin/bash\n\n########################## STEP 4 ###################################\n#                 Run the streamline analysis                        #\n######################################################################\n\n# Create streamlines\n# Note that the \"right\" number of streamlines is still up for debate. Last I read from the MRtrix documentation,\n# They recommend about 100 million tracks. Here I use 10 million, if only to save time. Read their papers and then make a decision\nfor_each -nthreads &lt;nproc --all&gt;/8 -info */dwi : tckgen -act IN/5tt_coreg.mif -backtrack -seed_gmwmi IN/gmwmSeed_coreg.mif -nthreads 8 -maxlength 250 -cutoff 0.06 -select 10000k IN/wmfod_norm.mif IN/tracks_10M.tck \n\n# Extract a subset of tracks (here, 200 thousand) for ease of visualization\n# tckedit tracks_10M.tck -number 200k smallerTracks_200k.tck\n\n# Reduce the number of streamlines with tcksift\nfor_each -nthreads &lt;nproc --all&gt;/8 -info */dwi : tcksift2 -act IN/5tt_coreg.mif -out_mu IN/sift_mu.txt -out_coeffs IN/sift_coeffs.txt -nthreads 8 IN/tracks_10M.tck IN/wmfod_norm.mif IN/sift_1M.txt \n\n\nRecon-all\nDownload the lh and rh.hcpmmp1 annot files in the supplementary files here and put them into $SUBJECTS_DIR/fsaverage/label. This allows to prepare the T1 image for the HCP MMP 1.0 atlas (Glasser et al. 2016).\n#!/bin/bash\n\n# 1. Since the HCPMMP1-atlas is a FreeSurfer-based atlas, you have to preprocess the T1 image in FreeSurfer. \n# This will take several hours to complete.\nrecon-all –s &lt;sub&gt;_recon –i T1_raw.nii.gz –all\n\n# If the recon folder specific to your subject haq not been placed into $SUBJECTS_DIR, you may have to move it manually\n# Copy into freesurfer's subjects directory\necho &lt;password&gt; | sudo -S cp -r *recon $SUBJECTS_DIR\n# Grant permission to write the file\necho &lt;password&gt; | sudo -S chmod -R a+w /usr/local/freesurfer\n\n# 2. Map the annotation files of the HCP MMP 1.0 atlas from fsaverage to you subject for both hemispheres:\nmri_surf2surf --srcsubject fsaverage --trgsubject &lt;sub&gt;_recon --hemi lh --sval-annot $SUBJECTS_DIR/fsaverage/label/lh.hcpmmp1.annot --tval\n$SUBJECTS_DIR/&lt;sub&gt;_recon/label/lh.hcpmmp1.annot\n\nmri_surf2surf --srcsubject fsaverage --trgsubject &lt;sub&gt;_recon --hemi rh --sval-annot $SUBJECTS_DIR/fsaverage/label/rh.hcpmmp1.annot --tval $SUBJECTS_DIR/&lt;sub&gt;_recon/label/rh.hcpmmp1.annot\nThis step can be sped up with parallel computing. Click here\n\n\nGenerate the Structural Connectome (SC)\n#!/bin/bash\n\nfor_each -nthreads &lt;nproc --all&gt; -info */dwi : mrconvert –datatype uint32  IN/hcpmmp1.mgz  IN/hcpmmp1.mif -force\n\n# Replace the random integers of the hcpmmp1.mif file with integers\n# that start at 1 and increase by 1.\nfor_each -nthreads &lt;nproc --all&gt; -info */dwi : labelconvert  IN/hcpmmp1.mif $MRtrix3/share/mrtrix3/labelconvert/hcpmmp1_original.txt $MRtrix3/share/mrtrix3/labelconvert/hcpmmp1_ordered.txt  IN/hcpmmp1_parcels_nocoreg.mif -force\n\n# Register the ordered atlas-based volumetric parcellation to diffusion space.\nfor_each -nthreads &lt;nproc --all&gt; -info */dwi : mrtransform  IN/hcpmmp1_parcels_nocoreg.mif –linear  IN/diff2struct_mrtrix.txt –inverse –datatype uint32  IN/hcpmmp1_parcels_coreg.mif -force\n\n# Create a whole-brain connectome, representing the streamlines between each parcellation pair in the atlas (in this case, 379x379). The \"symmetric\" option will make the lower diagonal the same as the upper diagonal, and the \"scale_invnodevol\" option will scale the connectome by the inverse of the size of the node\n\nfor_each -nthreads &lt;nproc --all&gt; -info * : tck2connectome -symmetric -zero_diagonal -scale_invnodevol -tck_weights_in IN/dwi/sift_1M.txt IN/dwi/tracks_10M.tck IN/dwi/hcpmmp1_parcels_coreg.mif IN/dwi/IN_hcpmmp1_parcels_coreg.csv -out_assignment IN/dwi/assignments_IN_hcpmmp1_parcels_coreg.csv -force\nThis is what you should end up with. The upper left and lower right quadrant represent the left and right intra-hemispheric connections respectively.\n\n\n\n\nIn Matlab: W = importdata(‘sub-XXXXX_hcpmmp1_parcels_coreg.csv’); figure, imagesc(W, [0 1]), xlabel([’ 379 Glasser regions ‘]), ylabel(’379 Glasser regions’), title([’ Structural connectome (streamline density) ‘]); colormap(jet), colorbar, set(gcf,’color’,‘w’), set(gca,‘fontsize’,14)\n\n\nYou can then copy and save the structural connectomes wherever you like:\nfind . -name \\sub-*.csv -exec cp {} /path/to/where you want to save the SC \\;"
  },
  {
    "objectID": "content/guide/rs-fMRI/rs-fMRI.html",
    "href": "content/guide/rs-fMRI/rs-fMRI.html",
    "title": "Resting-state functional magnetic resonance (rs-fMRI)",
    "section": "",
    "text": "The pipeline is run primarily with Matlab\n\nDownload SPM by copy pasting this command in a bash terminal\nDownload CONN by copy pasting this command in a bash terminal\nDownload GraphVar"
  },
  {
    "objectID": "content/guide/rs-fMRI/rs-fMRI.html#software-installation",
    "href": "content/guide/rs-fMRI/rs-fMRI.html#software-installation",
    "title": "Resting-state functional magnetic resonance (rs-fMRI)",
    "section": "",
    "text": "The pipeline is run primarily with Matlab\n\nDownload SPM by copy pasting this command in a bash terminal\nDownload CONN by copy pasting this command in a bash terminal\nDownload GraphVar"
  },
  {
    "objectID": "content/guide/rs-fMRI/rs-fMRI.html#preprocessing-automation",
    "href": "content/guide/rs-fMRI/rs-fMRI.html#preprocessing-automation",
    "title": "Resting-state functional magnetic resonance (rs-fMRI)",
    "section": "Preprocessing automation",
    "text": "Preprocessing automation"
  },
  {
    "objectID": "content/guide/rs-fMRI/rs-fMRI.html#automating-conn-roi-to-roi-analysis",
    "href": "content/guide/rs-fMRI/rs-fMRI.html#automating-conn-roi-to-roi-analysis",
    "title": "Resting-state functional magnetic resonance (rs-fMRI)",
    "section": "Automating CONN ROI-to-ROI analysis",
    "text": "Automating CONN ROI-to-ROI analysis"
  },
  {
    "objectID": "content/publications.html",
    "href": "content/publications.html",
    "title": "Publications",
    "section": "",
    "text": "Research project:\nCognitive neuroscience is undergoing a paradigm shift. The abundance of multimodal empirical data, coupled with the unprecendented computational capabilities, is helping to redefine the links between the brain and human behavior. The brain is now understood as a vast network of interactions between cerebral regions from which cognitive operations and processes emerge.\nSpecifically, language functions (L) are not isolated but constantly interact with declarative memory (M) and executive functions (EF). However, the neural mechanisms underlying this L-M-EF dynamic remain unclear. The cognitomic perspective (structure-function-cognition) is closely linked to the identification of multimodal L-M-EF phenotypes, that is the neuropsychological implications that the language connectomic architecture places on cognition.\nThus, this project has:\n\na theoretical dimension, through the enrichment of a neurocognitive L-M-EF model\na methodological dimension, through the fusion of multimodal data required to evaluate this model (i.e. structural, functional, cognitive-behavioral)\n\nIn fine, we expect this project to enable significant advances in both fundamental and clinical research (e.g. pre-habilitation & cognitive rehabilitation).\n\nLatest:\n\nIn our latest preprint (Guichet et al. 2023), we modeled the neural mechanisms that uphold inter-cognitive functioning across the lifespan. The SENECA model has three dimensions:\n\n\n\n\n\n\n\nAt the cognitive level (CA), we show that language is not isolated but works in synergy with LTM and EF across the lifespan\nAt the cerebral level (SE), we show that DMN-FPN coupling is essential to mitigate cognitive decline, achieving an optimal balance between the cost of reorganization of neural connections and the cognitive efficiency.\nTaken together (SE-NE-CA), less DMN-FPN coupling may be responsible for a transition around 50yo towards less synergistic processing, accelerating cognitive decline in highly synergistic tasks such as lexical production.\n\n\n\nDMN-FPN coupling is associated with a Nonlinear and Emergent trajectory across the lifespan\n\n\n\n\nWhat’s next?\nWe are now investigating the structural underpinnings of the DMN-FPN coupling across the lifespan and whether SC-FC coupling can be a reliable biomarker of individuals with high vs. low cognitive reserve, thus predicting healthy cognitive aging.\n\n\nPrevious works:\n(Ashokumar et al. 2022)\n\n\n\n\n\nReferences\n\nAshokumar, Monica, Clément Guichet, Jean-Luc Schwartz, and Takayuki Ito. 2022. “Correlation Between the Effect of Orofacial Somatosensory Inputs in Speech Perception and Speech Production Performance.” Auditory Perception & Cognition, October, 1–11. https://doi.org/10.1080/25742442.2022.2134674.\n\n\nGuichet, Clément, Sonja Banjac, Martial Mermillod, Sophie Achard, and Monica Baciu. 2023. “Modeling the Neurocognitive Dynamics of Language Across the Lifespan.” Preprint. Neuroscience. https://doi.org/10.1101/2023.07.04.547510."
  }
]