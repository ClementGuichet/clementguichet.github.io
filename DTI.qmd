---
title: "**Diffusion Tensor Imaging (DTI)**"
format: html
editor: visual
subtitle: A step-by-step guide to DTI preprocessing & SC generation based on MRtrix3
bibliography: references.yaml
---

## Software installation

The pipeline revolves around MRtrix3 which works hand in hand with Freesurfer, FSL, and ANTs

### MRtrix3

Download MRtrix3 by copy pasting this command in a bash terminal:

``` bash
# Clone the MRtrix3 repo
git clone https://github.com/MRtrix3/mrtrix3.git
# Configure the install
cd mrtrix3
./configure
# Build the binaries
./build
# Add it to your path
./set_path
```

If everything went fine, you should now see a window pop up when typing *mrview* on the command line.

### Freesurfer

#### Linux

Follow the instructions [here](https://surfer.nmr.mgh.harvard.edu/fswiki//FS7_linux).

#### Windows (WSL)

1.  In your "HOME" directory (cd \$HOME), download the Freesurfer installer package:

    ``` bash
    wget https://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/7.4.1/freesurfer_ubuntu22-7.4.1_amd64.deb
    ```

2.  Make sure to install the Freesurfer distribution under the path /usr/local/freesurfer/7.4.1

    ``` bash
    cd /usr/local
    sudo apt-get -y install ./freesurfer_ubuntu22-7.4.1_amd64.deb
    ```

3.  Add it to your PATH

    ``` bash
    echo "export FREESURFER_HOME=/usr/local/freesurfer/7.4.1" >> $HOME/.bashrc
    ```

4.  Get the [free license online](https://surfer.nmr.mgh.harvard.edu/registration.html), download it in your home directory and add this command in your .bashrc:

    ``` bash
    export FS_LICENSE=$HOME/license.txt
    ```

5.  Set the Freesurfer env to be setup when you open the shell:

    ``` bash
    echo "source $FREESURFER_HOME/SetUpFreeSurfer.sh" >> $HOME/.bashrc
    ```

Open a new Ubuntu linux terminal window and verify you see the following output showing the Freesurfer environment has been set. If everything went fine, you should see this output:

``` bash
 - - - - - - - -freesurfer-linux-ubuntu22_x86_64-7.4.1-20230614-7eb8460- - - - - - - -
Setting up environment for FreeSurfer/FS-FAST (and FSL)
FREESURFER_HOME   /usr/local/freesurfer/7.4.1
FSFAST_HOME       /usr/local/freesurfer/7.4.1/fsfast
FSF_OUTPUT_FORMAT nii.gz
SUBJECTS_DIR      /usr/local/freesurfer/7.4.1/subjects
MNI_DIR           /usr/local/freesurfer/7.4.1/mni
```

### FSL

1.  Download the [FSL installer script online](https://fsl.fmrib.ox.ac.uk/fsldownloads_registration). When selecting the OS to install on the download page, [make sure to select Ubuntu and not Windows]{.underline}.

2.  Run the installer script by replacing \<UserName\> with your windows user name. Make sure to install it under the path /usr/local/fsl/.

    ``` bash
    python "/mnt/c/Users/<WindowsUserName>/Downloads/fslinstaller.py"
    ```

### ANTs

1.  Download the [ANTs installer script](https://github.com/cookpa/antsInstallExample/blob/master/installANTs.sh)

2.  In the terminal, enter:

    ``` bash
    bash installANTs.sh
    ```

3.  Add it to your PATH

    ``` bash
    echo "ANTSPATH=$HOME/install/bin/" >> $HOME/.bashrc
    echo "export PATH=${ANTSPATH}:$PATH" >> $HOME/.bashrc
    ```

## Batch processing

I recommend you check [Andrew Jahn's book](https://andysbrainbook.readthedocs.io/en/latest/MRtrix/MRtrix_Introduction.html) for a thorough walk-through DTI analysis with MRtrix3. Below, I provide a synthesis of the preprocessing steps using the for_each command available on MRtrix3. You may want to tweak it to your systems specs and size of your cohort for a smooth run.

#### Logical processors

To determine the number of available logical processors on your system, enter *nproc \--all* in the terminal. The output number is the argument we'll pass to the *-nthreads* flag below. I recommend you spare some of it if you wish to perform other tasks while the pipeline is running. For example, I only use 32 out of the 48 available on my system.

#### For_each command

For_each is useful when you want to run multiple subjects, with multi-threading if possible. You have to provide the path to your dwi directory where your raw data is stored (bvals, bvecs, etc...) as a template :

*assuming you are in the raw_data directory: \*/dwi*

In a BIDS-compliant dataset, for_each will then iterate over the directories paths that match this template, substituting the \* with each subject in your dataset.

*IN* is used in the MRtrix command to echo the path to the dwi directory of each subject.

### Preprocessing

``` bash
############################### STEP 1 ###############################
#             Convert data to .mif format and denoise                #
######################################################################

# Also consider doing Gibbs denoising (using mrdegibbs). Check your diffusion data for ringing artifacts before deciding whether to use it
for_each -nthreads <nproc -all> -info */dwi : mrconvert IN/*dwi.nii.gz IN/dwi.mif 
for_each -nthreads <nproc -all> -info */dwi : mrconvert IN/dwi.mif -fslgrad IN/*.bvec IN/*.bval IN/dwi_header.mif 

for_each -nthreads <nproc -all> -info */dwi : dwidenoise IN/dwi_header.mif IN/dwi_den.mif -noise IN/noise.mif 
for_each -nthreads <nproc -all> -info */dwi : mrdegibbs IN/dwi_den.mif IN/dwi_den_unr.mif 

# Extract the b0 images from the diffusion data acquired in the AP direction
for_each -nthreads <nproc -all> -info */dwi : dwiextract IN/dwi_den.mif - -bzero \| mrmath - mean IN/mean_b0_AP.mif -axis 3 

######################################################################
# Runs the dwipreproc command, which is a wrapper for eddy and topup.
#### !!! Here the CAMCAN dataset does not provide reverse encoding, hence -rpe_none !!! ####
#### !!! <nproc --all>/8 means you should divide by 8 as each subject's preprocessing will be performed by 8 threads already (see at the end of the line) #### !!!
######################################################################
for_each <nproc --all>/8 -info */dwi : dwifslpreproc IN/dwi_den.mif IN/dwi_den_preproc.mif -pe_dir AP -rpe_none -readout_time 0.0342002 -eddy_options " --slm=linear --data_is_shelled"  -nthreads 8

# Performs bias field correction. Needs ANTs to be installed in order to use the "ants" option (use "fsl" otherwise)
for_each -nthreads <nproc -all> -info */dwi : dwibiascorrect ants IN/dwi_den_preproc.mif IN/dwi_den_preproc_unbiased.mif -bias IN/bias.mif 

# Create a mask for future processing steps
for_each -nthreads <nproc -all> -info */dwi : dwi2mask IN/dwi_den_preproc_unbiased.mif IN/mask.mif 

########################### STEP 2 ###################################
#             Basis function for each tissue type                    #
######################################################################

# Create a basis function from the subject's DWI data. The "dhollander" function is best used for multi-shell acquisitions; it will estimate different basis functions for each tissue type. For single-shell acquisition, use the "tournier" function instead
for_each -nthreads <nproc -all> -info */dwi : dwi2response dhollander IN/dwi_den_preproc_unbiased.mif IN/wm.txt IN/gm.txt IN/csf.txt -voxels IN/voxels.mif 

# Performs multishell-multitissue constrained spherical deconvolution, using the basis functions estimated above
for_each -nthreads <nproc -all> -info */dwi : dwi2fod msmt_csd IN/dwi_den_preproc_unbiased.mif -mask IN/mask.mif IN/wm.txt IN/wmfod.mif IN/gm.txt IN/gmfod.mif IN/csf.txt IN/csffod.mif 

# Creates an image of the fiber orientation densities overlaid onto the estimated tissues (Blue=WM; Green=GM; Red=CSF)
# You should see FOD's mostly within the white matter. These can be viewed later with the command "mrview vf.mif -odf.load_sh wmfod.mif"
for_each -nthreads <nproc -all> -info */dwi : mrconvert -coord 3 0 IN/wmfod.mif - \| mrcat IN/csffod.mif IN/gmfod.mif - IN/vf.mif 

# Now normalize the FODs to enable comparison between subjects
for_each -nthreads <nproc -all> -info */dwi : mtnormalise IN/wmfod.mif IN/wmfod_norm.mif IN/gmfod.mif IN/gmfod_norm.mif IN/csffod.mif IN/csffod_norm.mif -mask IN/mask.mif 

########################### STEP 3 ###################################
#            Create a GM/WM boundary for seed analysis               #
######################################################################

# Convert the anatomical image to .mif format, and then extract all five tissue catagories (1=GM; 2=Subcortical GM; 3=WM; 4=CSF; 5=Pathological tissue)
for_each -nthreads <nproc -all> -info */dwi : mrconvert IN/../anat/*T1w.nii.gz IN/T1.mif 
for_each <nproc --all>/8 -info */dwi : 5ttgen fsl IN/T1.mif IN/5tt_nocoreg.mif -nthreads 8 

# The following series of commands will take the average of the b0 images (which have the best contrast), convert them and the 5tt image to NIFTI format, and use it for coregistration.
for_each -nthreads <nproc -all> -info */dwi : dwiextract IN/dwi_den_preproc_unbiased.mif - -bzero \| mrmath - mean IN/mean_b0_processed.mif -axis 3 
for_each -nthreads <nproc -all> -info */dwi : mrconvert IN/mean_b0_processed.mif IN/mean_b0_processed.nii.gz 
for_each -nthreads <nproc -all> -info */dwi : mrconvert IN/5tt_nocoreg.mif IN/5tt_nocoreg.nii.gz 

# Uses FSL commands fslroi and flirt to create a transformation matrix for regisitration between the tissue map and the b0 images
for_each -nthreads <nproc -all> -info */dwi : fslroi IN/5tt_nocoreg.nii.gz IN/5tt_vol0.nii.gz 0 1 #Extract the first volume of the 5tt dataset (since flirt can only use 3D images, not 4D images)
for_each -nthreads <nproc -all> -info */dwi : flirt -in IN/mean_b0_processed.nii.gz -ref IN/5tt_vol0.nii.gz -interp nearestneighbour -dof 6 -omat IN/diff2struct_fsl.mat
for_each -nthreads <nproc -all> -info */dwi : transformconvert IN/diff2struct_fsl.mat IN/mean_b0_processed.nii.gz IN/5tt_nocoreg.nii.gz flirt_import IN/diff2struct_mrtrix.txt 
for_each -nthreads <nproc -all> -info */dwi : mrtransform IN/5tt_nocoreg.mif -linear IN/diff2struct_mrtrix.txt -inverse IN/5tt_coreg.mif 

#Create a seed region along the GM/WM boundary
for_each -nthreads <nproc -all> -info */dwi : 5tt2gmwmi IN/5tt_coreg.mif IN/gmwmSeed_coreg.mif 
```

### Streamline generation

Make sure to allocate at least 5Go of space for each subject on your local disk as streamline generation can get quite heavy. Here we generate 10 millions streamlines and then reduce that number using the *tckgen* and *tcksift2* command.

``` bash
########################## STEP 4 ###################################
#                 Run the streamline analysis                        #
######################################################################

# Create streamlines
# Note that the "right" number of streamlines is still up for debate. Last I read from the MRtrix documentation,
# They recommend about 100 million tracks. Here I use 10 million, if only to save time. Read their papers and then make a decision
for_each -nthreads <nproc --all>/8 -info */dwi : tckgen -act IN/5tt_coreg.mif -backtrack -seed_gmwmi IN/gmwmSeed_coreg.mif -nthreads 8 -maxlength 250 -cutoff 0.06 -select 10000k IN/wmfod_norm.mif IN/tracks_10M.tck 

# Extract a subset of tracks (here, 200 thousand) for ease of visualization
# tckedit tracks_10M.tck -number 200k smallerTracks_200k.tck

# Reduce the number of streamlines with tcksift
for_each -nthreads <nproc --all>/8 -info */dwi : tcksift2 -act IN/5tt_coreg.mif -out_mu IN/sift_mu.txt -out_coeffs IN/sift_coeffs.txt -nthreads 8 IN/tracks_10M.tck IN/wmfod_norm.mif IN/sift_1M.txt 
```

### Recon-all

Download the lh and rh.hcpmmp1 annot files in the supplementary files [here](https://osf.io/fkyht/#!) and put them into \$SUBJECTS_DIR/fsaverage/label. This allows to prepare the T1 image for the HCP MMP 1.0 atlas [@glasser2016 ].

``` bash
# 1. Since the HCPMMP1-atlas is a FreeSurfer-based atlas, you have to preprocess the T1 image in FreeSurfer. 
# This will take several hours to complete.
recon-all –s <sub>_recon –i T1_raw.nii.gz –all

# If the recon folder specific to your subject haq not been placed into $SUBJECTS_DIR, you may have to move it manually
# Copy into freesurfer's subjects directory
echo <password> | sudo -S cp -r *T1w_recon $SUBJECTS_DIR
# Grant permission to write the file
echo <password> | sudo -S chmod -R a+w /usr/local/freesurfer

# 2. Map the annotation files of the HCP MMP 1.0 atlas from fsaverage to you subject for both hemispheres:
mri_surf2surf --srcsubject fsaverage --trgsubject <sub>_recon --hemi lh --sval-annot $SUBJECTS_DIR/fsaverage/label/lh.hcpmmp1.annot --tval
$SUBJECTS_DIR/<sub>_recon/label/lh.hcpmmp1.annot

mri_surf2surf --srcsubject fsaverage --trgsubject <sub>_recon --hemi rh --sval-annot $SUBJECTS_DIR/fsaverage/label/rh.hcpmmp1.annot --tval $SUBJECTS_DIR/<sub>_recon/label/rh.hcpmmp1.annot
```

**This step can be sped up with parallel computing. See the next section.**

### Generate the Structural Connectome (SC)

``` bash
for_each -nthreads <nproc --all> -info */dwi : mrconvert –datatype uint32  IN/hcpmmp1.mgz  IN/hcpmmp1.mif -force

# Replace the random integers of the hcpmmp1.mif file with integers
# that start at 1 and increase by 1.
for_each -nthreads <nproc --all> -info */dwi : labelconvert  IN/hcpmmp1.mif $MRtrix3/share/mrtrix3/labelconvert/hcpmmp1_original.txt $MRtrix3/share/mrtrix3/labelconvert/hcpmmp1_ordered.txt  IN/hcpmmp1_parcels_nocoreg.mif -force

# Register the ordered atlas-based volumetric parcellation to diffusion space.
for_each -nthreads <nproc --all> -info */dwi : mrtransform  IN/hcpmmp1_parcels_nocoreg.mif –linear  IN/diff2struct_mrtrix.txt –inverse –datatype uint32  IN/hcpmmp1_parcels_coreg.mif -force

# Create a whole-brain connectome, representing the streamlines between each parcellation pair in the atlas (in this case, 84x84). The "symmetric" option will make the lower diagonal the same as the upper diagonal, 
# and the "scale_invnodevol" option will scale the connectome by the inverse of the size of the node

for_each -nthreads <nproc --all> -info * : tck2connectome -symmetric -zero_diagonal -scale_invnodevol -tck_weights_in IN/dwi/sift_1M.txt IN/dwi/tracks_10M.tck IN/dwi/hcpmmp1_parcels_coreg.mif IN/dwi/IN_hcpmmp1_parcels_coreg.csv -out_assignment IN/dwi/assignments_IN_hcpmmp1_parcels_coreg.csv -force
```

This is what you should end up with.\

![W = importdata('sub-XXXXX_hcpmmp1_parcels_coreg.csv'); figure, imagesc(W, \[0 1\]), xlabel(\[' 379 Glasser regions '\]), ylabel('379 Glasser regions'), title(\[' Structural connectome (streamline density) '\]); colormap(jet), colorbar, set(gcf,'color','w'), set(gca,'fontsize',14)](SC.png){fig-align="center" width="784"}

You can then copy and save the structural connectomes wherever you like:

``` bash
find . -name \sub-*.csv -exec cp {} /path/to/where you want to save the SC \;
```
